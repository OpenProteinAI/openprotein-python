[
  {
    "objectID": "reference/index.html",
    "href": "reference/index.html",
    "title": "Function reference",
    "section": "",
    "text": "Welcome to the OpenProtein python client documentation!  Our workflows follow an asynchronous POST and GET framework. Once you initiate a task the system will schedule the job for retrieval later, once the work is complete. This means that even for tasks that may take a while to complete, your request will return immediately.  The job objects contain a job ID (job_id) which can be used to resume a workflow from where you left off! See the notebooks for demonstrations.\n\n\n\nbase.APISession\nConnection session.\n\n\n\n\n\n\nUpload your dataset to OpenProtein’s engineering platform for train, predict and design tasks.\n\n\n\napi.data.DataAPI\nAPI interface for calling AssayData endpoints\n\n\napi.data.AssayDataset\nFuture Job for manipulating results\n\n\n\n\n\n\nTrain model(s) on your measured properties to enable predictions for new sequences! These workflows can additionally perform cross-validation on your models to estimate uncertainty. /n A trained model is required before you can utilize predict or design endpoints.\n\n\n\napi.train.TrainingAPI\nAPI interface for calling Train endpoints\n\n\napi.train.TrainFuture\nFuture Job for manipulating results\n\n\n\n\n\n\nDesign new sequences based on your stated objectives and our genetic algorithm!\n\n\n\napi.design.DesignAPI\nAPI interface for calling Design endpoints\n\n\napi.design.DesignFuture\nFuture Job for manipulating results\n\n\n\n\n\n\nPredict properties on arbitary sequences with your OpenProtein trained models! You can make predictions for single sequences as well as single mutant variants of the sequence. Note, that you must first train a model with the train endpoints (see above).\n\n\n\napi.predict.PredictAPI\nAPI interface for calling Predict endpoints\n\n\napi.predict.PredictFuture\nFuture Job for manipulating results\n\n\n\n\n\n\nUse our generative Protein Evolutionary Transformer (PoET) model for de novo generation of proteins, evaluation of protein fitness, and single site mutant analysis of proteins. These workflows are all possible without prior wetlab data, and therefore do not require assaydata to be pre-loaded!\n\n\n\napi.poet.PoetAPI\nAPI interface for calling Poet and Align endpoints\n\n\napi.poet.PoetScoreFuture\nRepresents a result of a PoET scoring job.\n\n\napi.poet.PoetSingleSiteFuture\nRepresents a result of a PoET single-site analysis job.\n\n\napi.poet.PoetGenerateFuture\nRepresents a result of a PoET generation job.\n\n\napi.poet.PromptFuture\nRepresents a result of a prompt job.\n\n\napi.poet.MSAFuture\nRepresents a result of a MSA job.\n\n\n\n\n\n\nCreate embeddings for your protein sequences using open-source and proprietary models!\n\n\n\napi.embedding.EmbeddingAPI\nThis class defines a high level interface for accessing the embeddings API.\n\n\napi.embedding.EmbeddingResultFuture\nFuture Job for manipulating results\n\n\napi.embedding.ProtembedModel\nClass providing inference endpoints for protein embedding models served by OpenProtein.\n\n\napi.embedding.SVDModel\nClass providing embedding endpoint for SVD models. Also allows retrieving embeddings of sequences used to fit the SVD with get."
  },
  {
    "objectID": "reference/index.html#overview",
    "href": "reference/index.html#overview",
    "title": "Function reference",
    "section": "",
    "text": "Welcome to the OpenProtein python client documentation!  Our workflows follow an asynchronous POST and GET framework. Once you initiate a task the system will schedule the job for retrieval later, once the work is complete. This means that even for tasks that may take a while to complete, your request will return immediately.  The job objects contain a job ID (job_id) which can be used to resume a workflow from where you left off! See the notebooks for demonstrations.\n\n\n\nbase.APISession\nConnection session."
  },
  {
    "objectID": "reference/index.html#assay-data",
    "href": "reference/index.html#assay-data",
    "title": "Function reference",
    "section": "",
    "text": "Upload your dataset to OpenProtein’s engineering platform for train, predict and design tasks.\n\n\n\napi.data.DataAPI\nAPI interface for calling AssayData endpoints\n\n\napi.data.AssayDataset\nFuture Job for manipulating results"
  },
  {
    "objectID": "reference/index.html#train",
    "href": "reference/index.html#train",
    "title": "Function reference",
    "section": "",
    "text": "Train model(s) on your measured properties to enable predictions for new sequences! These workflows can additionally perform cross-validation on your models to estimate uncertainty. /n A trained model is required before you can utilize predict or design endpoints.\n\n\n\napi.train.TrainingAPI\nAPI interface for calling Train endpoints\n\n\napi.train.TrainFuture\nFuture Job for manipulating results"
  },
  {
    "objectID": "reference/index.html#design",
    "href": "reference/index.html#design",
    "title": "Function reference",
    "section": "",
    "text": "Design new sequences based on your stated objectives and our genetic algorithm!\n\n\n\napi.design.DesignAPI\nAPI interface for calling Design endpoints\n\n\napi.design.DesignFuture\nFuture Job for manipulating results"
  },
  {
    "objectID": "reference/index.html#predict",
    "href": "reference/index.html#predict",
    "title": "Function reference",
    "section": "",
    "text": "Predict properties on arbitary sequences with your OpenProtein trained models! You can make predictions for single sequences as well as single mutant variants of the sequence. Note, that you must first train a model with the train endpoints (see above).\n\n\n\napi.predict.PredictAPI\nAPI interface for calling Predict endpoints\n\n\napi.predict.PredictFuture\nFuture Job for manipulating results"
  },
  {
    "objectID": "reference/index.html#protein-evolutionary-transformer-poet",
    "href": "reference/index.html#protein-evolutionary-transformer-poet",
    "title": "Function reference",
    "section": "",
    "text": "Use our generative Protein Evolutionary Transformer (PoET) model for de novo generation of proteins, evaluation of protein fitness, and single site mutant analysis of proteins. These workflows are all possible without prior wetlab data, and therefore do not require assaydata to be pre-loaded!\n\n\n\napi.poet.PoetAPI\nAPI interface for calling Poet and Align endpoints\n\n\napi.poet.PoetScoreFuture\nRepresents a result of a PoET scoring job.\n\n\napi.poet.PoetSingleSiteFuture\nRepresents a result of a PoET single-site analysis job.\n\n\napi.poet.PoetGenerateFuture\nRepresents a result of a PoET generation job.\n\n\napi.poet.PromptFuture\nRepresents a result of a prompt job.\n\n\napi.poet.MSAFuture\nRepresents a result of a MSA job."
  },
  {
    "objectID": "reference/index.html#embeddings",
    "href": "reference/index.html#embeddings",
    "title": "Function reference",
    "section": "",
    "text": "Create embeddings for your protein sequences using open-source and proprietary models!\n\n\n\napi.embedding.EmbeddingAPI\nThis class defines a high level interface for accessing the embeddings API.\n\n\napi.embedding.EmbeddingResultFuture\nFuture Job for manipulating results\n\n\napi.embedding.ProtembedModel\nClass providing inference endpoints for protein embedding models served by OpenProtein.\n\n\napi.embedding.SVDModel\nClass providing embedding endpoint for SVD models. Also allows retrieving embeddings of sequences used to fit the SVD with get."
  },
  {
    "objectID": "reference/api.predict.PredictFuture.html",
    "href": "reference/api.predict.PredictFuture.html",
    "title": "api.predict.PredictFuture",
    "section": "",
    "text": "api.predict.PredictFuture(self, session, job, page_size=1000)\nFuture Job for manipulating results\n\n\n\n\n\nName\nDescription\n\n\n\n\nget\nGet all the results of the predict job.\n\n\n\n\n\napi.predict.PredictFuture.get(self, verbose=False)\nGet all the results of the predict job.\nArgs: verbose (bool, optional): If True, print verbose output. Defaults False.\nRaises: APIError: If there is an issue with the API request.\nReturns: PredictJob: A list of predict objects representing the results."
  },
  {
    "objectID": "reference/api.predict.PredictFuture.html#methods",
    "href": "reference/api.predict.PredictFuture.html#methods",
    "title": "api.predict.PredictFuture",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nget\nGet all the results of the predict job.\n\n\n\n\n\napi.predict.PredictFuture.get(self, verbose=False)\nGet all the results of the predict job.\nArgs: verbose (bool, optional): If True, print verbose output. Defaults False.\nRaises: APIError: If there is an issue with the API request.\nReturns: PredictJob: A list of predict objects representing the results."
  },
  {
    "objectID": "reference/api.data.AssayDataset.html",
    "href": "reference/api.data.AssayDataset.html",
    "title": "api.data.AssayDataset",
    "section": "",
    "text": "api.data.AssayDataset(self, session, metadata)\nFuture Job for manipulating results\n\n\n\n\n\nName\nDescription\n\n\n\n\nget_first\nGet head slice of assay data.\n\n\nget_slice\nGet a slice of assay data.\n\n\nlist_models\nList models assoicated with assay.\n\n\nupdate\nUpdate the assay metadata.\n\n\n\n\n\napi.data.AssayDataset.get_first(self)\nGet head slice of assay data.\n\n\n\n\n\nType\nDescription\n\n\n\n\npandas.DataFrame\nDataframe containing the slice of assay data.\n\n\n\n\n\n\n\napi.data.AssayDataset.get_slice(self, start, end)\nGet a slice of assay data.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nstart\nint\nStart index of the slice.\nrequired\n\n\nend\nint\nEnd index of the slice.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npandas.DataFrame\nDataframe containing the slice of assay data.\n\n\n\n\n\n\n\napi.data.AssayDataset.list_models(self)\nList models assoicated with assay.\n\n\n\n\n\nType\nDescription\n\n\n\n\nList\nList of models\n\n\n\n\n\n\n\napi.data.AssayDataset.update(self, assay_name=None, assay_description=None)\nUpdate the assay metadata.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nassay_name\nstr\nNew name of the assay, by default None.\nNone\n\n\nassay_description\nstr\nNew description of the assay, by default None.\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone"
  },
  {
    "objectID": "reference/api.data.AssayDataset.html#methods",
    "href": "reference/api.data.AssayDataset.html#methods",
    "title": "api.data.AssayDataset",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nget_first\nGet head slice of assay data.\n\n\nget_slice\nGet a slice of assay data.\n\n\nlist_models\nList models assoicated with assay.\n\n\nupdate\nUpdate the assay metadata.\n\n\n\n\n\napi.data.AssayDataset.get_first(self)\nGet head slice of assay data.\n\n\n\n\n\nType\nDescription\n\n\n\n\npandas.DataFrame\nDataframe containing the slice of assay data.\n\n\n\n\n\n\n\napi.data.AssayDataset.get_slice(self, start, end)\nGet a slice of assay data.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nstart\nint\nStart index of the slice.\nrequired\n\n\nend\nint\nEnd index of the slice.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npandas.DataFrame\nDataframe containing the slice of assay data.\n\n\n\n\n\n\n\napi.data.AssayDataset.list_models(self)\nList models assoicated with assay.\n\n\n\n\n\nType\nDescription\n\n\n\n\nList\nList of models\n\n\n\n\n\n\n\napi.data.AssayDataset.update(self, assay_name=None, assay_description=None)\nUpdate the assay metadata.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nassay_name\nstr\nNew name of the assay, by default None.\nNone\n\n\nassay_description\nstr\nNew description of the assay, by default None.\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone"
  },
  {
    "objectID": "reference/api.embedding.ProtembedModel.html",
    "href": "reference/api.embedding.ProtembedModel.html",
    "title": "api.embedding.ProtembedModel",
    "section": "",
    "text": "api.embedding.ProtembedModel(self, session, model_id, metadata=None)\nClass providing inference endpoints for protein embedding models served by OpenProtein.\n\n\n\n\n\nName\nDescription\n\n\n\n\nattn\nAttention embeddings for sequences using this model.\n\n\nembed\nEmbed sequences using this model.\n\n\nfit_svd\nFit an SVD on the embedding results of this model.\n\n\nget_metadata\nGet model metadata for this model.\n\n\nlogits\nlogit embeddings for sequences using this model.\n\n\n\n\n\napi.embedding.ProtembedModel.attn(self, sequences)\nAttention embeddings for sequences using this model.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsequences\ntyping.List[bytes]\nsequences to SVD\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nEmbeddingResultFuture\n\n\n\n\n\n\n\n\napi.embedding.ProtembedModel.embed(self, sequences, reduction='MEAN')\nEmbed sequences using this model.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsequences\ntyping.List[bytes]\nsequences to SVD\nrequired\n\n\nreduction\ntyping.Optional[str]\nembeddings reduction to use (e.g. mean)\n'MEAN'\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nEmbeddingResultFuture\n\n\n\n\n\n\n\n\napi.embedding.ProtembedModel.fit_svd(self, sequences, n_components=1024, reduction=None)\nFit an SVD on the embedding results of this model.\nThis function will create an SVDModel based on the embeddings from this model as well as the hyperparameters specified in the args.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsequences\ntyping.List[bytes]\nsequences to SVD\nrequired\n\n\nn_components\nint\nnumber of components in SVD. Will determine output shapes\n1024\n\n\nreduction\ntyping.Optional[str]\nembeddings reduction to use (e.g. mean)\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nSVDModel\n\n\n\n\n\n\n\n\napi.embedding.ProtembedModel.get_metadata(self)\nGet model metadata for this model.\n\n\n\n\n\nType\nDescription\n\n\n\n\nModelMetadata\n\n\n\n\n\n\n\n\napi.embedding.ProtembedModel.logits(self, sequences)\nlogit embeddings for sequences using this model.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsequences\ntyping.List[bytes]\nsequences to SVD\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nEmbeddingResultFuture"
  },
  {
    "objectID": "reference/api.embedding.ProtembedModel.html#methods",
    "href": "reference/api.embedding.ProtembedModel.html#methods",
    "title": "api.embedding.ProtembedModel",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nattn\nAttention embeddings for sequences using this model.\n\n\nembed\nEmbed sequences using this model.\n\n\nfit_svd\nFit an SVD on the embedding results of this model.\n\n\nget_metadata\nGet model metadata for this model.\n\n\nlogits\nlogit embeddings for sequences using this model.\n\n\n\n\n\napi.embedding.ProtembedModel.attn(self, sequences)\nAttention embeddings for sequences using this model.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsequences\ntyping.List[bytes]\nsequences to SVD\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nEmbeddingResultFuture\n\n\n\n\n\n\n\n\napi.embedding.ProtembedModel.embed(self, sequences, reduction='MEAN')\nEmbed sequences using this model.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsequences\ntyping.List[bytes]\nsequences to SVD\nrequired\n\n\nreduction\ntyping.Optional[str]\nembeddings reduction to use (e.g. mean)\n'MEAN'\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nEmbeddingResultFuture\n\n\n\n\n\n\n\n\napi.embedding.ProtembedModel.fit_svd(self, sequences, n_components=1024, reduction=None)\nFit an SVD on the embedding results of this model.\nThis function will create an SVDModel based on the embeddings from this model as well as the hyperparameters specified in the args.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsequences\ntyping.List[bytes]\nsequences to SVD\nrequired\n\n\nn_components\nint\nnumber of components in SVD. Will determine output shapes\n1024\n\n\nreduction\ntyping.Optional[str]\nembeddings reduction to use (e.g. mean)\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nSVDModel\n\n\n\n\n\n\n\n\napi.embedding.ProtembedModel.get_metadata(self)\nGet model metadata for this model.\n\n\n\n\n\nType\nDescription\n\n\n\n\nModelMetadata\n\n\n\n\n\n\n\n\napi.embedding.ProtembedModel.logits(self, sequences)\nlogit embeddings for sequences using this model.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsequences\ntyping.List[bytes]\nsequences to SVD\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nEmbeddingResultFuture"
  },
  {
    "objectID": "reference/api.poet.PoetScoreFuture.html",
    "href": "reference/api.poet.PoetScoreFuture.html",
    "title": "api.poet.PoetScoreFuture",
    "section": "",
    "text": "api.poet.PoetScoreFuture(self, session, job, page_size=config.POET_PAGE_SIZE)\nRepresents a result of a PoET scoring job.\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\nsession\nAPISession\nAn instance of APISession for API interactions.\n\n\njob\nJob\nThe PoET scoring job.\n\n\npage_size\nint\nThe number of results to fetch in a single page.\n\n\n\n\n\n\nget(verbose=False) Get the final results of the PoET job.\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nget\nGet the final results of the PoET scoring job.\n\n\n\n\n\napi.poet.PoetScoreFuture.get(self, verbose=False)\nGet the final results of the PoET scoring job.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nverbose\nbool\nIf True, print verbose output. Defaults to False.\nFalse\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nAPIError\nIf there is an issue with the API request.\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\ntyping.List[openprotein.models.PoetScoreResult]\nA list of PoetScoreResult objects representing the scoring results."
  },
  {
    "objectID": "reference/api.poet.PoetScoreFuture.html#attributes",
    "href": "reference/api.poet.PoetScoreFuture.html#attributes",
    "title": "api.poet.PoetScoreFuture",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\nsession\nAPISession\nAn instance of APISession for API interactions.\n\n\njob\nJob\nThe PoET scoring job.\n\n\npage_size\nint\nThe number of results to fetch in a single page."
  },
  {
    "objectID": "reference/api.poet.PoetScoreFuture.html#methods",
    "href": "reference/api.poet.PoetScoreFuture.html#methods",
    "title": "api.poet.PoetScoreFuture",
    "section": "",
    "text": "get(verbose=False) Get the final results of the PoET job."
  },
  {
    "objectID": "reference/api.poet.PoetScoreFuture.html#methods-1",
    "href": "reference/api.poet.PoetScoreFuture.html#methods-1",
    "title": "api.poet.PoetScoreFuture",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nget\nGet the final results of the PoET scoring job.\n\n\n\n\n\napi.poet.PoetScoreFuture.get(self, verbose=False)\nGet the final results of the PoET scoring job.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nverbose\nbool\nIf True, print verbose output. Defaults to False.\nFalse\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nAPIError\nIf there is an issue with the API request.\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\ntyping.List[openprotein.models.PoetScoreResult]\nA list of PoetScoreResult objects representing the scoring results."
  },
  {
    "objectID": "reference/api.poet.PoetAPI.html",
    "href": "reference/api.poet.PoetAPI.html",
    "title": "api.poet.PoetAPI",
    "section": "",
    "text": "api.poet.PoetAPI(self, session)\nAPI interface for calling Poet and Align endpoints\n\n\n\n\n\nName\nDescription\n\n\n\n\ncreate_msa\nConstruct an MSA via homology search with the seed sequence.\n\n\ngenerate\nGenerate protein sequences conditioned on a prompt.\n\n\nget_msa\nGet generated MSA for a given job.\n\n\nget_msa_job\nGet MSA job based on job_id.\n\n\nget_prompt\nGet prompts for a given job.\n\n\nget_prompt_job\nGet prompt job based on job_id.\n\n\nget_seed\nGet input data for a given msa job.\n\n\nload_msa_job\nReload a previously ran MSA job to resume where you left off.\n\n\nload_poet_job\nReload a previously ran Poet job to resume where you left off.\n\n\nload_prompt_job\nReload a previously ran prompt job to resume where you left off.\n\n\nscore\nScore query sequences using the specified prompt.\n\n\nsingle_site\nScore all single substitutions of the query sequence using the specified prompt.\n\n\nupload_msa\nUpload an MSA from file.\n\n\nupload_prompt\nDirectly upload a prompt.\n\n\n\n\n\napi.poet.PoetAPI.create_msa(self, seed)\nConstruct an MSA via homology search with the seed sequence.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nseed\nbytes\nSeed sequence for the MSA construction.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nAPIError\nIf there is an issue with the API request.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nMSAJob\nJob object containing the details of the MSA construction.\n\n\n\n\n\n\n\napi.poet.PoetAPI.generate(self, prompt, num_samples=100, temperature=1.0, topk=None, topp=None, max_length=1000, seed=None)\nGenerate protein sequences conditioned on a prompt.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nprompt\nPromptJob\nThe prompt to use for generating sequences.\nrequired\n\n\nnum_samples\nint\nThe number of samples to generate, by default 100.\n100\n\n\ntemperature\nfloat\nThe temperature for sampling. Higher values produce more random outputs, by default 1.0.\n1.0\n\n\ntopk\nint\nThe number of top-k residues to consider during sampling, by default None.\nNone\n\n\ntopp\nfloat\nThe cumulative probability threshold for top-p sampling, by default None.\nNone\n\n\nmax_length\nint\nThe maximum length of generated proteins, by default 1000.\n1000\n\n\nseed\nint\nSeed for random number generation, by default a random number.\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nAPIError\nIf there is an issue with the API request.\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nJob\nAn object representing the status and information about the generation job.\n\n\n\n\n\n\n\napi.poet.PoetAPI.get_msa(self, job)\nGet generated MSA for a given job.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\njob\nJob\nThe job for which to retrieve data.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\ncsv.reader\nA CSV reader for the response data.\n\n\n\n\n\n\n\napi.poet.PoetAPI.get_msa_job(self, job_id)\nGet MSA job based on job_id.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\njob_id\nstr\njob ID for a prompt job\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nMSAJob\nA prompt job instance\n\n\n\n\n\n\n\napi.poet.PoetAPI.get_prompt(self, job, prompt_index=None)\nGet prompts for a given job.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\njob\nJob\nThe job for which to retrieve data.\nrequired\n\n\nprompt_index\ntyping.Optional[int]\nThe replicate number for the prompt (input_type=-PROMPT only)\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\ncsv.reader\nA CSV reader for the response data.\n\n\n\n\n\n\n\napi.poet.PoetAPI.get_prompt_job(self, job_id)\nGet prompt job based on job_id.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\njob_id\nstr\njob ID for a prompt job\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nPromptJob\nA prompt job instance\n\n\n\n\n\n\n\napi.poet.PoetAPI.get_seed(self, job)\nGet input data for a given msa job.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\njob\nJob\nThe job for which to retrieve data.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\ncsv.reader\nA CSV reader for the response data.\n\n\n\n\n\n\n\napi.poet.PoetAPI.load_msa_job(self, msa_id)\nReload a previously ran MSA job to resume where you left off.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmsa_id\nstr\nID for job.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nInvalidJob\nIf job is of incorrect type.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nPromptFuture\nJob to resume workflows.\n\n\n\n\n\n\n\napi.poet.PoetAPI.load_poet_job(self, job_id)\nReload a previously ran Poet job to resume where you left off.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\njob_id\nstr\nID for job.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nInvalidJob\nIf job is of incorrect type.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nPoetFuture\nJob to resume workflows.\n\n\n\n\n\n\n\napi.poet.PoetAPI.load_prompt_job(self, prompt_id)\nReload a previously ran prompt job to resume where you left off.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nprompt_id\nstr\nID for job.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nInvalidJob\nIf job is of incorrect type.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nPromptFuture\nJob to resume workflows.\n\n\n\n\n\n\n\napi.poet.PoetAPI.score(self, prompt, queries)\nScore query sequences using the specified prompt.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nprompt\nPrompt\nPrompt job to use for scoring the sequences.\nrequired\n\n\nqueries\ntyping.List[bytes]\nSequences to score.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nresults\nThe scores of the query sequences.\n\n\n\n\n\n\n\napi.poet.PoetAPI.single_site(self, prompt, sequence)\nScore all single substitutions of the query sequence using the specified prompt.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nprompt\nPrompt\nPrompt job to use for scoring the sequences.\nrequired\n\n\nsequence\nbytes\nSequence to analyse.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nresults\nThe scores of the mutated sequence.\n\n\n\n\n\n\n\napi.poet.PoetAPI.upload_msa(self, msa_file)\nUpload an MSA from file.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmsa_file\nstr\nReady-made MSA. If not provided, default value is None.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nAPIError\nIf there is an issue with the API request.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nMSAJob\nJob object containing the details of the MSA upload.\n\n\n\n\n\n\n\napi.poet.PoetAPI.upload_prompt(self, prompt_file)\nDirectly upload a prompt.\nBypass post_msa and prompt_post steps entirely. In this case PoET will use the prompt as is. You can specify multiple prompts (one per replicate) with an  and newline between CSVs.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nprompt_file\nBinaryIO\nBinary I/O object representing the prompt file.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nAPIError\nIf there is an issue with the API request.\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nPromptJob\nAn object representing the status and results of the prompt job."
  },
  {
    "objectID": "reference/api.poet.PoetAPI.html#methods",
    "href": "reference/api.poet.PoetAPI.html#methods",
    "title": "api.poet.PoetAPI",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ncreate_msa\nConstruct an MSA via homology search with the seed sequence.\n\n\ngenerate\nGenerate protein sequences conditioned on a prompt.\n\n\nget_msa\nGet generated MSA for a given job.\n\n\nget_msa_job\nGet MSA job based on job_id.\n\n\nget_prompt\nGet prompts for a given job.\n\n\nget_prompt_job\nGet prompt job based on job_id.\n\n\nget_seed\nGet input data for a given msa job.\n\n\nload_msa_job\nReload a previously ran MSA job to resume where you left off.\n\n\nload_poet_job\nReload a previously ran Poet job to resume where you left off.\n\n\nload_prompt_job\nReload a previously ran prompt job to resume where you left off.\n\n\nscore\nScore query sequences using the specified prompt.\n\n\nsingle_site\nScore all single substitutions of the query sequence using the specified prompt.\n\n\nupload_msa\nUpload an MSA from file.\n\n\nupload_prompt\nDirectly upload a prompt.\n\n\n\n\n\napi.poet.PoetAPI.create_msa(self, seed)\nConstruct an MSA via homology search with the seed sequence.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nseed\nbytes\nSeed sequence for the MSA construction.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nAPIError\nIf there is an issue with the API request.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nMSAJob\nJob object containing the details of the MSA construction.\n\n\n\n\n\n\n\napi.poet.PoetAPI.generate(self, prompt, num_samples=100, temperature=1.0, topk=None, topp=None, max_length=1000, seed=None)\nGenerate protein sequences conditioned on a prompt.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nprompt\nPromptJob\nThe prompt to use for generating sequences.\nrequired\n\n\nnum_samples\nint\nThe number of samples to generate, by default 100.\n100\n\n\ntemperature\nfloat\nThe temperature for sampling. Higher values produce more random outputs, by default 1.0.\n1.0\n\n\ntopk\nint\nThe number of top-k residues to consider during sampling, by default None.\nNone\n\n\ntopp\nfloat\nThe cumulative probability threshold for top-p sampling, by default None.\nNone\n\n\nmax_length\nint\nThe maximum length of generated proteins, by default 1000.\n1000\n\n\nseed\nint\nSeed for random number generation, by default a random number.\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nAPIError\nIf there is an issue with the API request.\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nJob\nAn object representing the status and information about the generation job.\n\n\n\n\n\n\n\napi.poet.PoetAPI.get_msa(self, job)\nGet generated MSA for a given job.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\njob\nJob\nThe job for which to retrieve data.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\ncsv.reader\nA CSV reader for the response data.\n\n\n\n\n\n\n\napi.poet.PoetAPI.get_msa_job(self, job_id)\nGet MSA job based on job_id.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\njob_id\nstr\njob ID for a prompt job\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nMSAJob\nA prompt job instance\n\n\n\n\n\n\n\napi.poet.PoetAPI.get_prompt(self, job, prompt_index=None)\nGet prompts for a given job.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\njob\nJob\nThe job for which to retrieve data.\nrequired\n\n\nprompt_index\ntyping.Optional[int]\nThe replicate number for the prompt (input_type=-PROMPT only)\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\ncsv.reader\nA CSV reader for the response data.\n\n\n\n\n\n\n\napi.poet.PoetAPI.get_prompt_job(self, job_id)\nGet prompt job based on job_id.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\njob_id\nstr\njob ID for a prompt job\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nPromptJob\nA prompt job instance\n\n\n\n\n\n\n\napi.poet.PoetAPI.get_seed(self, job)\nGet input data for a given msa job.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\njob\nJob\nThe job for which to retrieve data.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\ncsv.reader\nA CSV reader for the response data.\n\n\n\n\n\n\n\napi.poet.PoetAPI.load_msa_job(self, msa_id)\nReload a previously ran MSA job to resume where you left off.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmsa_id\nstr\nID for job.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nInvalidJob\nIf job is of incorrect type.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nPromptFuture\nJob to resume workflows.\n\n\n\n\n\n\n\napi.poet.PoetAPI.load_poet_job(self, job_id)\nReload a previously ran Poet job to resume where you left off.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\njob_id\nstr\nID for job.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nInvalidJob\nIf job is of incorrect type.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nPoetFuture\nJob to resume workflows.\n\n\n\n\n\n\n\napi.poet.PoetAPI.load_prompt_job(self, prompt_id)\nReload a previously ran prompt job to resume where you left off.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nprompt_id\nstr\nID for job.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nInvalidJob\nIf job is of incorrect type.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nPromptFuture\nJob to resume workflows.\n\n\n\n\n\n\n\napi.poet.PoetAPI.score(self, prompt, queries)\nScore query sequences using the specified prompt.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nprompt\nPrompt\nPrompt job to use for scoring the sequences.\nrequired\n\n\nqueries\ntyping.List[bytes]\nSequences to score.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nresults\nThe scores of the query sequences.\n\n\n\n\n\n\n\napi.poet.PoetAPI.single_site(self, prompt, sequence)\nScore all single substitutions of the query sequence using the specified prompt.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nprompt\nPrompt\nPrompt job to use for scoring the sequences.\nrequired\n\n\nsequence\nbytes\nSequence to analyse.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nresults\nThe scores of the mutated sequence.\n\n\n\n\n\n\n\napi.poet.PoetAPI.upload_msa(self, msa_file)\nUpload an MSA from file.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmsa_file\nstr\nReady-made MSA. If not provided, default value is None.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nAPIError\nIf there is an issue with the API request.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nMSAJob\nJob object containing the details of the MSA upload.\n\n\n\n\n\n\n\napi.poet.PoetAPI.upload_prompt(self, prompt_file)\nDirectly upload a prompt.\nBypass post_msa and prompt_post steps entirely. In this case PoET will use the prompt as is. You can specify multiple prompts (one per replicate) with an  and newline between CSVs.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nprompt_file\nBinaryIO\nBinary I/O object representing the prompt file.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nAPIError\nIf there is an issue with the API request.\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nPromptJob\nAn object representing the status and results of the prompt job."
  },
  {
    "objectID": "reference/api.poet.MSAFuture.html",
    "href": "reference/api.poet.MSAFuture.html",
    "title": "api.poet.MSAFuture",
    "section": "",
    "text": "api.poet.MSAFuture(self, session, job, page_size=config.POET_PAGE_SIZE)\nRepresents a result of a MSA job.\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\nsession\nAPISession\nAn instance of APISession for API interactions.\n\n\njob\nJob\nThe PoET scoring job.\n\n\npage_size\nint\nThe number of results to fetch in a single page.\n\n\n\n\n\n\nget(verbose=False) Get the final results of the PoET scoring job.\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\ntyping.List[openprotein.models.PoetScoreResult]\nThe list of results from the PoET scoring job.\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nsample_prompt\nCreate a protein sequence prompt from a linked MSA (Multiple Sequence Alignment) for PoET Jobs.\n\n\n\n\n\napi.poet.MSAFuture.sample_prompt(self, num_sequences=None, num_residues=None, method=MSASamplingMethod.NEIGHBORS_NONGAP_NORM_NO_LIMIT, homology_level=0.8, max_similarity=1.0, min_similarity=0.0, always_include_seed_sequence=False, num_ensemble_prompts=1, random_seed=None)\nCreate a protein sequence prompt from a linked MSA (Multiple Sequence Alignment) for PoET Jobs.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nnum_sequences\nint\nMaximum number of sequences in the prompt. Must be &lt;100.\nNone\n\n\nnum_residues\nint\nMaximum number of residues (tokens) in the prompt. Must be less than 24577.\nNone\n\n\nmethod\nMSASamplingMethod\nMethod to use for MSA sampling. Defaults to NEIGHBORS_NONGAP_NORM_NO_LIMIT.\nMSASamplingMethod.NEIGHBORS_NONGAP_NORM_NO_LIMIT\n\n\nhomology_level\nfloat\nLevel of homology for sequences in the MSA (neighbors methods only). Must be between 0 and 1. Defaults to 0.8.\n0.8\n\n\nmax_similarity\nfloat\nMaximum similarity between sequences in the MSA and the seed. Must be between 0 and 1. Defaults to 1.0.\n1.0\n\n\nmin_similarity\nfloat\nMinimum similarity between sequences in the MSA and the seed. Must be between 0 and 1. Defaults to 0.0.\n0.0\n\n\nalways_include_seed_sequence\nbool\nWhether to always include the seed sequence in the MSA. Defaults to False.\nFalse\n\n\nnum_ensemble_prompts\nint\nNumber of ensemble jobs to run. Defaults to 1.\n1\n\n\nrandom_seed\nint\nSeed for random number generation. Defaults to a random number between 0 and 2**32-1.\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nInvalidParameterError\nIf provided parameter values are not in the allowed range.\n\n\nMissingParameterError\nIf both or none of ‘num_sequences’, ‘num_residues’ is specified.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nPromptJob"
  },
  {
    "objectID": "reference/api.poet.MSAFuture.html#attributes",
    "href": "reference/api.poet.MSAFuture.html#attributes",
    "title": "api.poet.MSAFuture",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\nsession\nAPISession\nAn instance of APISession for API interactions.\n\n\njob\nJob\nThe PoET scoring job.\n\n\npage_size\nint\nThe number of results to fetch in a single page."
  },
  {
    "objectID": "reference/api.poet.MSAFuture.html#methods",
    "href": "reference/api.poet.MSAFuture.html#methods",
    "title": "api.poet.MSAFuture",
    "section": "",
    "text": "get(verbose=False) Get the final results of the PoET scoring job."
  },
  {
    "objectID": "reference/api.poet.MSAFuture.html#returns",
    "href": "reference/api.poet.MSAFuture.html#returns",
    "title": "api.poet.MSAFuture",
    "section": "",
    "text": "Type\nDescription\n\n\n\n\ntyping.List[openprotein.models.PoetScoreResult]\nThe list of results from the PoET scoring job."
  },
  {
    "objectID": "reference/api.poet.MSAFuture.html#methods-1",
    "href": "reference/api.poet.MSAFuture.html#methods-1",
    "title": "api.poet.MSAFuture",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nsample_prompt\nCreate a protein sequence prompt from a linked MSA (Multiple Sequence Alignment) for PoET Jobs.\n\n\n\n\n\napi.poet.MSAFuture.sample_prompt(self, num_sequences=None, num_residues=None, method=MSASamplingMethod.NEIGHBORS_NONGAP_NORM_NO_LIMIT, homology_level=0.8, max_similarity=1.0, min_similarity=0.0, always_include_seed_sequence=False, num_ensemble_prompts=1, random_seed=None)\nCreate a protein sequence prompt from a linked MSA (Multiple Sequence Alignment) for PoET Jobs.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nnum_sequences\nint\nMaximum number of sequences in the prompt. Must be &lt;100.\nNone\n\n\nnum_residues\nint\nMaximum number of residues (tokens) in the prompt. Must be less than 24577.\nNone\n\n\nmethod\nMSASamplingMethod\nMethod to use for MSA sampling. Defaults to NEIGHBORS_NONGAP_NORM_NO_LIMIT.\nMSASamplingMethod.NEIGHBORS_NONGAP_NORM_NO_LIMIT\n\n\nhomology_level\nfloat\nLevel of homology for sequences in the MSA (neighbors methods only). Must be between 0 and 1. Defaults to 0.8.\n0.8\n\n\nmax_similarity\nfloat\nMaximum similarity between sequences in the MSA and the seed. Must be between 0 and 1. Defaults to 1.0.\n1.0\n\n\nmin_similarity\nfloat\nMinimum similarity between sequences in the MSA and the seed. Must be between 0 and 1. Defaults to 0.0.\n0.0\n\n\nalways_include_seed_sequence\nbool\nWhether to always include the seed sequence in the MSA. Defaults to False.\nFalse\n\n\nnum_ensemble_prompts\nint\nNumber of ensemble jobs to run. Defaults to 1.\n1\n\n\nrandom_seed\nint\nSeed for random number generation. Defaults to a random number between 0 and 2**32-1.\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nInvalidParameterError\nIf provided parameter values are not in the allowed range.\n\n\nMissingParameterError\nIf both or none of ‘num_sequences’, ‘num_residues’ is specified.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nPromptJob"
  },
  {
    "objectID": "reference/api.poet.PoetSingleSiteFuture.html",
    "href": "reference/api.poet.PoetSingleSiteFuture.html",
    "title": "api.poet.PoetSingleSiteFuture",
    "section": "",
    "text": "api.poet.PoetSingleSiteFuture(self, session, job, page_size=config.POET_PAGE_SIZE)\nRepresents a result of a PoET single-site analysis job.\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\nsession\nAPISession\nAn instance of APISession for API interactions.\n\n\njob\nJob\nThe PoET scoring job.\n\n\npage_size\nint\nThe number of results to fetch in a single page.\n\n\n\n\n\n\nget(verbose=False) Get the final results of the PoET job.\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nget\nGet the results of a PoET single-site analysis job.\n\n\n\n\n\napi.poet.PoetSingleSiteFuture.get(self, verbose=False)\nGet the results of a PoET single-site analysis job.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nverbose\nbool\nIf True, print verbose output. Defaults to False.\nFalse\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nDict[bytes, float]\nA dictionary mapping mutation codes to scores.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nAPIError\nIf there is an issue with the API request."
  },
  {
    "objectID": "reference/api.poet.PoetSingleSiteFuture.html#attributes",
    "href": "reference/api.poet.PoetSingleSiteFuture.html#attributes",
    "title": "api.poet.PoetSingleSiteFuture",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\nsession\nAPISession\nAn instance of APISession for API interactions.\n\n\njob\nJob\nThe PoET scoring job.\n\n\npage_size\nint\nThe number of results to fetch in a single page."
  },
  {
    "objectID": "reference/api.poet.PoetSingleSiteFuture.html#methods",
    "href": "reference/api.poet.PoetSingleSiteFuture.html#methods",
    "title": "api.poet.PoetSingleSiteFuture",
    "section": "",
    "text": "get(verbose=False) Get the final results of the PoET job."
  },
  {
    "objectID": "reference/api.poet.PoetSingleSiteFuture.html#methods-1",
    "href": "reference/api.poet.PoetSingleSiteFuture.html#methods-1",
    "title": "api.poet.PoetSingleSiteFuture",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nget\nGet the results of a PoET single-site analysis job.\n\n\n\n\n\napi.poet.PoetSingleSiteFuture.get(self, verbose=False)\nGet the results of a PoET single-site analysis job.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nverbose\nbool\nIf True, print verbose output. Defaults to False.\nFalse\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nDict[bytes, float]\nA dictionary mapping mutation codes to scores.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nAPIError\nIf there is an issue with the API request."
  },
  {
    "objectID": "reference/api.poet.PromptFuture.html",
    "href": "reference/api.poet.PromptFuture.html",
    "title": "api.poet.PromptFuture",
    "section": "",
    "text": "api.poet.PromptFuture(self, session, job, page_size=config.POET_PAGE_SIZE, msa_id=None)\nRepresents a result of a prompt job.\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\nsession\nAPISession\nAn instance of APISession for API interactions.\n\n\njob\nJob\nThe PoET scoring job.\n\n\npage_size\nint\nThe number of results to fetch in a single page.\n\n\n\n\n\n\nget(verbose=False) Get the final results of the PoET scoring job.\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\ntyping.List[openprotein.models.PoetScoreResult]\nThe list of results from the PoET scoring job."
  },
  {
    "objectID": "reference/api.poet.PromptFuture.html#attributes",
    "href": "reference/api.poet.PromptFuture.html#attributes",
    "title": "api.poet.PromptFuture",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\nsession\nAPISession\nAn instance of APISession for API interactions.\n\n\njob\nJob\nThe PoET scoring job.\n\n\npage_size\nint\nThe number of results to fetch in a single page."
  },
  {
    "objectID": "reference/api.poet.PromptFuture.html#methods",
    "href": "reference/api.poet.PromptFuture.html#methods",
    "title": "api.poet.PromptFuture",
    "section": "",
    "text": "get(verbose=False) Get the final results of the PoET scoring job."
  },
  {
    "objectID": "reference/api.poet.PromptFuture.html#returns",
    "href": "reference/api.poet.PromptFuture.html#returns",
    "title": "api.poet.PromptFuture",
    "section": "",
    "text": "Type\nDescription\n\n\n\n\ntyping.List[openprotein.models.PoetScoreResult]\nThe list of results from the PoET scoring job."
  },
  {
    "objectID": "reference/api.data.DataAPI.html",
    "href": "reference/api.data.DataAPI.html",
    "title": "api.data.DataAPI",
    "section": "",
    "text": "api.data.DataAPI(self, session)\nAPI interface for calling AssayData endpoints\n\n\n\n\n\nName\nDescription\n\n\n\n\ncreate\nCreate a new assay dataset.\n\n\nget\nGet an assay dataset by its ID.\n\n\nlist\nList all assay datasets.\n\n\nload_job\nReload a Submitted job to resume from where you left off!\n\n\n\n\n\napi.data.DataAPI.create(self, table, name, description=None)\nCreate a new assay dataset.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ntable\npandas.DataFrame\nDataFrame containing the assay data.\nrequired\n\n\nname\nstr\nName of the assay dataset.\nrequired\n\n\ndescription\nstr\nDescription of the assay dataset, by default None.\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nAssayDataset\nCreated assay dataset.\n\n\n\n\n\n\n\napi.data.DataAPI.get(self, assay_id)\nGet an assay dataset by its ID.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nassay_id\nstr\nID of the assay dataset.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nAssayDataset\nAssay dataset with the specified ID.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nKeyError\nIf no assay dataset with the given ID is found.\n\n\n\n\n\n\n\napi.data.DataAPI.list(self)\nList all assay datasets.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\ntyping.List[openprotein.api.data.AssayDataset]\nList of all assay datasets.\n\n\n\n\n\n\n\napi.data.DataAPI.load_job(self, assay_id)\nReload a Submitted job to resume from where you left off!\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nassay_id\nstr\nThe identifier of the job whose details are to be loaded.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nJob\nJob\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nHTTPError\nIf the request to the server fails.\n\n\nInvalidJob\nIf the Job is of the wrong type"
  },
  {
    "objectID": "reference/api.data.DataAPI.html#methods",
    "href": "reference/api.data.DataAPI.html#methods",
    "title": "api.data.DataAPI",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ncreate\nCreate a new assay dataset.\n\n\nget\nGet an assay dataset by its ID.\n\n\nlist\nList all assay datasets.\n\n\nload_job\nReload a Submitted job to resume from where you left off!\n\n\n\n\n\napi.data.DataAPI.create(self, table, name, description=None)\nCreate a new assay dataset.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ntable\npandas.DataFrame\nDataFrame containing the assay data.\nrequired\n\n\nname\nstr\nName of the assay dataset.\nrequired\n\n\ndescription\nstr\nDescription of the assay dataset, by default None.\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nAssayDataset\nCreated assay dataset.\n\n\n\n\n\n\n\napi.data.DataAPI.get(self, assay_id)\nGet an assay dataset by its ID.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nassay_id\nstr\nID of the assay dataset.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nAssayDataset\nAssay dataset with the specified ID.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nKeyError\nIf no assay dataset with the given ID is found.\n\n\n\n\n\n\n\napi.data.DataAPI.list(self)\nList all assay datasets.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\ntyping.List[openprotein.api.data.AssayDataset]\nList of all assay datasets.\n\n\n\n\n\n\n\napi.data.DataAPI.load_job(self, assay_id)\nReload a Submitted job to resume from where you left off!\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nassay_id\nstr\nThe identifier of the job whose details are to be loaded.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nJob\nJob\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nHTTPError\nIf the request to the server fails.\n\n\nInvalidJob\nIf the Job is of the wrong type"
  },
  {
    "objectID": "reference/api.predict.PredictAPI.html",
    "href": "reference/api.predict.PredictAPI.html",
    "title": "api.predict.PredictAPI",
    "section": "",
    "text": "api.predict.PredictAPI(self, session)\nAPI interface for calling Predict endpoints\n\n\n\n\n\nName\nDescription\n\n\n\n\ncreate_predict_job\nCreates a new Predict job for a given list of sequences and a trained model.\n\n\ncreate_predict_single_site\nCreates a new Predict job for single site mutation analysis with a trained model.\n\n\nget_prediction_results\nRetrieves the results of a Predict job.\n\n\nget_single_site_prediction_results\nRetrieves the results of a single site Predict job.\n\n\nload_job\nReload a Submitted job to resume from where you left off!\n\n\n\n\n\napi.predict.PredictAPI.create_predict_job(self, sequences, train_job, model_ids=None)\nCreates a new Predict job for a given list of sequences and a trained model.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsequences\nList\nThe list of sequences to be used for the Predict job.\nrequired\n\n\ntrain_job\nTrainFuture\nThe train job object representing the trained model.\nrequired\n\n\nmodel_ids\ntyping.List[str]\nThe list of model ids to be used for Predict. Default is None.\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nPredictFuture\nThe job object representing the Predict job.\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nInvalidParameterError\nIf the sequences are not of the same length as the assay data or if the train job has not completed successfully.\n\n\nInvalidParameterError\nIf BOTH train_job and model_ids are specified\n\n\nInvalidParameterError\nIf NEITHER train_job or model_ids is specified\n\n\nAPIError\nIf the backend refuses the job (due to sequence length or invalid inputs)\n\n\n\n\n\n\n\napi.predict.PredictAPI.create_predict_single_site(self, sequence, train_job, model_ids=None)\nCreates a new Predict job for single site mutation analysis with a trained model.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsequence\nstr\nThe sequence for single site analysis.\nrequired\n\n\ntrain_job\nTrainFuture\nThe train job object representing the trained model.\nrequired\n\n\nmodel_ids\ntyping.List[str]\nThe list of model ids to be used for Predict. Default is None.\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nPredictFuture\nThe job object representing the Predict job.\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nInvalidParameterError\nIf the sequences are not of the same length as the assay data or if the train job has not completed successfully.\n\n\nInvalidParameterError\nIf BOTH train_job and model_ids are specified\n\n\nInvalidParameterError\nIf NEITHER train_job or model_ids is specified\n\n\nAPIError\nIf the backend refuses the job (due to sequence length or invalid inputs)\n\n\n\n\n\n\n\napi.predict.PredictAPI.get_prediction_results(self, job_id, page_size=None, page_offset=None)\nRetrieves the results of a Predict job.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\njob_id\nstr\nThe ID of the Predict job.\nrequired\n\n\npage_size\ntyping.Optional[int]\nThe number of results to be returned per page. If None, all results are returned.\nis None\n\n\npage_offset\ntyping.Optional[int]\nThe number of results to skip. If None, defaults to 0.\nis None\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nPredictJob\nThe job object representing the Predict job.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nHTTPError\nIf the GET request does not succeed.\n\n\n\n\n\n\n\napi.predict.PredictAPI.get_single_site_prediction_results(self, job_id, page_size=None, page_offset=None)\nRetrieves the results of a single site Predict job.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\njob_id\nstr\nThe ID of the Predict job.\nrequired\n\n\npage_size\ntyping.Optional[int]\nThe number of results to be returned per page. If None, all results are returned.\nis None\n\n\npage_offset\ntyping.Optional[int]\nThe page number to start retrieving results from. If None, defaults to 0.\nis None\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nPredictSingleSiteJob\nThe job object representing the single site Predict job.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nHTTPError\nIf the GET request does not succeed.\n\n\n\n\n\n\n\napi.predict.PredictAPI.load_job(self, job_id)\nReload a Submitted job to resume from where you left off!\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\njob_id\nstr\nThe identifier of the job whose details are to be loaded.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nJob\nJob\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nHTTPError\nIf the request to the server fails.\n\n\nInvalidJob\nIf the Job is of the wrong type"
  },
  {
    "objectID": "reference/api.predict.PredictAPI.html#methods",
    "href": "reference/api.predict.PredictAPI.html#methods",
    "title": "api.predict.PredictAPI",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ncreate_predict_job\nCreates a new Predict job for a given list of sequences and a trained model.\n\n\ncreate_predict_single_site\nCreates a new Predict job for single site mutation analysis with a trained model.\n\n\nget_prediction_results\nRetrieves the results of a Predict job.\n\n\nget_single_site_prediction_results\nRetrieves the results of a single site Predict job.\n\n\nload_job\nReload a Submitted job to resume from where you left off!\n\n\n\n\n\napi.predict.PredictAPI.create_predict_job(self, sequences, train_job, model_ids=None)\nCreates a new Predict job for a given list of sequences and a trained model.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsequences\nList\nThe list of sequences to be used for the Predict job.\nrequired\n\n\ntrain_job\nTrainFuture\nThe train job object representing the trained model.\nrequired\n\n\nmodel_ids\ntyping.List[str]\nThe list of model ids to be used for Predict. Default is None.\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nPredictFuture\nThe job object representing the Predict job.\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nInvalidParameterError\nIf the sequences are not of the same length as the assay data or if the train job has not completed successfully.\n\n\nInvalidParameterError\nIf BOTH train_job and model_ids are specified\n\n\nInvalidParameterError\nIf NEITHER train_job or model_ids is specified\n\n\nAPIError\nIf the backend refuses the job (due to sequence length or invalid inputs)\n\n\n\n\n\n\n\napi.predict.PredictAPI.create_predict_single_site(self, sequence, train_job, model_ids=None)\nCreates a new Predict job for single site mutation analysis with a trained model.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsequence\nstr\nThe sequence for single site analysis.\nrequired\n\n\ntrain_job\nTrainFuture\nThe train job object representing the trained model.\nrequired\n\n\nmodel_ids\ntyping.List[str]\nThe list of model ids to be used for Predict. Default is None.\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nPredictFuture\nThe job object representing the Predict job.\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nInvalidParameterError\nIf the sequences are not of the same length as the assay data or if the train job has not completed successfully.\n\n\nInvalidParameterError\nIf BOTH train_job and model_ids are specified\n\n\nInvalidParameterError\nIf NEITHER train_job or model_ids is specified\n\n\nAPIError\nIf the backend refuses the job (due to sequence length or invalid inputs)\n\n\n\n\n\n\n\napi.predict.PredictAPI.get_prediction_results(self, job_id, page_size=None, page_offset=None)\nRetrieves the results of a Predict job.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\njob_id\nstr\nThe ID of the Predict job.\nrequired\n\n\npage_size\ntyping.Optional[int]\nThe number of results to be returned per page. If None, all results are returned.\nis None\n\n\npage_offset\ntyping.Optional[int]\nThe number of results to skip. If None, defaults to 0.\nis None\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nPredictJob\nThe job object representing the Predict job.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nHTTPError\nIf the GET request does not succeed.\n\n\n\n\n\n\n\napi.predict.PredictAPI.get_single_site_prediction_results(self, job_id, page_size=None, page_offset=None)\nRetrieves the results of a single site Predict job.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\njob_id\nstr\nThe ID of the Predict job.\nrequired\n\n\npage_size\ntyping.Optional[int]\nThe number of results to be returned per page. If None, all results are returned.\nis None\n\n\npage_offset\ntyping.Optional[int]\nThe page number to start retrieving results from. If None, defaults to 0.\nis None\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nPredictSingleSiteJob\nThe job object representing the single site Predict job.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nHTTPError\nIf the GET request does not succeed.\n\n\n\n\n\n\n\napi.predict.PredictAPI.load_job(self, job_id)\nReload a Submitted job to resume from where you left off!\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\njob_id\nstr\nThe identifier of the job whose details are to be loaded.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nJob\nJob\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nHTTPError\nIf the request to the server fails.\n\n\nInvalidJob\nIf the Job is of the wrong type"
  },
  {
    "objectID": "reference/api.design.DesignAPI.html",
    "href": "reference/api.design.DesignAPI.html",
    "title": "api.design.DesignAPI",
    "section": "",
    "text": "api.design.DesignAPI(self, session)\nAPI interface for calling Design endpoints\n\n\n\n\n\nName\nDescription\n\n\n\n\ncreate_design_job\nStart a protein design job based on your assaydata, a trained ML model and Criteria (specified here).\n\n\nget_design_results\nRetrieves the results of a Design job.\n\n\nload_job\nReload a Submitted job to resume from where you left off!\n\n\n\n\n\napi.design.DesignAPI.create_design_job(self, design_job)\nStart a protein design job based on your assaydata, a trained ML model and Criteria (specified here).\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndesign_job\nDesignJobCreate\nThe details of the design job to be created, with the following parameters: - assay_id: The ID for the assay. - criteria: A list of CriterionItem lists for evaluating the design. - num_steps: The number of steps in the genetic algo. Default is 8. - pop_size: The population size for the genetic algo. Default is None. - n_offsprings: The number of offspring for the genetic algo. Default is None. - crossover_prob: The crossover probability for the genetic algo. Default is None. - crossover_prob_pointwise: The pointwise crossover probability for the genetic algo. Default is None. - mutation_average_mutations_per_seq: The average number of mutations per sequence. Default is None. - mutation_positions: A list of positions where mutations may occur. Default is None.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nDesignFuture\nThe created job as a DesignFuture instance.\n\n\n\n\n\n\n\napi.design.DesignAPI.get_design_results(self, job_id, page_size=None, page_offset=None)\nRetrieves the results of a Design job.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\njob_id\nstr\nThe ID for the design job\nrequired\n\n\npage_size\ntyping.Optional[int]\nThe number of results to be returned per page. If None, all results are returned.\nis None\n\n\npage_offset\ntyping.Optional[int]\nThe number of results to skip. If None, defaults to 0.\nis None\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nDesignJob\nThe job object representing the Design job.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nHTTPError\nIf the GET request does not succeed.\n\n\n\n\n\n\n\napi.design.DesignAPI.load_job(self, job_id)\nReload a Submitted job to resume from where you left off!\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\njob_id\nstr\nThe identifier of the job whose details are to be loaded.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nJob\nJob\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nHTTPError\nIf the request to the server fails.\n\n\nInvalidJob\nIf the Job is of the wrong type"
  },
  {
    "objectID": "reference/api.design.DesignAPI.html#methods",
    "href": "reference/api.design.DesignAPI.html#methods",
    "title": "api.design.DesignAPI",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ncreate_design_job\nStart a protein design job based on your assaydata, a trained ML model and Criteria (specified here).\n\n\nget_design_results\nRetrieves the results of a Design job.\n\n\nload_job\nReload a Submitted job to resume from where you left off!\n\n\n\n\n\napi.design.DesignAPI.create_design_job(self, design_job)\nStart a protein design job based on your assaydata, a trained ML model and Criteria (specified here).\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndesign_job\nDesignJobCreate\nThe details of the design job to be created, with the following parameters: - assay_id: The ID for the assay. - criteria: A list of CriterionItem lists for evaluating the design. - num_steps: The number of steps in the genetic algo. Default is 8. - pop_size: The population size for the genetic algo. Default is None. - n_offsprings: The number of offspring for the genetic algo. Default is None. - crossover_prob: The crossover probability for the genetic algo. Default is None. - crossover_prob_pointwise: The pointwise crossover probability for the genetic algo. Default is None. - mutation_average_mutations_per_seq: The average number of mutations per sequence. Default is None. - mutation_positions: A list of positions where mutations may occur. Default is None.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nDesignFuture\nThe created job as a DesignFuture instance.\n\n\n\n\n\n\n\napi.design.DesignAPI.get_design_results(self, job_id, page_size=None, page_offset=None)\nRetrieves the results of a Design job.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\njob_id\nstr\nThe ID for the design job\nrequired\n\n\npage_size\ntyping.Optional[int]\nThe number of results to be returned per page. If None, all results are returned.\nis None\n\n\npage_offset\ntyping.Optional[int]\nThe number of results to skip. If None, defaults to 0.\nis None\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nDesignJob\nThe job object representing the Design job.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nHTTPError\nIf the GET request does not succeed.\n\n\n\n\n\n\n\napi.design.DesignAPI.load_job(self, job_id)\nReload a Submitted job to resume from where you left off!\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\njob_id\nstr\nThe identifier of the job whose details are to be loaded.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nJob\nJob\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nHTTPError\nIf the request to the server fails.\n\n\nInvalidJob\nIf the Job is of the wrong type"
  },
  {
    "objectID": "reference/api.train.TrainFuture.html",
    "href": "reference/api.train.TrainFuture.html",
    "title": "api.train.TrainFuture",
    "section": "",
    "text": "api.train.TrainFuture(self, session, job, assaymetadata=None)\nFuture Job for manipulating results\n\n\n\n\n\nName\nDescription\n\n\n\n\nget_assay_data\nNOT IMPLEMENTED.\n\n\n\n\n\napi.train.TrainFuture.get_assay_data(self)\nNOT IMPLEMENTED.\nGet the assay data used for the training job.\nReturns: The assay data."
  },
  {
    "objectID": "reference/api.train.TrainFuture.html#methods",
    "href": "reference/api.train.TrainFuture.html#methods",
    "title": "api.train.TrainFuture",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nget_assay_data\nNOT IMPLEMENTED.\n\n\n\n\n\napi.train.TrainFuture.get_assay_data(self)\nNOT IMPLEMENTED.\nGet the assay data used for the training job.\nReturns: The assay data."
  },
  {
    "objectID": "reference/base.APISession.html",
    "href": "reference/base.APISession.html",
    "title": "base.APISession",
    "section": "",
    "text": "base.APISession(self, username, password, backend='https://dev.api.openprotein.ai/api/')\nConnection session.\n\n\n\n\n\nName\nDescription\n\n\n\n\nlogin\nAuthenticate connection to OpenProtein with your credentials.\n\n\n\n\n\nbase.APISession.login(self, username, password)\nAuthenticate connection to OpenProtein with your credentials.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nusername\nstr\nusername\nrequired\n\n\npassword\nstr\npassword\nrequired"
  },
  {
    "objectID": "reference/base.APISession.html#methods",
    "href": "reference/base.APISession.html#methods",
    "title": "base.APISession",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nlogin\nAuthenticate connection to OpenProtein with your credentials.\n\n\n\n\n\nbase.APISession.login(self, username, password)\nAuthenticate connection to OpenProtein with your credentials.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nusername\nstr\nusername\nrequired\n\n\npassword\nstr\npassword\nrequired"
  },
  {
    "objectID": "reference/api.poet.PoetGenerateFuture.html",
    "href": "reference/api.poet.PoetGenerateFuture.html",
    "title": "api.poet.PoetGenerateFuture",
    "section": "",
    "text": "api.poet.PoetGenerateFuture()\nRepresents a result of a PoET generation job.\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\nsession\nAPISession\nAn instance of APISession for API interactions.\n\n\njob\nJob\nThe PoET scoring job.\n\n\n\nMethods: stream() -&gt; Iterator[PoetScoreResult]: Stream the results of the PoET generation job.\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nstream\nStream the results from the response.\n\n\n\n\n\napi.poet.PoetGenerateFuture.stream(self)\nStream the results from the response.\n\n\n\n\n\nType\nDescription\n\n\n\n\nYield\nA result object containing the sequence, score, and name.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nAPIError\nIf the request fails."
  },
  {
    "objectID": "reference/api.poet.PoetGenerateFuture.html#attributes",
    "href": "reference/api.poet.PoetGenerateFuture.html#attributes",
    "title": "api.poet.PoetGenerateFuture",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\nsession\nAPISession\nAn instance of APISession for API interactions.\n\n\njob\nJob\nThe PoET scoring job.\n\n\n\nMethods: stream() -&gt; Iterator[PoetScoreResult]: Stream the results of the PoET generation job."
  },
  {
    "objectID": "reference/api.poet.PoetGenerateFuture.html#methods",
    "href": "reference/api.poet.PoetGenerateFuture.html#methods",
    "title": "api.poet.PoetGenerateFuture",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nstream\nStream the results from the response.\n\n\n\n\n\napi.poet.PoetGenerateFuture.stream(self)\nStream the results from the response.\n\n\n\n\n\nType\nDescription\n\n\n\n\nYield\nA result object containing the sequence, score, and name.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nAPIError\nIf the request fails."
  },
  {
    "objectID": "reference/api.train.TrainingAPI.html",
    "href": "reference/api.train.TrainingAPI.html",
    "title": "api.train.TrainingAPI",
    "section": "",
    "text": "api.train.TrainingAPI(self, session)\nAPI interface for calling Train endpoints\n\n\n\n\n\nName\nDescription\n\n\n\n\ncreate_training_job\nCreate a training job on your data.\n\n\nget_training_results\nGet training results (e.g. loss etc).\n\n\nload_job\nReload a Submitted job to resume from where you left off!\n\n\n\n\n\napi.train.TrainingAPI.create_training_job(self, assaydataset, measurement_name, model_name='', force_preprocess=False)\nCreate a training job on your data.\nThis function validates the inputs, formats the data, and sends the job.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nassaydataset\nAssayDataset\nAn AssayDataset object from which the assay_id is extracted.\nrequired\n\n\nmeasurement_name\nstr or typing.List[str]\nThe name(s) of the measurement(s) to be used in the training job.\nrequired\n\n\nmodel_name\nstr\nThe name to give the model.\n''\n\n\nforce_preprocess\nbool\nIf set to True, preprocessing is forced even if data already exists.\nFalse\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nTrainFuture\nA TrainFuture Job\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nInvalidParameterError\nIf the assaydataset is not an AssayDataset object, If any measurement name provided does not exist in the AssayDataset, or if the AssayDataset has fewer than 3 data points.\n\n\nHTTPError\nIf the request to the server fails.\n\n\n\n\n\n\n\napi.train.TrainingAPI.get_training_results(self, job_id)\nGet training results (e.g. loss etc).\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\njob_id\nstr\njob_id to get\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nTrainFuture\nA TrainFuture Job\n\n\n\n\n\n\n\napi.train.TrainingAPI.load_job(self, job_id)\nReload a Submitted job to resume from where you left off!\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\njob_id\nstr\nThe identifier of the job whose details are to be loaded.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nJob\nJob\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nHTTPError\nIf the request to the server fails.\n\n\nInvalidJob\nIf the Job is of the wrong type"
  },
  {
    "objectID": "reference/api.train.TrainingAPI.html#methods",
    "href": "reference/api.train.TrainingAPI.html#methods",
    "title": "api.train.TrainingAPI",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ncreate_training_job\nCreate a training job on your data.\n\n\nget_training_results\nGet training results (e.g. loss etc).\n\n\nload_job\nReload a Submitted job to resume from where you left off!\n\n\n\n\n\napi.train.TrainingAPI.create_training_job(self, assaydataset, measurement_name, model_name='', force_preprocess=False)\nCreate a training job on your data.\nThis function validates the inputs, formats the data, and sends the job.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nassaydataset\nAssayDataset\nAn AssayDataset object from which the assay_id is extracted.\nrequired\n\n\nmeasurement_name\nstr or typing.List[str]\nThe name(s) of the measurement(s) to be used in the training job.\nrequired\n\n\nmodel_name\nstr\nThe name to give the model.\n''\n\n\nforce_preprocess\nbool\nIf set to True, preprocessing is forced even if data already exists.\nFalse\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nTrainFuture\nA TrainFuture Job\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nInvalidParameterError\nIf the assaydataset is not an AssayDataset object, If any measurement name provided does not exist in the AssayDataset, or if the AssayDataset has fewer than 3 data points.\n\n\nHTTPError\nIf the request to the server fails.\n\n\n\n\n\n\n\napi.train.TrainingAPI.get_training_results(self, job_id)\nGet training results (e.g. loss etc).\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\njob_id\nstr\njob_id to get\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nTrainFuture\nA TrainFuture Job\n\n\n\n\n\n\n\napi.train.TrainingAPI.load_job(self, job_id)\nReload a Submitted job to resume from where you left off!\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\njob_id\nstr\nThe identifier of the job whose details are to be loaded.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nJob\nJob\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nHTTPError\nIf the request to the server fails.\n\n\nInvalidJob\nIf the Job is of the wrong type"
  },
  {
    "objectID": "reference/api.embedding.EmbeddingAPI.html",
    "href": "reference/api.embedding.EmbeddingAPI.html",
    "title": "api.embedding.EmbeddingAPI",
    "section": "",
    "text": "api.embedding.EmbeddingAPI(self, session)\nThis class defines a high level interface for accessing the embeddings API.\n\n\n\n\n\nName\nDescription\n\n\n\n\ndelete_svd\nDelete SVD model.\n\n\nembed\nEmbed sequences using the specified model.\n\n\nfit_svd\nFit an SVD on the sequences with the specified model_id and hyperparameters (n_components).\n\n\nget_model\nGet model by model_id.\n\n\nget_results\nRetrieves the results of an embedding job.\n\n\nget_svd\nGet SVD job results. Including SVD dimension and sequence lengths.\n\n\nget_svd_results\nGet SVD job results. Including SVD dimension and sequence lengths.\n\n\nlist_models\nlist models available for creating embeddings of your sequences\n\n\nlist_svd\nList SVD models made by user.\n\n\nload_job\nReload a Submitted job to resume from where you left off!\n\n\n\n\n\napi.embedding.EmbeddingAPI.delete_svd(self, svd_id)\nDelete SVD model.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsvd_id\nstr\nThe ID of the SVD job.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nbool\nTrue: successful deletion\n\n\n\n\n\n\n\napi.embedding.EmbeddingAPI.embed(self, model, sequences, reduction='MEAN')\nEmbed sequences using the specified model.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmodel\ntyping.Union[openprotein.api.embedding.ProtembedModel, openprotein.api.embedding.SVDModel, str]\nThe model to use for embedding. This can be an instance of ProtembedModel, SVDModel, or a string representing the model_id.\nrequired\n\n\nsequences\ntyping.List[bytes]\nList of byte sequences to be embedded.\nrequired\n\n\nreduction\nstr\nThe reduction operation to be applied on the embeddings. Options are None, “MEAN”, or “SUM”. Default is None.\n'MEAN'\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nEmbeddingResultFuture\nAn instance of EmbeddingResultFuture\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nTypeError\nIf the input model is neither ProtembedModel, SVDModel, nor str.\n\n\n\n\n\n\n\napi.embedding.EmbeddingAPI.fit_svd(self, model_id, sequences, n_components=1024, reduction=None)\nFit an SVD on the sequences with the specified model_id and hyperparameters (n_components).\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmodel_id\nstr\nThe ID of the model to fit the SVD on.\nrequired\n\n\nsequences\ntyping.List[bytes]\nThe list of sequences to use for the SVD fitting.\nrequired\n\n\nn_components\nint\nThe number of components for the SVD, by default 1024.\n1024\n\n\nreduction\ntyping.Optional[str]\nThe reduction method to apply to the embeddings, by default None.\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nSVDModel\nThe model with the SVD fit.\n\n\n\n\n\n\n\napi.embedding.EmbeddingAPI.get_model(self, model_id)\nGet model by model_id.\nProtembedModel allows all the usual job manipulation: e.g. making POST and GET requests for this model specifically.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmodel_id\nstr\nthe model identifier\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nProtembedModel\nThe model\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nHTTPError\nIf the GET request does not succeed.\n\n\n\n\n\n\n\napi.embedding.EmbeddingAPI.get_results(self, job)\nRetrieves the results of an embedding job.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\njob\nJob\nThe embedding job whose results are to be retrieved.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nEmbeddingResultFuture\nAn instance of EmbeddingResultFuture\n\n\n\n\n\n\n\napi.embedding.EmbeddingAPI.get_svd(self, svd_id)\nGet SVD job results. Including SVD dimension and sequence lengths.\nRequires a successful SVD job from fit_svd\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsvd_id\nstr\nThe ID of the SVD job.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nSVDModel\nThe model with the SVD fit.\n\n\n\n\n\n\n\napi.embedding.EmbeddingAPI.get_svd_results(self, job)\nGet SVD job results. Including SVD dimension and sequence lengths.\nRequires a successful SVD job from fit_svd\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\njob\nJob\nSVD JobFuture\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nSVDModel\nThe model with the SVD fit.\n\n\n\n\n\n\n\napi.embedding.EmbeddingAPI.list_models(self)\nlist models available for creating embeddings of your sequences\n\n\n\napi.embedding.EmbeddingAPI.list_svd(self)\nList SVD models made by user.\nTakes no args.\n\n\n\n\n\nType\nDescription\n\n\n\n\nlist[openprotein.api.embedding.SVDModel]\nSVDModels\n\n\n\n\n\n\n\napi.embedding.EmbeddingAPI.load_job(self, job_id)\nReload a Submitted job to resume from where you left off!\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\njob_id\nstr\nThe identifier of the job whose details are to be loaded.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nJob\nJob\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nHTTPError\nIf the request to the server fails.\n\n\nInvalidJob\nIf the Job is of the wrong type"
  },
  {
    "objectID": "reference/api.embedding.EmbeddingAPI.html#methods",
    "href": "reference/api.embedding.EmbeddingAPI.html#methods",
    "title": "api.embedding.EmbeddingAPI",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ndelete_svd\nDelete SVD model.\n\n\nembed\nEmbed sequences using the specified model.\n\n\nfit_svd\nFit an SVD on the sequences with the specified model_id and hyperparameters (n_components).\n\n\nget_model\nGet model by model_id.\n\n\nget_results\nRetrieves the results of an embedding job.\n\n\nget_svd\nGet SVD job results. Including SVD dimension and sequence lengths.\n\n\nget_svd_results\nGet SVD job results. Including SVD dimension and sequence lengths.\n\n\nlist_models\nlist models available for creating embeddings of your sequences\n\n\nlist_svd\nList SVD models made by user.\n\n\nload_job\nReload a Submitted job to resume from where you left off!\n\n\n\n\n\napi.embedding.EmbeddingAPI.delete_svd(self, svd_id)\nDelete SVD model.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsvd_id\nstr\nThe ID of the SVD job.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nbool\nTrue: successful deletion\n\n\n\n\n\n\n\napi.embedding.EmbeddingAPI.embed(self, model, sequences, reduction='MEAN')\nEmbed sequences using the specified model.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmodel\ntyping.Union[openprotein.api.embedding.ProtembedModel, openprotein.api.embedding.SVDModel, str]\nThe model to use for embedding. This can be an instance of ProtembedModel, SVDModel, or a string representing the model_id.\nrequired\n\n\nsequences\ntyping.List[bytes]\nList of byte sequences to be embedded.\nrequired\n\n\nreduction\nstr\nThe reduction operation to be applied on the embeddings. Options are None, “MEAN”, or “SUM”. Default is None.\n'MEAN'\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nEmbeddingResultFuture\nAn instance of EmbeddingResultFuture\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nTypeError\nIf the input model is neither ProtembedModel, SVDModel, nor str.\n\n\n\n\n\n\n\napi.embedding.EmbeddingAPI.fit_svd(self, model_id, sequences, n_components=1024, reduction=None)\nFit an SVD on the sequences with the specified model_id and hyperparameters (n_components).\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmodel_id\nstr\nThe ID of the model to fit the SVD on.\nrequired\n\n\nsequences\ntyping.List[bytes]\nThe list of sequences to use for the SVD fitting.\nrequired\n\n\nn_components\nint\nThe number of components for the SVD, by default 1024.\n1024\n\n\nreduction\ntyping.Optional[str]\nThe reduction method to apply to the embeddings, by default None.\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nSVDModel\nThe model with the SVD fit.\n\n\n\n\n\n\n\napi.embedding.EmbeddingAPI.get_model(self, model_id)\nGet model by model_id.\nProtembedModel allows all the usual job manipulation: e.g. making POST and GET requests for this model specifically.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmodel_id\nstr\nthe model identifier\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nProtembedModel\nThe model\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nHTTPError\nIf the GET request does not succeed.\n\n\n\n\n\n\n\napi.embedding.EmbeddingAPI.get_results(self, job)\nRetrieves the results of an embedding job.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\njob\nJob\nThe embedding job whose results are to be retrieved.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nEmbeddingResultFuture\nAn instance of EmbeddingResultFuture\n\n\n\n\n\n\n\napi.embedding.EmbeddingAPI.get_svd(self, svd_id)\nGet SVD job results. Including SVD dimension and sequence lengths.\nRequires a successful SVD job from fit_svd\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsvd_id\nstr\nThe ID of the SVD job.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nSVDModel\nThe model with the SVD fit.\n\n\n\n\n\n\n\napi.embedding.EmbeddingAPI.get_svd_results(self, job)\nGet SVD job results. Including SVD dimension and sequence lengths.\nRequires a successful SVD job from fit_svd\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\njob\nJob\nSVD JobFuture\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nSVDModel\nThe model with the SVD fit.\n\n\n\n\n\n\n\napi.embedding.EmbeddingAPI.list_models(self)\nlist models available for creating embeddings of your sequences\n\n\n\napi.embedding.EmbeddingAPI.list_svd(self)\nList SVD models made by user.\nTakes no args.\n\n\n\n\n\nType\nDescription\n\n\n\n\nlist[openprotein.api.embedding.SVDModel]\nSVDModels\n\n\n\n\n\n\n\napi.embedding.EmbeddingAPI.load_job(self, job_id)\nReload a Submitted job to resume from where you left off!\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\njob_id\nstr\nThe identifier of the job whose details are to be loaded.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nJob\nJob\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nHTTPError\nIf the request to the server fails.\n\n\nInvalidJob\nIf the Job is of the wrong type"
  },
  {
    "objectID": "reference/api.design.DesignFuture.html",
    "href": "reference/api.design.DesignFuture.html",
    "title": "api.design.DesignFuture",
    "section": "",
    "text": "api.design.DesignFuture(self, session, job, page_size=1000)\nFuture Job for manipulating results\n\n\n\n\n\nName\nDescription\n\n\n\n\nget\nGet all the results of the design job.\n\n\n\n\n\napi.design.DesignFuture.get(self, verbose=False)\nGet all the results of the design job.\nArgs: verbose (bool, optional): If True, print verbose output. Defaults False.\nRaises: APIError: If there is an issue with the API request.\nReturns: DesignJob: A list of predict objects representing the results."
  },
  {
    "objectID": "reference/api.design.DesignFuture.html#methods",
    "href": "reference/api.design.DesignFuture.html#methods",
    "title": "api.design.DesignFuture",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nget\nGet all the results of the design job.\n\n\n\n\n\napi.design.DesignFuture.get(self, verbose=False)\nGet all the results of the design job.\nArgs: verbose (bool, optional): If True, print verbose output. Defaults False.\nRaises: APIError: If there is an issue with the API request.\nReturns: DesignJob: A list of predict objects representing the results."
  },
  {
    "objectID": "reference/api.embedding.EmbeddingResultFuture.html",
    "href": "reference/api.embedding.EmbeddingResultFuture.html",
    "title": "api.embedding.EmbeddingResultFuture",
    "section": "",
    "text": "api.embedding.EmbeddingResultFuture(self, session, job, sequences=None, max_workers=config.MAX_CONCURRENT_WORKERS)\nFuture Job for manipulating results\n\n\n\n\n\nName\nDescription\n\n\n\n\nget_item\nGet embedding results for specified sequence.\n\n\n\n\n\napi.embedding.EmbeddingResultFuture.get_item(self, sequence)\nGet embedding results for specified sequence.\nArgs: sequence (bytes): sequence to fetch results for\nReturns: np.ndarray: embeddings"
  },
  {
    "objectID": "reference/api.embedding.EmbeddingResultFuture.html#methods",
    "href": "reference/api.embedding.EmbeddingResultFuture.html#methods",
    "title": "api.embedding.EmbeddingResultFuture",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nget_item\nGet embedding results for specified sequence.\n\n\n\n\n\napi.embedding.EmbeddingResultFuture.get_item(self, sequence)\nGet embedding results for specified sequence.\nArgs: sequence (bytes): sequence to fetch results for\nReturns: np.ndarray: embeddings"
  },
  {
    "objectID": "reference/api.embedding.SVDModel.html",
    "href": "reference/api.embedding.SVDModel.html",
    "title": "api.embedding.SVDModel",
    "section": "",
    "text": "api.embedding.SVDModel(self, session, metadata)\nClass providing embedding endpoint for SVD models. Also allows retrieving embeddings of sequences used to fit the SVD with get.\n\n\n\n\n\nName\nDescription\n\n\n\n\ndelete\nDelete this SVD model.\n\n\nembed\nUse this SVD model to reduce embeddings results.\n\n\nget_embeddings\nGet SVD embedding results for this model.\n\n\nget_inputs\nGet sequences used for embeddings job.\n\n\nget_job\nGet job associated with this SVD model\n\n\nget_model\nFetch embeddings model\n\n\n\n\n\napi.embedding.SVDModel.delete(self)\nDelete this SVD model.\n\n\n\napi.embedding.SVDModel.embed(self, sequences)\nUse this SVD model to reduce embeddings results.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsequences\ntyping.List[bytes]\nList of protein sequences.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nEmbeddingResultFuture\nClass for further job manipulation.\n\n\n\n\n\n\n\napi.embedding.SVDModel.get_embeddings(self)\nGet SVD embedding results for this model.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nEmbeddingResultFuture: class for futher job manipulation\n\n\n\n\n\n\n\n\napi.embedding.SVDModel.get_inputs(self)\nGet sequences used for embeddings job.\n\n\n\n\n\nType\nDescription\n\n\n\n\nList[bytes]: list of sequences\n\n\n\n\n\n\n\n\napi.embedding.SVDModel.get_job(self)\nGet job associated with this SVD model\n\n\n\napi.embedding.SVDModel.get_model(self)\nFetch embeddings model"
  },
  {
    "objectID": "reference/api.embedding.SVDModel.html#methods",
    "href": "reference/api.embedding.SVDModel.html#methods",
    "title": "api.embedding.SVDModel",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ndelete\nDelete this SVD model.\n\n\nembed\nUse this SVD model to reduce embeddings results.\n\n\nget_embeddings\nGet SVD embedding results for this model.\n\n\nget_inputs\nGet sequences used for embeddings job.\n\n\nget_job\nGet job associated with this SVD model\n\n\nget_model\nFetch embeddings model\n\n\n\n\n\napi.embedding.SVDModel.delete(self)\nDelete this SVD model.\n\n\n\napi.embedding.SVDModel.embed(self, sequences)\nUse this SVD model to reduce embeddings results.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsequences\ntyping.List[bytes]\nList of protein sequences.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nEmbeddingResultFuture\nClass for further job manipulation.\n\n\n\n\n\n\n\napi.embedding.SVDModel.get_embeddings(self)\nGet SVD embedding results for this model.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nEmbeddingResultFuture: class for futher job manipulation\n\n\n\n\n\n\n\n\napi.embedding.SVDModel.get_inputs(self)\nGet sequences used for embeddings job.\n\n\n\n\n\nType\nDescription\n\n\n\n\nList[bytes]: list of sequences\n\n\n\n\n\n\n\n\napi.embedding.SVDModel.get_job(self)\nGet job associated with this SVD model\n\n\n\napi.embedding.SVDModel.get_model(self)\nFetch embeddings model"
  },
  {
    "objectID": "notebooks/core_demo.html",
    "href": "notebooks/core_demo.html",
    "title": "Demo of Core workflow functionality",
    "section": "",
    "text": "%matplotlib inline\nThis notebook will briefly cover how to run assaydata, train, predict, design workflows.\nFor more information please read the docs.\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport time\nimport json\nimport pandas as pd\nimport seaborn as sns \nsns.set() \n\nfrom AWSTools.Batchtools.batch_utils import fakeseq # Used for creating fake protein sequences for testing"
  },
  {
    "objectID": "notebooks/core_demo.html#setup",
    "href": "notebooks/core_demo.html#setup",
    "title": "Demo of Core workflow functionality",
    "section": "Setup",
    "text": "Setup\nConnect to the OpenProtein backend with your credentials:\n\nimport openprotein\n\nwith open('secrets.config', 'r') as f:\n    config = json.load(f)\n\nsession = openprotein.connect(username= config['username'], password= config['password'], backend= \"https://dev.api.openprotein.ai/api/\") \nprint(session.backend)\n\nhttps://dev.api.openprotein.ai/api/\n\n\nLoad some demo data:\n\ndataset = pd.read_csv(\"./demo_data/core.csv\")\ndataset.head(2)\n\n\n\n\n\n\n\n\nsequence\nisobutyramide_normalized_fitness\nacetamide_normalized_fitness\npropionamide_normalized_fitness\n\n\n\n\n0\nWRHGDISSSNDTVGVAVVNYKMPRLHTAAEVLDNARKIAEMIVGMK...\n-0.5174\nNaN\nNaN\n\n\n1\nWRHGDISSSNDTVGVAVVNYKMPRLHTAAEVLDNARKIAEMIVGMK...\n-0.5154\n-2.1514\n-1.1457"
  },
  {
    "objectID": "notebooks/core_demo.html#data-upload",
    "href": "notebooks/core_demo.html#data-upload",
    "title": "Demo of Core workflow functionality",
    "section": "Data Upload",
    "text": "Data Upload\nCreate the Demo data in the backend to be able to use it with our suite of tools:\n\n# Create\nassay = session.data.create(dataset, \"Dataset Name\", \"Dataset description\")\nassay_id = assay.id\nassay\n\nAssayMetadata(assay_name='Dataset Name', assay_description='Dataset description', assay_id='dbf85fa1-12ff-45e7-b5a5-2e93e888a6ac', original_filename='assay_data', created_date=datetime.datetime(2023, 7, 28, 1, 41, 47, 332556), num_rows=15, num_entries=41, measurement_names=['isobutyramide_normalized_fitness', 'acetamide_normalized_fitness', 'propionamide_normalized_fitness'], sequence_length=346)\n\n\nWe could also have loaded a job from an old job ID. This will be faster and more efficient for users resuming workflows:\n\nassay = session.data.load_job(assay_id) # can reload job to resume workflows\n\n\nassay.get_first()\n\n\n\n\n\n\n\n\nsequence\nisobutyramide_normalized_fitness\nacetamide_normalized_fitness\npropionamide_normalized_fitness\n\n\n\n\n0\nWRHGDISSSNDTVGVAVVNYKMPRLHTAAEVLDNARKIAEMIVGMK...\n-0.5174\nNone\nNone\n\n\n\n\n\n\n\n\nassay.get_slice(start=3, end=5)\n\n\n\n\n\n\n\n\nsequence\nisobutyramide_normalized_fitness\nacetamide_normalized_fitness\npropionamide_normalized_fitness\n\n\n\n\n0\nMRHGDISSSNDTVGVAVVNYKMPRLHTAAEVLDNARKWAEMIVGMK...\nNaN\nNaN\n-0.7550\n\n\n1\nMRHGDISSSNDTVGVAVVNYKMPRLHTAAEVLDNARKYAEMIVGMK...\n-0.7448\n-1.7992\n-0.9711\n\n\n\n\n\n\n\n\nassay.sequence_length\n\n346"
  },
  {
    "objectID": "notebooks/core_demo.html#model-training",
    "href": "notebooks/core_demo.html#model-training",
    "title": "Demo of Core workflow functionality",
    "section": "Model training",
    "text": "Model training\nWe can use the assay object to create a training job:\n\ntrain = session.train.create_training_job(assay,\n                                          measurement_name=[\"isobutyramide_normalized_fitness\", \"acetamide_normalized_fitness\"],\n                                          model_name=\"mymodel\") # name the resulting model\ntrain_id = train.id\ntrain\n\nJobplus(status=&lt;JobStatus.PENDING: 'PENDING'&gt;, job_id='d292d4de-392f-4fc8-9e45-7d3938f63902', job_type='/workflow/train', created_date=datetime.datetime(2023, 7, 28, 1, 41, 47, 762130), start_date=None, end_date=None, prerequisite_job_id='6ba74592-91ac-47e4-9ea7-59fa0fc199fb', progress_message=None, progress_counter=None, num_records=None, sequence_length=346)\n\n\n\n#train = session.train.load_job(train_id)\n#train\n\n\ntrain.refresh()\ntrain.status\n\n&lt;JobStatus.PENDING: 'PENDING'&gt;\n\n\nWe can wait for the results before proceeding:\n\nresults = train.wait(verbose=False)\n\n\nisobut_results = [i for i in results.traingraph if i.tag==\"isobutyramide_normalized_fitness\"]\nsns.scatterplot(x=[i.step for i in isobut_results], y=[i.loss for i in isobut_results])\nplt.xlabel(\"Steps\")\nplt.ylabel(\"Loss\");\n\n\n\n\nWe can also request a cross-validation job to see the training results in more detail:\n\ntrain.crossvalidate()\ntrain.crossvalidation.id\n\n'e12e7cc5-89e7-4c22-9958-2366243b196e'\n\n\n\ncvdata = train.crossvalidation.wait()\n\n\ncvresult = [i for i in cvdata if i.measurement_name == \"isobutyramide_normalized_fitness\"]\n\nsns.regplot(x=[i.y for i in cvresult], y=[i.y_mu for i in cvresult])\nplt.xlabel(\"Y\")\nplt.ylabel(\"Y-hat\");\n\n\n\n\nWe can examine the models associated with a train or assaydata set. These will be identical here but multiple train jobs are possible on a single assaydata:\n\ntrain.list_models()\n\n[{'name': 'mymodel - acetamide_normalized_fitness',\n  'description': '',\n  'model_id': '4f5a95cc-7cd9-4d19-bd2c-768c93d8d217',\n  'training_assaydata': 'dbf85fa1-12ff-45e7-b5a5-2e93e888a6ac',\n  'job_id': 'd292d4de-392f-4fc8-9e45-7d3938f63902',\n  'created_date': '2023-07-28T01:43:16.966824',\n  'model_type': 'EXACT_GP',\n  'additional_metadata': {'input_dims': 13,\n   'embedding_model': 'TorchLowRankSVD',\n   'sequence_length': 346,\n   'projection_layer': 'dbf85fa1-12ff-45e7-b5a5-2e93e888a6ac_pca.joblib',\n   'measurement_names': ['acetamide_normalized_fitness'],\n   'original_task_index': 1}},\n {'name': 'mymodel - isobutyramide_normalized_fitness',\n  'description': '',\n  'model_id': 'd292d4de-392f-4fc8-9e45-7d3938f63902',\n  'training_assaydata': 'dbf85fa1-12ff-45e7-b5a5-2e93e888a6ac',\n  'job_id': 'd292d4de-392f-4fc8-9e45-7d3938f63902',\n  'created_date': '2023-07-28T01:43:16.327287',\n  'model_type': 'EXACT_GP',\n  'additional_metadata': {'input_dims': 13,\n   'embedding_model': 'TorchLowRankSVD',\n   'sequence_length': 346,\n   'projection_layer': 'dbf85fa1-12ff-45e7-b5a5-2e93e888a6ac_pca.joblib',\n   'measurement_names': ['isobutyramide_normalized_fitness'],\n   'original_task_index': 0}}]\n\n\n\nassay.list_models()\n\n[{'name': 'mymodel - acetamide_normalized_fitness',\n  'description': '',\n  'model_id': '4f5a95cc-7cd9-4d19-bd2c-768c93d8d217',\n  'training_assaydata': 'dbf85fa1-12ff-45e7-b5a5-2e93e888a6ac',\n  'job_id': 'd292d4de-392f-4fc8-9e45-7d3938f63902',\n  'created_date': '2023-07-28T01:43:16.966824',\n  'model_type': 'EXACT_GP',\n  'additional_metadata': {'input_dims': 13,\n   'embedding_model': 'TorchLowRankSVD',\n   'sequence_length': 346,\n   'projection_layer': 'dbf85fa1-12ff-45e7-b5a5-2e93e888a6ac_pca.joblib',\n   'measurement_names': ['acetamide_normalized_fitness'],\n   'original_task_index': 1}},\n {'name': 'mymodel - isobutyramide_normalized_fitness',\n  'description': '',\n  'model_id': 'd292d4de-392f-4fc8-9e45-7d3938f63902',\n  'training_assaydata': 'dbf85fa1-12ff-45e7-b5a5-2e93e888a6ac',\n  'job_id': 'd292d4de-392f-4fc8-9e45-7d3938f63902',\n  'created_date': '2023-07-28T01:43:16.327287',\n  'model_type': 'EXACT_GP',\n  'additional_metadata': {'input_dims': 13,\n   'embedding_model': 'TorchLowRankSVD',\n   'sequence_length': 346,\n   'projection_layer': 'dbf85fa1-12ff-45e7-b5a5-2e93e888a6ac_pca.joblib',\n   'measurement_names': ['isobutyramide_normalized_fitness'],\n   'original_task_index': 0}}]\n\n\nLet’s take one of these models for further use:\n\nmodel_id = train.list_models()[0]['model_id']\ntrain.list_models()[0]\n\n{'name': 'mymodel - acetamide_normalized_fitness',\n 'description': '',\n 'model_id': '4f5a95cc-7cd9-4d19-bd2c-768c93d8d217',\n 'training_assaydata': 'dbf85fa1-12ff-45e7-b5a5-2e93e888a6ac',\n 'job_id': 'd292d4de-392f-4fc8-9e45-7d3938f63902',\n 'created_date': '2023-07-28T01:43:16.966824',\n 'model_type': 'EXACT_GP',\n 'additional_metadata': {'input_dims': 13,\n  'embedding_model': 'TorchLowRankSVD',\n  'sequence_length': 346,\n  'projection_layer': 'dbf85fa1-12ff-45e7-b5a5-2e93e888a6ac_pca.joblib',\n  'measurement_names': ['acetamide_normalized_fitness'],\n  'original_task_index': 1}}"
  },
  {
    "objectID": "notebooks/core_demo.html#sequence-design",
    "href": "notebooks/core_demo.html#sequence-design",
    "title": "Demo of Core workflow functionality",
    "section": "Sequence design",
    "text": "Sequence design\nWe can set up a design job using our trained model as a criteria:\n\nfrom openprotein.models import DesignJobCreate, ModelCriterion, NMutationCriterion, Criterion\ndesign_data = DesignJobCreate(\n    assay_id=assay.id,\n    criteria=[\n        [\n            ModelCriterion(\n                criterion_type='model',\n                model_id=model_id,\n                measurement_name=\"acetamide_normalized_fitness\",\n                criterion=Criterion(target=-0.5, weight=1.0, direction=\"&lt;\")\n            ),\n        ],\n        [NMutationCriterion(criterion_type=\"n_mutations\", )]\n    ],\n    mutation_positions=[2,13],\n    num_steps=10\n)\n\n\njson.loads(design_data.json())\n\n\n{'assay_id': 'dbf85fa1-12ff-45e7-b5a5-2e93e888a6ac',\n 'criteria': [[{'criterion_type': 'model',\n    'model_id': '4f5a95cc-7cd9-4d19-bd2c-768c93d8d217',\n    'measurement_name': 'acetamide_normalized_fitness',\n    'criterion': {'target': -0.5, 'weight': 1.0, 'direction': '&lt;'}}],\n  [{'criterion_type': 'n_mutations'}]],\n 'num_steps': 10,\n 'pop_size': None,\n 'n_offsprings': None,\n 'crossover_prob': None,\n 'crossover_prob_pointwise': None,\n 'mutation_average_mutations_per_seq': None,\n 'mutation_positions': [2, 13]}\n\n\n\n# create the design job\ndesign_job = session.design.create_design_job(design_data)\ndesign_id = design_job.id\ndesign_job\n\nJob(status=&lt;JobStatus.PENDING: 'PENDING'&gt;, job_id='e1826033-583b-4581-a602-9ceff483c8e0', job_type='/workflow/design', created_date=datetime.datetime(2023, 7, 28, 1, 43, 24, 642996), start_date=None, end_date=None, prerequisite_job_id=None, progress_message=None, progress_counter=None, num_records=None)\n\n\n\n\n#design_job = session.design.load_job(design_id)\n\n\nresults = design_job.wait()\nresults[-3:]\n\n[DesignStep(step=9, sample_index=2557, sequence='MRHGDIMSSNMTVGVAVVFPKMPRDRSGEWRLDNADKIKYMTAGMKRKQQQYQLVVEPIRVWQGQMWDYAEYTEQMCYIPGCETSIHSDACKKVNVWGVYSLMGEKHEEHIDKAQYYTCDLIDMDGTFADKYYKISPWYQIEQWYWGQQDYVSRDPVDMKIYLAFCDCHNYPEIWYDTAMKGAYCCVPCNGSMQPAKDDEQQMAKAMQWCHNCYVEVKNMASGSGVQSDFRVSASIIFDQRIVAETGCTEMCIQYAQLSLSDQRYARCEPQSINKQFTIQMRGYSGLQASGDGDRPLIACPRHFVRTYVGTRVIYRESVHGNIRSTTGSAQADVGAWEYKMYENDA', initial_scores=[0, 195], scores=[[DesignSubscore(score=0, metadata=DesignMetadata(y_mu=-1.052383542060852, y_var=0.008722011931240559))], [DesignSubscore(score=195, metadata=DesignMetadata(y_mu=None, y_var=None))]], umap1=0.5089479088783264, umap2=8.538457870483398),\n DesignStep(step=9, sample_index=2558, sequence='RRHGDISSNWDTYGVRVVNYTCPRLGHWAEVLANAPNCPGQILGMRLMLRGATGGRCPMYSLMGIMLTCAERMLTAQACVSETVHDFSEACRVATVWGVFKAGTQRCEECGIKGPYNCLVLIPQNGEAQQCYRKILLPCPMEGDYAQTQTYDSANPKGFESSQNHCRDPNEPSEWRDCASFGAELIVRCQGYRYPAKQIWPMNPKNMRWANNWYTGVANAACRDPHESIFPHSMIRGFDGRTWGYQGWEECITQCFQESLQQILSCRANDQSQNETFKIVKRSWRVLQALKRGDRGLNELCFRFYRTWVNDCPKARENVGRLTRSSPGCAQWSVGGLNYWGLEHRA', initial_scores=[0, 196], scores=[[DesignSubscore(score=0, metadata=DesignMetadata(y_mu=-1.052383542060852, y_var=0.008722011931240559))], [DesignSubscore(score=196, metadata=DesignMetadata(y_mu=None, y_var=None))]], umap1=0.4868474304676056, umap2=8.431281089782715),\n DesignStep(step=9, sample_index=2559, sequence='MRHGDISSSNDTVGVAVVNYKMPRLHTAAEVLDNARKLAEMIVGMKQGLPGMDLVVFPEYSLQGIMYDPAEMMETAVAIPGEETEIFSRACRKANVWGVFSLTGERHEEHPRKAPYNTLVLIDNNGEIVQKYRKIIPWCPIEGWYPGGQTYVSEGPKGMKISLIICDDGNYPEIWRDCAMKGAELIVRCQGYMYPAKDQQVMMAKAMAWANNCYVAVANAAGFDGVYSYFGHSAIIGFDGRTLGECGEEEMGIQYAQLSLSQIRDARANDQSQNHLFKILHRGYSGLQASGDGDRGLAECPFEFYRTWVTDAEKARENVERLTRSTTGVAQCPVGRLPYEGLEKEA', initial_scores=[0, 346], scores=[[DesignSubscore(score=0, metadata=DesignMetadata(y_mu=-1.0225590467453003, y_var=0.008469139225780964))], [DesignSubscore(score=346, metadata=DesignMetadata(y_mu=None, y_var=None))]], umap1=4.1282830238342285, umap2=6.924859046936035)]\n\n\nWe can access the design results:\n\nresults[-1].scores\n\n[[DesignSubscore(score=0, metadata=DesignMetadata(y_mu=-1.0225590467453003, y_var=0.008469139225780964))],\n [DesignSubscore(score=346, metadata=DesignMetadata(y_mu=None, y_var=None))]]"
  },
  {
    "objectID": "notebooks/core_demo.html#sequence-predictions",
    "href": "notebooks/core_demo.html#sequence-predictions",
    "title": "Demo of Core workflow functionality",
    "section": "Sequence predictions",
    "text": "Sequence predictions\nWe can also predict scores for new sequences using our models trained on our old sequences:\n\n# Create some random sequences to predict\nnp.random.seed(111)\np_seqs = [fakeseq(assay.sequence_length) for i in range(3)]\np_seqs\n\n['MVINYHGGMLRTPNHQMEMFQPEFYKCDGILVREQCWLKKWGGIPEFHARIMDCFQQQARMAGNKPIGYKHLYLLHMWCFEVIQAFTNQIAYGKQLPGDHPRTNWYHFEHTMNCNPQLHFTSGSLYRSTMEKLAYSCNYTYCVQTHMYYHRREVIEMLSPSNPARTARHHPHVDMELQIIINVENQVVIPTDWNPWWIRIMCIEPDRWDCMQKKDKVFSTHFRNINVCIRPEHRDDIFDEMYCKYPHRVECQHFSGWKGLPNINPHHRTFTTCGMDPPRMWCLRKVWIDTGKYPAFYSEAQGQFQCPKYEKDAYAKGFRTELGHEISSQYEVGNFTMTNQAIAGLA',\n 'QRMNDISWFCLAEWYWYKKEWILMFLCDTDGDENQAKCQQINVQIIIYVPSRAVVEIMEALFVMSAHLYWYTAVADNFLLDSHLLDGRDNTTFMIIGTRQWSIVHRSGLSYYKQNDLSNKLQMQKRRLLMPEMWWIRNWPWLQLVLNMENARHTGYYHQSRNGVWQWIDLLEAQRGCHQRGYVNTRQALFFAADHQLWDHTIIYTVQWEPAHQKDDQVRKMICAEYDCIIVKSSAYCFCNFQFHQKEFGFKCFIVSHGALSLTYLHYVVFRPKEEPHWHGTISACKDDRPYGLWLMGTPPYFWAPSGKLANWNMMEPCETQDCFANNYPESWLKFWWVMTTGSKPS',\n 'NSIMWHDIKCPRMMQWAWHVDNVATEVNTYNGDQTKGNGKFAHAQPSHFPYMFFWQMAIMGYHIDAAFPCLKNELVHGMCQWECLCIVNGRPVKPYENSVFSYHYDSEAKSYKFDKEEPMMFQFFELIQTATTHEYVWHECSSNQQNIGLNSQMNRHICQPEILIPLYRVTLLESGPMIVRHSAIKTYEPGPGWLPTGDFIKSFRQRTDMLIWTGFNRNVRVVGMMAFKTMHLGPAVCEFSQEDHHDHTLRWKHKWTKACKYWDIRQIANQLPCFSELEHKKTLIHCETQKDKFESKWLMRMLCDRPHSEVDMYHHCQAVNFERKWTSLQGWCQSGKVTYPCDDPT']\n\n\n\npjob = session.predict.create_predict_job(sequences=p_seqs, train_job=train)\npjob_id = pjob.id\npjob\n\nJob(status=&lt;JobStatus.PENDING: 'PENDING'&gt;, job_id='395645cb-2d09-46cf-bcc2-c625fb7e2063', job_type='/workflow/predict', created_date=None, start_date=None, end_date=None, prerequisite_job_id=None, progress_message=None, progress_counter=0, num_records=None)\n\n\n\nresults = pjob.wait(verbose=True)\n\nWaiting: 100%|██████████| 100/100 [07:22&lt;00:00,  4.42s/it, status=SUCCESS]\n\n\n\nresults[0].dict()\n\n{'sequence': 'MVINYHGGMLRTPNHQMEMFQPEFYKCDGILVREQCWLKKWGGIPEFHARIMDCFQQQARMAGNKPIGYKHLYLLHMWCFEVIQAFTNQIAYGKQLPGDHPRTNWYHFEHTMNCNPQLHFTSGSLYRSTMEKLAYSCNYTYCVQTHMYYHRREVIEMLSPSNPARTARHHPHVDMELQIIINVENQVVIPTDWNPWWIRIMCIEPDRWDCMQKKDKVFSTHFRNINVCIRPEHRDDIFDEMYCKYPHRVECQHFSGWKGLPNINPHHRTFTTCGMDPPRMWCLRKVWIDTGKYPAFYSEAQGQFQCPKYEKDAYAKGFRTELGHEISSQYEVGNFTMTNQAIAGLA',\n 'predictions': [{'model_id': '4f5a95cc-7cd9-4d19-bd2c-768c93d8d217',\n   'model_name': 'mymodel - acetamide_normalized_fitness',\n   'properties': {'acetamide_normalized_fitness': {'y_mu': -1.052383542060852,\n     'y_var': 0.008722011931240559}}},\n  {'model_id': 'd292d4de-392f-4fc8-9e45-7d3938f63902',\n   'model_name': 'mymodel - isobutyramide_normalized_fitness',\n   'properties': {'isobutyramide_normalized_fitness': {'y_mu': -0.5801481008529663,\n     'y_var': 0.07187105715274811}}}]}\n\n\nWe can also send a single sequence for single site mutation analysis:\n\nsequence = assay.get_first().sequence[0]\n\nsspredict = session.predict.create_predict_single_site(sequence, train)\n\n\nssp_results = sspredict.wait(verbose=True)\nssp_results[0:3]\n\nWaiting: 100%|██████████| 100/100 [03:30&lt;00:00,  2.11s/it, status=SUCCESS]\n\n\n[SequencePrediction(position=0, amino_acid='A', predictions=[Prediction(model_id='4f5a95cc-7cd9-4d19-bd2c-768c93d8d217', model_name='mymodel - acetamide_normalized_fitness', properties={'acetamide_normalized_fitness': {'y_mu': -1.0585644245147705, 'y_var': 0.00865915883332491}}), Prediction(model_id='d292d4de-392f-4fc8-9e45-7d3938f63902', model_name='mymodel - isobutyramide_normalized_fitness', properties={'isobutyramide_normalized_fitness': {'y_mu': -0.509050190448761, 'y_var': 0.04599723219871521}})]),\n SequencePrediction(position=0, amino_acid='R', predictions=[Prediction(model_id='4f5a95cc-7cd9-4d19-bd2c-768c93d8d217', model_name='mymodel - acetamide_normalized_fitness', properties={'acetamide_normalized_fitness': {'y_mu': -1.0604116916656494, 'y_var': 0.008511288091540337}}), Prediction(model_id='d292d4de-392f-4fc8-9e45-7d3938f63902', model_name='mymodel - isobutyramide_normalized_fitness', properties={'isobutyramide_normalized_fitness': {'y_mu': -0.38895800709724426, 'y_var': 0.01822088658809662}})]),\n SequencePrediction(position=0, amino_acid='N', predictions=[Prediction(model_id='4f5a95cc-7cd9-4d19-bd2c-768c93d8d217', model_name='mymodel - acetamide_normalized_fitness', properties={'acetamide_normalized_fitness': {'y_mu': -1.0604782104492188, 'y_var': 0.008520051836967468}}), Prediction(model_id='d292d4de-392f-4fc8-9e45-7d3938f63902', model_name='mymodel - isobutyramide_normalized_fitness', properties={'isobutyramide_normalized_fitness': {'y_mu': -0.39489519596099854, 'y_var': 0.019712451845407486}})])]\n\n\n\nssp_results[0:3][0].dict()\n\n{'position': 0,\n 'amino_acid': 'A',\n 'predictions': [{'model_id': '4f5a95cc-7cd9-4d19-bd2c-768c93d8d217',\n   'model_name': 'mymodel - acetamide_normalized_fitness',\n   'properties': {'acetamide_normalized_fitness': {'y_mu': -1.0585644245147705,\n     'y_var': 0.00865915883332491}}},\n  {'model_id': 'd292d4de-392f-4fc8-9e45-7d3938f63902',\n   'model_name': 'mymodel - isobutyramide_normalized_fitness',\n   'properties': {'isobutyramide_normalized_fitness': {'y_mu': -0.509050190448761,\n     'y_var': 0.04599723219871521}}}]}\n\n\n\npreds = pd.DataFrame([i.dict() for i in ssp_results])\npreds['acetamide_normalized_fitness'] = [i[0]['properties']['acetamide_normalized_fitness']['y_mu'] for i in preds.predictions]\npreds.head()\n\n\n\n\n\n\n\n\nposition\namino_acid\npredictions\nacetamide_normalized_fitness\n\n\n\n\n0\n0\nA\n[{'model_id': '4f5a95cc-7cd9-4d19-bd2c-768c93d...\n-1.058564\n\n\n1\n0\nR\n[{'model_id': '4f5a95cc-7cd9-4d19-bd2c-768c93d...\n-1.060412\n\n\n2\n0\nN\n[{'model_id': '4f5a95cc-7cd9-4d19-bd2c-768c93d...\n-1.060478\n\n\n3\n0\nD\n[{'model_id': '4f5a95cc-7cd9-4d19-bd2c-768c93d...\n-1.064667\n\n\n4\n0\nC\n[{'model_id': '4f5a95cc-7cd9-4d19-bd2c-768c93d...\n-1.067287\n\n\n\n\n\n\n\n\n\ndf_pivot = preds.pivot(columns='position', index='amino_acid', values='acetamide_normalized_fitness')\n\n# Create  heatmap\nplt.figure(figsize=(14, 5))\nsns.heatmap(df_pivot, cmap='coolwarm', annot=False, fmt=\".2f\")\nplt.title('Acetamide Normalized Fitness Heatmap')\nplt.xlabel('Amino Acid')\nplt.ylabel('Position')\nplt.show()"
  },
  {
    "objectID": "notebooks/core_demo.html#resume-workflows",
    "href": "notebooks/core_demo.html#resume-workflows",
    "title": "Demo of Core workflow functionality",
    "section": "Resume workflows",
    "text": "Resume workflows\nLastly, it’s possible to resume from where you left off with the job id:\n\ntrain = session.train.load_job(train_id)\ntrain\n\nJobplus(status=&lt;JobStatus.SUCCESS: 'SUCCESS'&gt;, job_id='d292d4de-392f-4fc8-9e45-7d3938f63902', job_type='/workflow/train', created_date=datetime.datetime(2023, 7, 28, 1, 41, 47, 762130), start_date=datetime.datetime(2023, 7, 28, 1, 42, 48, 246124), end_date=datetime.datetime(2023, 7, 28, 1, 43, 17, 160692), prerequisite_job_id='6ba74592-91ac-47e4-9ea7-59fa0fc199fb', progress_message=None, progress_counter=None, num_records=None, sequence_length=346)\n\n\nThis reloaded job can be used as above for predict or design tasks, and those can also be reloaded!\n\npjob = session.predict.load_job(pjob_id)\npjob\n\nJob(status=&lt;JobStatus.SUCCESS: 'SUCCESS'&gt;, job_id='395645cb-2d09-46cf-bcc2-c625fb7e2063', job_type='/workflow/predict', created_date=datetime.datetime(2023, 7, 28, 1, 56, 20, 244335), start_date=datetime.datetime(2023, 7, 28, 2, 3, 3, 642814), end_date=datetime.datetime(2023, 7, 28, 2, 3, 37, 431378), prerequisite_job_id='d292d4de-392f-4fc8-9e45-7d3938f63902', progress_message=None, progress_counter=None, num_records=None)"
  }
]