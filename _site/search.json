[
  {
    "objectID": "poet_demo.html",
    "href": "poet_demo.html",
    "title": "Demo of PoET functionality",
    "section": "",
    "text": "%matplotlib inline\nThis notebook will briefly cover how to run align and PoET workflows.\nFor more information please read the docs.\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport time\nimport json\nimport pandas as pd\nimport seaborn as sns \nsns.set() \n\nfrom AWSTools.Batchtools.batch_utils import fakeseq # Used for creating fake protein sequences for testing"
  },
  {
    "objectID": "poet_demo.html#setup",
    "href": "poet_demo.html#setup",
    "title": "Demo of PoET functionality",
    "section": "Setup",
    "text": "Setup\nConnect to the OpenProtein backend with your credentials:\n\nimport openprotein\n\nwith open('secrets.config', 'r') as f:\n    config = json.load(f)\n\nsession = openprotein.connect(username= config['username'], password= config['password'], backend= \"https://dev.api.openprotein.ai/api/\") \nprint(session.backend)\n\nhttps://dev.api.openprotein.ai/api/\n\n\n\ndataset = pd.read_csv(\"./demo_data/core.csv\")[['sequence']]\ndataset.head(2)\n\n\n\n\n\n\n\n\nsequence\n\n\n\n\n0\nWRHGDISSSNDTVGVAVVNYKMPRLHTAAEVLDNARKIAEMIVGMK...\n\n\n1\nWRHGDISSSNDTVGVAVVNYKMPRLHTAAEVLDNARKIAEMIVGMK..."
  },
  {
    "objectID": "poet_demo.html#create-an-msa",
    "href": "poet_demo.html#create-an-msa",
    "title": "Demo of PoET functionality",
    "section": "Create an MSA",
    "text": "Create an MSA\nWe can create an MSA either from a seed, or by uploading a ready-made file. Here we will explore the seed workflow:\n\n# Create an MSA from a seed sequence\nseed = dataset.sequence[0]\n\nStart a ColabFold job to create an MSA:\n\nmsa = session.poet.create_msa(seed.encode())\nprint(msa)\n\n\nstatus=&lt;JobStatus.SUCCESS: 'SUCCESS'&gt; job_id='c8708fa8-e44f-4137-9b12-fec2db2bcb11' job_type='/align/align' created_date=datetime.datetime(2023, 7, 27, 8, 17, 27, 340881) start_date=None end_date=datetime.datetime(2023, 7, 27, 8, 17, 27, 350439) prerequisite_job_id=None progress_message=None progress_counter=None num_records=None msa_id='c8708fa8-e44f-4137-9b12-fec2db2bcb11'\n\n\n\nr = msa.wait() \nlist(r)[0:3]\n\n[['seed',\n  'WRHGDISSSNDTVGVAVVNYKMPRLHTAAEVLDNARKIAEMIVGMKQGLPGMDLVVFPEYSLQGIMYDPAEMMETAVAIPGEETEIFSRACRKANVWGVFSLTGERHEEHPRKAPYNTLVLIDNNGEIVQKYRKIIPWCPIEGWYPGGQTYVSEGPKGMKISLIICDDGNYPEIWRDCAMKGAELIVRCQGYMYPAKDQQVMMAKAMAWANNCYVAVANAAGFDGVYSYFGHSAIIGFDGRTLGECGEEEMGIQYAQLSLSQIRDARANDQSQNHLFKILHRGYSGLQASGDGDRGLAECPFEFYRTWVTDAEKARENVERLTRSTTGVAQCPVGRLPYEGLEKEA'],\n ['UniRef100_UPI0004660BEB',\n  '-RHGDISSSNDTVGVAVVNYKMPRLHTVAEVLDNARKIADMIVGMKQGLPGMDLVVFPEYSLQGIMYDPAEMMETAVAIPGEETEIFSRACRKANVWGVFSLTGERHEEHPRKAPYNTLVLIDNNGEIVQKYRKIIPWCPIEGWYPGGQTYVSEGPKGMKISLIICDDGNYPEIWRDCAMKGAELIVRCQGYMYPAKDQQVMMAKAMAWANNCYVAVANAAGFDGVYSYFGHSAIIGFDGRTLGECGEEEMGIQYAQLSLSQIRDARSNDQSQNHLFKILHRGYSGLQASGDGDRGLAECPFEFYRTWVTDAEKARENVERLTRSTTGVAQCPVGRLPYEGLEKEA'],\n ['UniRef100_UPI000730B3B9',\n  '-RHGDISSSNDTVGVAVVNYKMPRLHSREEVLANAQKIADMVVGMKQGLPGMDLVIFPEYSLQGIMYDPAEMMETAVAIPGDETELLARACRKANVWGVFSLTGERHEEHPNKAPYNTLVLIDNKGEVVQKYRKIIPWCPIEGWYPGGQTYVSEGPKGMKISMIICDDGNYPEIWRDCAMKGAELIVRCQGYMYPAKEQQVLMAKAMAWANNTYVAVANAAGFDGVYSYFGHSAIIGFDGRTLGECGEEEMGIQYAQLSVSQIRDARANDQSQNHLYKILHRGYTGLNNSGEGDRGLAECPFEFYKTWVTDAEKARENVEKITRSTSGVAQCPVGRLPYEGEEKEA']]\n\n\nWe can examine our inputs:\n\nlist(msa.get_input(\"RAW\"))\n\n[['seed',\n  'WRHGDISSSNDTVGVAVVNYKMPRLHTAAEVLDNARKIAEMIVGMKQGLPGMDLVVFPEYSLQGIMYDPAEMMETAVAIPGEETEIFSRACRKANVWGVFSLTGERHEEHPRKAPYNTLVLIDNNGEIVQKYRKIIPWCPIEGWYPGGQTYVSEGPKGMKISLIICDDGNYPEIWRDCAMKGAELIVRCQGYMYPAKDQQVMMAKAMAWANNCYVAVANAAGFDGVYSYFGHSAIIGFDGRTLGECGEEEMGIQYAQLSLSQIRDARANDQSQNHLFKILHRGYSGLQASGDGDRGLAECPFEFYRTWVTDAEKARENVERLTRSTTGVAQCPVGRLPYEGLEKEA']]\n\n\nand the resulting MSA (limited here to 4 sequences for brevity):\n\nlist(msa.get_input(\"GENERATED\"))[0:4]\n\n[['seed',\n  'WRHGDISSSNDTVGVAVVNYKMPRLHTAAEVLDNARKIAEMIVGMKQGLPGMDLVVFPEYSLQGIMYDPAEMMETAVAIPGEETEIFSRACRKANVWGVFSLTGERHEEHPRKAPYNTLVLIDNNGEIVQKYRKIIPWCPIEGWYPGGQTYVSEGPKGMKISLIICDDGNYPEIWRDCAMKGAELIVRCQGYMYPAKDQQVMMAKAMAWANNCYVAVANAAGFDGVYSYFGHSAIIGFDGRTLGECGEEEMGIQYAQLSLSQIRDARANDQSQNHLFKILHRGYSGLQASGDGDRGLAECPFEFYRTWVTDAEKARENVERLTRSTTGVAQCPVGRLPYEGLEKEA'],\n ['UniRef100_UPI0004660BEB',\n  '-RHGDISSSNDTVGVAVVNYKMPRLHTVAEVLDNARKIADMIVGMKQGLPGMDLVVFPEYSLQGIMYDPAEMMETAVAIPGEETEIFSRACRKANVWGVFSLTGERHEEHPRKAPYNTLVLIDNNGEIVQKYRKIIPWCPIEGWYPGGQTYVSEGPKGMKISLIICDDGNYPEIWRDCAMKGAELIVRCQGYMYPAKDQQVMMAKAMAWANNCYVAVANAAGFDGVYSYFGHSAIIGFDGRTLGECGEEEMGIQYAQLSLSQIRDARSNDQSQNHLFKILHRGYSGLQASGDGDRGLAECPFEFYRTWVTDAEKARENVERLTRSTTGVAQCPVGRLPYEGLEKEA'],\n ['UniRef100_UPI000730B3B9',\n  '-RHGDISSSNDTVGVAVVNYKMPRLHSREEVLANAQKIADMVVGMKQGLPGMDLVIFPEYSLQGIMYDPAEMMETAVAIPGDETELLARACRKANVWGVFSLTGERHEEHPNKAPYNTLVLIDNKGEVVQKYRKIIPWCPIEGWYPGGQTYVSEGPKGMKISMIICDDGNYPEIWRDCAMKGAELIVRCQGYMYPAKEQQVLMAKAMAWANNTYVAVANAAGFDGVYSYFGHSAIIGFDGRTLGECGEEEMGIQYAQLSVSQIRDARANDQSQNHLYKILHRGYTGLNNSGEGDRGLAECPFEFYKTWVTDAEKARENVEKITRSTSGVAQCPVGRLPYEGEEKEA'],\n ['UniRef100_UPI00235F2AA4',\n  '-RHGDISSSNDTVGVAVVNYKMPRLHNREQVLDNAERIAAMIVGMKQGLPGMDLVIFPEYSLQGIMYDPAEMYETAVSIPGDETEIFSRACRKAGTWGVFSLTGERHEEHPRKAPYNTLVLINNKGEVVQKYRKIIPWCPIEGWYPGNQTFVSEGPKGLKISLIICDDGNYPEIWRDCAMKGAELIVRCQGYMYPAKEQQVLMAKAMAWANNCYVAVANAAGFDGVYSYFGHSAIIGFDGRTLGECGEEEMGIQYAQLSLSQIRDARANDQSQNHLFKILHRGYSGLHASGEGDKGLAECPFEFYKTWVNDAEKAREQVQAITRTTSGVAQCPVGKLPYDGLEKQA']]"
  },
  {
    "objectID": "poet_demo.html#prompt",
    "href": "poet_demo.html#prompt",
    "title": "Demo of PoET functionality",
    "section": "Prompt",
    "text": "Prompt\nWe can use this MSA to create a prompt with a sampling regime (see the docs for details):\n\nprompt = msa.sample_prompt(num_ensemble_prompts=3, random_seed=42)\n\n\nprompt.id # or prompt.job.job_id\n\n'83c816d8-a65d-4c6d-b939-d58db669793a'\n\n\n\n# We can wait, or not, for the prompt to create\nprompt.wait() #not necessary but can\n\n&lt;_csv.reader at 0x7f16876be2e0&gt;\n\n\nAs we specified 3 prompts above we will have 3 different prompts all drawn from the same MSA:\n\nlist(prompt.get_prompt(1))[0:3]\n\n[['UniRef100_A0A959K4C9',\n  'GLMICYDTRFPEMARSLALAGAEIIIVPTAWPFPRVEHWQLLSRARAIENQCYVVTANRVGKDGQAIFCGNSRVIDPHGVVVSSASEDQEEIIYAEIKRDKLDFIRTRMPVFEHRRPDVY'],\n ['UniRef100_UPI00041A74DE',\n  'GSVSAWDEALLIAAIQYPVPVIKRPEDIQVQVQQICKTIDSTKAGYPDLDLIVFPEYSAQGLNTKIWTYDEMLLSLESPEVDSFRQACIRNNIWGVFSLMERNEDPSQPPYNTAIIINNSGEIVLHYRKLQPWVPIEPWMPGNGMPVCGGPKGAKLAVCICHDGMFPELAREAAYKGCNVFIRISGYSTQVNDQWIWTNRTNAWQNLMYTVSVNLAGYDE'],\n ['UniRef100_A0A7W9FMQ2',\n  'GGLNKSENGVVIGLVQLQLPVTVTRDDLARQTKRIVELVGKARRNNAGMDLVVFPEYALHGLSMDTNPAIMCDLDGPEVAAFKAACAEHRIWGCFSIMERNPGGNPYNSGIVIDDQGALKLYYRKLHPWVPVEPWEPGDGIPVIDGPKGAKLALIICHDGMFPEMARECAYKGAEIMIRTAGYTAPIRESWRFTNQANAFQNLMVTANVCMCGSDGTFDSMGEGMIVNFDGTVIAHGVTGRPEIITAEVRPDLVREARAGWGVENNIYQLWHRGYVAVKGGAMDCPYTFMQDMVAG']]\n\n\n\nlist(prompt.get_prompt(2))[0:3]\n\n[['UniRef100_A0A194RN05',\n  'FNTHIIIDNKGDIVQTYRKLHLFDESDFTSPGSHVVTPVDTPVGRIGLEICYDMRFPELSTTLGSMRADILTFPSAFTYTGMAHWHLLLRARAIENQCYVLAAAQTGHNAKRRSYGHALCVDPWGEVLADCEEEGPCYKIAEISLEKLADVRRNMPVFQHR'],\n ['UniRef100_A0A7W0G9W8',\n  'GGSAILGPDGAYLAGPLYDEEGILYAELDPTRLAEERQRDPAGHYHRPDV'],\n ['UniRef100_A0A6F9EEE2',\n  'RHGDISSSPDTVGVAVVNYKMPRLHTREQVLDNARKIADMIVGMKQGLPGMDLVVFPEYSTMGIMYDPDEMFETACTVPGEETEIFGRACREANTWGVFSLTGERHEEHPRKSPYNTLVLINNRGEIVQKYRKILPWAPIEGWYPGDKTYVSDGPKGLKVSLIICDDGNYPEIWRDCAMKGAELIVRPQGYMYPAKEQQIMMAKTMAWANNVYVAVANATGFDGVYSYFGHSAIIGFDGRTLGECGEEEYGIQYAELSISAIRDARQNWQSQNQLFKLLHRGYTGIYNSGDGDKGLAECPFDFYRTWVLDAKKAQENVEKITRTELTTACCPVGGLPYNGAEREA']]\n\n\n\nlist(prompt.get_prompt(3))[0:3]\n\n[['UniRef100_UPI0009488FB3',\n  'RHGDISSSPDTVGVAVVNYKMPRLHTKSDVLANAEQIADMIIGIKQGLPGMDLIVFPEYSTMGIMYDKDEMMATATTIPGEETAIFSAACKKANTWGVFSLTGEQHEEHPHKSPYNTLVLINNEGEIVQKYRKCIPWCPIEGWYPGDRTYVTTGPKGMKISLIICDDGNYPEIWRDCAMRGAELIVRCQGYMYPAKEQQVMMAKTMAWANNCYVAVANAAGFDGVYSYFGHSAIVGFDGRTLGECGEEDMGIQYAQLSVSQIRDARANDQSQNHLFKLLHRGYTGVHNSGDGDKGIADCPFEFYRTWVMDAEKAQSDVEAMTRDTIGVVDCPVGNLPAGASEKE'],\n ['UniRef100_UPI001BD4A459',\n  'GSVSAWDEALLIAAIQYPVPVIKVPEDIQVQVRQICKTIDSTKAGYPDLDLIVFPEYSAQGLNTKIWTYDEMLLSLDSPEVDCFRQACIRNDIWGVFSVMERNEDSSQPPYNAAIIINNNGEIALHYRKLQPWVPIEPWMPGNGMPVCEGPKGAKLAVCICHDGMFPELAREAAYKGCNVFIRISGYSTQVNDQWIWTNRTNAWQNLMYTVSVNLAGYDEVFYYFGEGTICNYDGNVIQQGQRNPWEIVTAELFPRLADKARENWALENSIFNLGCRGYVGKPGGERANYLTWVRDLANGEYK'],\n ['UniRef100_UPI000248378F',\n  'HGDISSSYDSVGVAVVNYKMPRLHTQDEVLANCNNIAEVIDGMKQGLPGLDLVIFPEYSTHGIMYDSQEMMDTASSIPGPETDIFSEACIRNKVWGVFSLTGERHEQHPDKVPYNTLILMNDQGDIVQKYRKIMPWTPIEGWYPGNCTYVTDGPKGLKISLIICDDGNYPEIWRDCVMKGAELVIRCQGYMYPAKEQQIIVSKAMAWMNNTYVAVANAAGFDGVYSYFGHSAIVGFDGRTLGECGEEENGIQYAALSKFSIRDFRKHAQSQNHLFKLLHRGYTGIINSGEGDQGMMECPYDFYREWVLDPESTKKKVEALTRPTVGTHECPIDGIP']]\n\n\n\nprompt1_seqs = [i[1] for i in list(prompt.get_prompt(1))]\nprompt2_seqs = [i[1] for i in list(prompt.get_prompt(2))]\nprompt3_seqs = [i[1] for i in list(prompt.get_prompt(3))]\n\nprint(f\"N seqs in prompt1: {len(prompt1_seqs)}, prompt2: {len(prompt2_seqs)} prompt3: {len(prompt3_seqs)}\") \nprint(f\"Seqs found in all 3 prompts: {len(set(prompt1_seqs) & set(prompt2_seqs)  & set(prompt3_seqs))} \")\n\nN seqs in prompt1: 44, prompt2: 44 prompt3: 46\nSeqs found in all 3 prompts: 0 \n\n\n\nmsa.msa_id, prompt.prompt_id\n\n('c8708fa8-e44f-4137-9b12-fec2db2bcb11',\n '83c816d8-a65d-4c6d-b939-d58db669793a')"
  },
  {
    "objectID": "poet_demo.html#scoring-with-poet",
    "href": "poet_demo.html#scoring-with-poet",
    "title": "Demo of PoET functionality",
    "section": "Scoring with PoET",
    "text": "Scoring with PoET\n\nseqs = [i.encode() for i in dataset.sequence] # prepare seqs from our dataset\n\n\nscorejob = session.poet.score(prompt.prompt_id, queries=seqs )\n\n\nscore_results = scorejob.wait()\nscore_results[0]\n\nPoetScoreResult(sequence=b'WRHGDISSSNDTVGVAVVNYKMPRLHTAAEVLDNARKIAEMIVGMKQGLPGMDLVVFPEYSLQGIMYDPAEMMETAVAIPGEETEIFSRACRKANVWGVFSLTGERHEEHPRKAPYNTLVLIDNNGEIVQKYRKIIPWCPIEGWYPGGQTYVSEGPKGMKISLIICDDGNYPEIWRDCAMKGAELIVRCQGYMYPAKDQQVMMAKAMAWANNCYVAVANAAGFDGVYSYFGHSAIIGFDGRTLGECGEEEMGIQYAQLSLSQIRDARANDQSQNHLFKILHRGYSGLQASGDGDRGLAECPFEFYRTWVTDAEKARENVERLTRSTTGVAQCPVGRLPYEGLEKEA', score=[-67.385009765625, -161.78848266601562, -173.0670166015625], name='sequence-01')"
  },
  {
    "objectID": "poet_demo.html#single-site-analysis-with-poet",
    "href": "poet_demo.html#single-site-analysis-with-poet",
    "title": "Demo of PoET functionality",
    "section": "Single site analysis with PoET",
    "text": "Single site analysis with PoET\nA similar flow yields a single site mutation analysis of a sequence:\n\nsspjob   = session.poet.single_site(prompt, sequence=\"AAPLAA\".encode())\n\n\nssp_results = sspjob.wait()\nssp_results[0:3]\n\n[PoetSSPResult(sequence=b'input', score=[-28.7412109375, -28.05859375, -28.6044921875], name=None),\n PoetSSPResult(sequence=b'A1R', score=[-30.0703125, -29.6171875, -29.744140625], name=None),\n PoetSSPResult(sequence=b'A1N', score=[-30.44921875, -30.638671875, -31.3056640625], name=None)]"
  },
  {
    "objectID": "poet_demo.html#generate-de-novo-sequences",
    "href": "poet_demo.html#generate-de-novo-sequences",
    "title": "Demo of PoET functionality",
    "section": "Generate de novo sequences",
    "text": "Generate de novo sequences\nLastly, we can use the generation workflow:\n\ngenjob  = session.poet.generate(prompt.prompt_id, num_samples=10) #make 10 sequences based on our prompt\n\n\n\ngen_results = genjob.wait()\ngen_results[0]\n\nPoetScoreResult(sequence=b'NWKMPRFHHSEEIVANCRKVADYVAGLKKGIPGLDLIIFPEYSTEGILYDINEMLSLNTSIPGQETEIFSRACIENKVWGVFSITGERHEDHPNKVPYNTLILINNQGEIVQKYRKMIPWTPIEGWYPGDKTYVSEGPKGLKISLIICDDGNYPEIWRDCAARGAELIVRCQGYMYPACDEQIKIVPVMAWCNNIYAAVANASGNDGVYSYFGHSSVVDFDGRVLGICGTEENSYQYAELSISAIRDARGNWQSQNHLYKLLHRGYTGTINSHEERQGIPECQFEFYKSWVTDPAGTQAKVEELTREAPGVKYAPIAGIPHE', score=[-348.2950134277344, -158.5674591064453, -277.7309875488281], name='generated-sequence-1')"
  },
  {
    "objectID": "poet_demo.html#resuming-work",
    "href": "poet_demo.html#resuming-work",
    "title": "Demo of PoET functionality",
    "section": "Resuming work",
    "text": "Resuming work\nYou can reload a prompt, MSA or PoET job to resume where you left off:\n\nold_msa = session.poet.load_msa_job(msa.msa_id)\nold_msa.job\n\nJob(status=&lt;JobStatus.SUCCESS: 'SUCCESS'&gt;, job_id='c8708fa8-e44f-4137-9b12-fec2db2bcb11', job_type='/align/align', created_date=datetime.datetime(2023, 7, 27, 8, 17, 27, 340881), start_date=None, end_date=datetime.datetime(2023, 7, 27, 8, 17, 27, 350439), prerequisite_job_id=None, progress_message=None, progress_counter=None, num_records=None)\n\n\nThe same functionality is present:\n\nnew_prompt = old_msa.sample_prompt(10)\nnew_prompt.job\n\nPromptJob(status=&lt;JobStatus.PENDING: 'PENDING'&gt;, job_id='c98c0115-1a15-4055-9a29-9ad89001146a', job_type='/align/prompt', created_date=datetime.datetime(2023, 7, 27, 8, 29, 55, 455136), start_date=None, end_date=None, prerequisite_job_id=None, progress_message=None, progress_counter=None, num_records=None, msa_id=None, prompt_id='c98c0115-1a15-4055-9a29-9ad89001146a')\n\n\n\noldprompt = session.poet.load_prompt_job(prompt.prompt_id)\noldprompt.job\n\nJob(status=&lt;JobStatus.SUCCESS: 'SUCCESS'&gt;, job_id='83c816d8-a65d-4c6d-b939-d58db669793a', job_type='/align/prompt', created_date=datetime.datetime(2023, 7, 27, 8, 17, 30, 13621), start_date=datetime.datetime(2023, 7, 27, 8, 19, 44, 182024), end_date=datetime.datetime(2023, 7, 27, 8, 19, 48, 685526), prerequisite_job_id=None, progress_message=None, progress_counter=None, num_records=None)\n\n\n\nold_job = session.poet.load_poet_job(sspjob.job.job_id)\nold_job.get()[0:3]\n\n[PoetSSPResult(sequence=b'input', score=[-28.7412109375, -28.05859375, -28.6044921875], name=None),\n PoetSSPResult(sequence=b'A1R', score=[-30.0703125, -29.6171875, -29.744140625], name=None),\n PoetSSPResult(sequence=b'A1N', score=[-30.44921875, -30.638671875, -31.3056640625], name=None)]"
  },
  {
    "objectID": "docsold/overview.html",
    "href": "docsold/overview.html",
    "title": "Overview",
    "section": "",
    "text": "Overview\nThis is an overview of OpenProtein-Python."
  },
  {
    "objectID": "newdocs/source/overview.html",
    "href": "newdocs/source/overview.html",
    "title": "Overview",
    "section": "",
    "text": "Overview\nThis is an overview of OpenProtein-Python."
  },
  {
    "objectID": "core_demo.html",
    "href": "core_demo.html",
    "title": "Demo of Core workflow functionality",
    "section": "",
    "text": "%matplotlib inline\nThis notebook will briefly cover how to run assaydata, train, predict, design workflows.\nFor more information please read the docs.\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport time\nimport json\nimport pandas as pd\nimport seaborn as sns \nsns.set() \n\nfrom AWSTools.Batchtools.batch_utils import fakeseq # Used for creating fake protein sequences for testing"
  },
  {
    "objectID": "core_demo.html#setup",
    "href": "core_demo.html#setup",
    "title": "Demo of Core workflow functionality",
    "section": "Setup",
    "text": "Setup\nConnect to the OpenProtein backend with your credentials:\n\nimport openprotein\n\nwith open('secrets.config', 'r') as f:\n    config = json.load(f)\n\nsession = openprotein.connect(username= config['username'], password= config['password'], backend= \"https://dev.api.openprotein.ai/api/\") \nprint(session.backend)\n\nhttps://dev.api.openprotein.ai/api/\n\n\nLoad some demo data:\n\ndataset = pd.read_csv(\"./demo_data/core.csv\")\ndataset.head(2)\n\n\n\n\n\n\n\n\nsequence\nisobutyramide_normalized_fitness\nacetamide_normalized_fitness\npropionamide_normalized_fitness\n\n\n\n\n0\nWRHGDISSSNDTVGVAVVNYKMPRLHTAAEVLDNARKIAEMIVGMK...\n-0.5174\nNaN\nNaN\n\n\n1\nWRHGDISSSNDTVGVAVVNYKMPRLHTAAEVLDNARKIAEMIVGMK...\n-0.5154\n-2.1514\n-1.1457"
  },
  {
    "objectID": "core_demo.html#data-upload",
    "href": "core_demo.html#data-upload",
    "title": "Demo of Core workflow functionality",
    "section": "Data Upload",
    "text": "Data Upload\nCreate the Demo data in the backend to be able to use it with our suite of tools:\n\n# Create\nassay = session.data.create(dataset, \"Dataset Name\", \"Dataset description\")\nassay_id = assay.id\nassay\n\nAssayMetadata(assay_name='Dataset Name', assay_description='Dataset description', assay_id='dbf85fa1-12ff-45e7-b5a5-2e93e888a6ac', original_filename='assay_data', created_date=datetime.datetime(2023, 7, 28, 1, 41, 47, 332556), num_rows=15, num_entries=41, measurement_names=['isobutyramide_normalized_fitness', 'acetamide_normalized_fitness', 'propionamide_normalized_fitness'], sequence_length=346)\n\n\nWe could also have loaded a job from an old job ID. This will be faster and more efficient for users resuming workflows:\n\nassay = session.data.load_job(assay_id) # can reload job to resume workflows\n\n\nassay.get_first()\n\n\n\n\n\n\n\n\nsequence\nisobutyramide_normalized_fitness\nacetamide_normalized_fitness\npropionamide_normalized_fitness\n\n\n\n\n0\nWRHGDISSSNDTVGVAVVNYKMPRLHTAAEVLDNARKIAEMIVGMK...\n-0.5174\nNone\nNone\n\n\n\n\n\n\n\n\nassay.get_slice(start=3, end=5)\n\n\n\n\n\n\n\n\nsequence\nisobutyramide_normalized_fitness\nacetamide_normalized_fitness\npropionamide_normalized_fitness\n\n\n\n\n0\nMRHGDISSSNDTVGVAVVNYKMPRLHTAAEVLDNARKWAEMIVGMK...\nNaN\nNaN\n-0.7550\n\n\n1\nMRHGDISSSNDTVGVAVVNYKMPRLHTAAEVLDNARKYAEMIVGMK...\n-0.7448\n-1.7992\n-0.9711\n\n\n\n\n\n\n\n\nassay.sequence_length\n\n346"
  },
  {
    "objectID": "core_demo.html#model-training",
    "href": "core_demo.html#model-training",
    "title": "Demo of Core workflow functionality",
    "section": "Model training",
    "text": "Model training\nWe can use the assay object to create a training job:\n\ntrain = session.train.create_training_job(assay,\n                                          measurement_name=[\"isobutyramide_normalized_fitness\", \"acetamide_normalized_fitness\"],\n                                          model_name=\"mymodel\") # name the resulting model\ntrain_id = train.id\ntrain\n\nJobplus(status=&lt;JobStatus.PENDING: 'PENDING'&gt;, job_id='d292d4de-392f-4fc8-9e45-7d3938f63902', job_type='/workflow/train', created_date=datetime.datetime(2023, 7, 28, 1, 41, 47, 762130), start_date=None, end_date=None, prerequisite_job_id='6ba74592-91ac-47e4-9ea7-59fa0fc199fb', progress_message=None, progress_counter=None, num_records=None, sequence_length=346)\n\n\n\n#train = session.train.load_job(train_id)\n#train\n\n\ntrain.refresh()\ntrain.status\n\n&lt;JobStatus.PENDING: 'PENDING'&gt;\n\n\nWe can wait for the results before proceeding:\n\nresults = train.wait(verbose=False)\n\n\nisobut_results = [i for i in results.traingraph if i.tag==\"isobutyramide_normalized_fitness\"]\nsns.scatterplot(x=[i.step for i in isobut_results], y=[i.loss for i in isobut_results])\nplt.xlabel(\"Steps\")\nplt.ylabel(\"Loss\");\n\n\n\n\nWe can also request a cross-validation job to see the training results in more detail:\n\ntrain.crossvalidate()\ntrain.crossvalidation.id\n\n'e12e7cc5-89e7-4c22-9958-2366243b196e'\n\n\n\ncvdata = train.crossvalidation.wait()\n\n\ncvresult = [i for i in cvdata if i.measurement_name == \"isobutyramide_normalized_fitness\"]\n\nsns.regplot(x=[i.y for i in cvresult], y=[i.y_mu for i in cvresult])\nplt.xlabel(\"Y\")\nplt.ylabel(\"Y-hat\");\n\n\n\n\nWe can examine the models associated with a train or assaydata set. These will be identical here but multiple train jobs are possible on a single assaydata:\n\ntrain.list_models()\n\n[{'name': 'mymodel - acetamide_normalized_fitness',\n  'description': '',\n  'model_id': '4f5a95cc-7cd9-4d19-bd2c-768c93d8d217',\n  'training_assaydata': 'dbf85fa1-12ff-45e7-b5a5-2e93e888a6ac',\n  'job_id': 'd292d4de-392f-4fc8-9e45-7d3938f63902',\n  'created_date': '2023-07-28T01:43:16.966824',\n  'model_type': 'EXACT_GP',\n  'additional_metadata': {'input_dims': 13,\n   'embedding_model': 'TorchLowRankSVD',\n   'sequence_length': 346,\n   'projection_layer': 'dbf85fa1-12ff-45e7-b5a5-2e93e888a6ac_pca.joblib',\n   'measurement_names': ['acetamide_normalized_fitness'],\n   'original_task_index': 1}},\n {'name': 'mymodel - isobutyramide_normalized_fitness',\n  'description': '',\n  'model_id': 'd292d4de-392f-4fc8-9e45-7d3938f63902',\n  'training_assaydata': 'dbf85fa1-12ff-45e7-b5a5-2e93e888a6ac',\n  'job_id': 'd292d4de-392f-4fc8-9e45-7d3938f63902',\n  'created_date': '2023-07-28T01:43:16.327287',\n  'model_type': 'EXACT_GP',\n  'additional_metadata': {'input_dims': 13,\n   'embedding_model': 'TorchLowRankSVD',\n   'sequence_length': 346,\n   'projection_layer': 'dbf85fa1-12ff-45e7-b5a5-2e93e888a6ac_pca.joblib',\n   'measurement_names': ['isobutyramide_normalized_fitness'],\n   'original_task_index': 0}}]\n\n\n\nassay.list_models()\n\n[{'name': 'mymodel - acetamide_normalized_fitness',\n  'description': '',\n  'model_id': '4f5a95cc-7cd9-4d19-bd2c-768c93d8d217',\n  'training_assaydata': 'dbf85fa1-12ff-45e7-b5a5-2e93e888a6ac',\n  'job_id': 'd292d4de-392f-4fc8-9e45-7d3938f63902',\n  'created_date': '2023-07-28T01:43:16.966824',\n  'model_type': 'EXACT_GP',\n  'additional_metadata': {'input_dims': 13,\n   'embedding_model': 'TorchLowRankSVD',\n   'sequence_length': 346,\n   'projection_layer': 'dbf85fa1-12ff-45e7-b5a5-2e93e888a6ac_pca.joblib',\n   'measurement_names': ['acetamide_normalized_fitness'],\n   'original_task_index': 1}},\n {'name': 'mymodel - isobutyramide_normalized_fitness',\n  'description': '',\n  'model_id': 'd292d4de-392f-4fc8-9e45-7d3938f63902',\n  'training_assaydata': 'dbf85fa1-12ff-45e7-b5a5-2e93e888a6ac',\n  'job_id': 'd292d4de-392f-4fc8-9e45-7d3938f63902',\n  'created_date': '2023-07-28T01:43:16.327287',\n  'model_type': 'EXACT_GP',\n  'additional_metadata': {'input_dims': 13,\n   'embedding_model': 'TorchLowRankSVD',\n   'sequence_length': 346,\n   'projection_layer': 'dbf85fa1-12ff-45e7-b5a5-2e93e888a6ac_pca.joblib',\n   'measurement_names': ['isobutyramide_normalized_fitness'],\n   'original_task_index': 0}}]\n\n\nLet’s take one of these models for further use:\n\nmodel_id = train.list_models()[0]['model_id']\ntrain.list_models()[0]\n\n{'name': 'mymodel - acetamide_normalized_fitness',\n 'description': '',\n 'model_id': '4f5a95cc-7cd9-4d19-bd2c-768c93d8d217',\n 'training_assaydata': 'dbf85fa1-12ff-45e7-b5a5-2e93e888a6ac',\n 'job_id': 'd292d4de-392f-4fc8-9e45-7d3938f63902',\n 'created_date': '2023-07-28T01:43:16.966824',\n 'model_type': 'EXACT_GP',\n 'additional_metadata': {'input_dims': 13,\n  'embedding_model': 'TorchLowRankSVD',\n  'sequence_length': 346,\n  'projection_layer': 'dbf85fa1-12ff-45e7-b5a5-2e93e888a6ac_pca.joblib',\n  'measurement_names': ['acetamide_normalized_fitness'],\n  'original_task_index': 1}}"
  },
  {
    "objectID": "core_demo.html#sequence-design",
    "href": "core_demo.html#sequence-design",
    "title": "Demo of Core workflow functionality",
    "section": "Sequence design",
    "text": "Sequence design\nWe can set up a design job using our trained model as a criteria:\n\nfrom openprotein.models import DesignJobCreate, ModelCriterion, NMutationCriterion, Criterion\ndesign_data = DesignJobCreate(\n    assay_id=assay.id,\n    criteria=[\n        [\n            ModelCriterion(\n                criterion_type='model',\n                model_id=model_id,\n                measurement_name=\"acetamide_normalized_fitness\",\n                criterion=Criterion(target=-0.5, weight=1.0, direction=\"&lt;\")\n            ),\n        ],\n        [NMutationCriterion(criterion_type=\"n_mutations\", )]\n    ],\n    mutation_positions=[2,13],\n    num_steps=10\n)\n\n\njson.loads(design_data.json())\n\n\n{'assay_id': 'dbf85fa1-12ff-45e7-b5a5-2e93e888a6ac',\n 'criteria': [[{'criterion_type': 'model',\n    'model_id': '4f5a95cc-7cd9-4d19-bd2c-768c93d8d217',\n    'measurement_name': 'acetamide_normalized_fitness',\n    'criterion': {'target': -0.5, 'weight': 1.0, 'direction': '&lt;'}}],\n  [{'criterion_type': 'n_mutations'}]],\n 'num_steps': 10,\n 'pop_size': None,\n 'n_offsprings': None,\n 'crossover_prob': None,\n 'crossover_prob_pointwise': None,\n 'mutation_average_mutations_per_seq': None,\n 'mutation_positions': [2, 13]}\n\n\n\n# create the design job\ndesign_job = session.design.create_design_job(design_data)\ndesign_id = design_job.id\ndesign_job\n\nJob(status=&lt;JobStatus.PENDING: 'PENDING'&gt;, job_id='e1826033-583b-4581-a602-9ceff483c8e0', job_type='/workflow/design', created_date=datetime.datetime(2023, 7, 28, 1, 43, 24, 642996), start_date=None, end_date=None, prerequisite_job_id=None, progress_message=None, progress_counter=None, num_records=None)\n\n\n\n\n#design_job = session.design.load_job(design_id)\n\n\nresults = design_job.wait()\nresults[-3:]\n\n[DesignStep(step=9, sample_index=2557, sequence='MRHGDIMSSNMTVGVAVVFPKMPRDRSGEWRLDNADKIKYMTAGMKRKQQQYQLVVEPIRVWQGQMWDYAEYTEQMCYIPGCETSIHSDACKKVNVWGVYSLMGEKHEEHIDKAQYYTCDLIDMDGTFADKYYKISPWYQIEQWYWGQQDYVSRDPVDMKIYLAFCDCHNYPEIWYDTAMKGAYCCVPCNGSMQPAKDDEQQMAKAMQWCHNCYVEVKNMASGSGVQSDFRVSASIIFDQRIVAETGCTEMCIQYAQLSLSDQRYARCEPQSINKQFTIQMRGYSGLQASGDGDRPLIACPRHFVRTYVGTRVIYRESVHGNIRSTTGSAQADVGAWEYKMYENDA', initial_scores=[0, 195], scores=[[DesignSubscore(score=0, metadata=DesignMetadata(y_mu=-1.052383542060852, y_var=0.008722011931240559))], [DesignSubscore(score=195, metadata=DesignMetadata(y_mu=None, y_var=None))]], umap1=0.5089479088783264, umap2=8.538457870483398),\n DesignStep(step=9, sample_index=2558, sequence='RRHGDISSNWDTYGVRVVNYTCPRLGHWAEVLANAPNCPGQILGMRLMLRGATGGRCPMYSLMGIMLTCAERMLTAQACVSETVHDFSEACRVATVWGVFKAGTQRCEECGIKGPYNCLVLIPQNGEAQQCYRKILLPCPMEGDYAQTQTYDSANPKGFESSQNHCRDPNEPSEWRDCASFGAELIVRCQGYRYPAKQIWPMNPKNMRWANNWYTGVANAACRDPHESIFPHSMIRGFDGRTWGYQGWEECITQCFQESLQQILSCRANDQSQNETFKIVKRSWRVLQALKRGDRGLNELCFRFYRTWVNDCPKARENVGRLTRSSPGCAQWSVGGLNYWGLEHRA', initial_scores=[0, 196], scores=[[DesignSubscore(score=0, metadata=DesignMetadata(y_mu=-1.052383542060852, y_var=0.008722011931240559))], [DesignSubscore(score=196, metadata=DesignMetadata(y_mu=None, y_var=None))]], umap1=0.4868474304676056, umap2=8.431281089782715),\n DesignStep(step=9, sample_index=2559, sequence='MRHGDISSSNDTVGVAVVNYKMPRLHTAAEVLDNARKLAEMIVGMKQGLPGMDLVVFPEYSLQGIMYDPAEMMETAVAIPGEETEIFSRACRKANVWGVFSLTGERHEEHPRKAPYNTLVLIDNNGEIVQKYRKIIPWCPIEGWYPGGQTYVSEGPKGMKISLIICDDGNYPEIWRDCAMKGAELIVRCQGYMYPAKDQQVMMAKAMAWANNCYVAVANAAGFDGVYSYFGHSAIIGFDGRTLGECGEEEMGIQYAQLSLSQIRDARANDQSQNHLFKILHRGYSGLQASGDGDRGLAECPFEFYRTWVTDAEKARENVERLTRSTTGVAQCPVGRLPYEGLEKEA', initial_scores=[0, 346], scores=[[DesignSubscore(score=0, metadata=DesignMetadata(y_mu=-1.0225590467453003, y_var=0.008469139225780964))], [DesignSubscore(score=346, metadata=DesignMetadata(y_mu=None, y_var=None))]], umap1=4.1282830238342285, umap2=6.924859046936035)]\n\n\nWe can access the design results:\n\nresults[-1].scores\n\n[[DesignSubscore(score=0, metadata=DesignMetadata(y_mu=-1.0225590467453003, y_var=0.008469139225780964))],\n [DesignSubscore(score=346, metadata=DesignMetadata(y_mu=None, y_var=None))]]"
  },
  {
    "objectID": "core_demo.html#sequence-predictions",
    "href": "core_demo.html#sequence-predictions",
    "title": "Demo of Core workflow functionality",
    "section": "Sequence predictions",
    "text": "Sequence predictions\nWe can also predict scores for new sequences using our models trained on our old sequences:\n\n# Create some random sequences to predict\nnp.random.seed(111)\np_seqs = [fakeseq(assay.sequence_length) for i in range(3)]\np_seqs\n\n['MVINYHGGMLRTPNHQMEMFQPEFYKCDGILVREQCWLKKWGGIPEFHARIMDCFQQQARMAGNKPIGYKHLYLLHMWCFEVIQAFTNQIAYGKQLPGDHPRTNWYHFEHTMNCNPQLHFTSGSLYRSTMEKLAYSCNYTYCVQTHMYYHRREVIEMLSPSNPARTARHHPHVDMELQIIINVENQVVIPTDWNPWWIRIMCIEPDRWDCMQKKDKVFSTHFRNINVCIRPEHRDDIFDEMYCKYPHRVECQHFSGWKGLPNINPHHRTFTTCGMDPPRMWCLRKVWIDTGKYPAFYSEAQGQFQCPKYEKDAYAKGFRTELGHEISSQYEVGNFTMTNQAIAGLA',\n 'QRMNDISWFCLAEWYWYKKEWILMFLCDTDGDENQAKCQQINVQIIIYVPSRAVVEIMEALFVMSAHLYWYTAVADNFLLDSHLLDGRDNTTFMIIGTRQWSIVHRSGLSYYKQNDLSNKLQMQKRRLLMPEMWWIRNWPWLQLVLNMENARHTGYYHQSRNGVWQWIDLLEAQRGCHQRGYVNTRQALFFAADHQLWDHTIIYTVQWEPAHQKDDQVRKMICAEYDCIIVKSSAYCFCNFQFHQKEFGFKCFIVSHGALSLTYLHYVVFRPKEEPHWHGTISACKDDRPYGLWLMGTPPYFWAPSGKLANWNMMEPCETQDCFANNYPESWLKFWWVMTTGSKPS',\n 'NSIMWHDIKCPRMMQWAWHVDNVATEVNTYNGDQTKGNGKFAHAQPSHFPYMFFWQMAIMGYHIDAAFPCLKNELVHGMCQWECLCIVNGRPVKPYENSVFSYHYDSEAKSYKFDKEEPMMFQFFELIQTATTHEYVWHECSSNQQNIGLNSQMNRHICQPEILIPLYRVTLLESGPMIVRHSAIKTYEPGPGWLPTGDFIKSFRQRTDMLIWTGFNRNVRVVGMMAFKTMHLGPAVCEFSQEDHHDHTLRWKHKWTKACKYWDIRQIANQLPCFSELEHKKTLIHCETQKDKFESKWLMRMLCDRPHSEVDMYHHCQAVNFERKWTSLQGWCQSGKVTYPCDDPT']\n\n\n\npjob = session.predict.create_predict_job(sequences=p_seqs, train_job=train)\npjob_id = pjob.id\npjob\n\nJob(status=&lt;JobStatus.PENDING: 'PENDING'&gt;, job_id='395645cb-2d09-46cf-bcc2-c625fb7e2063', job_type='/workflow/predict', created_date=None, start_date=None, end_date=None, prerequisite_job_id=None, progress_message=None, progress_counter=0, num_records=None)\n\n\n\nresults = pjob.wait(verbose=True)\n\nWaiting: 100%|██████████| 100/100 [07:22&lt;00:00,  4.42s/it, status=SUCCESS]\n\n\n\nresults[0].dict()\n\n{'sequence': 'MVINYHGGMLRTPNHQMEMFQPEFYKCDGILVREQCWLKKWGGIPEFHARIMDCFQQQARMAGNKPIGYKHLYLLHMWCFEVIQAFTNQIAYGKQLPGDHPRTNWYHFEHTMNCNPQLHFTSGSLYRSTMEKLAYSCNYTYCVQTHMYYHRREVIEMLSPSNPARTARHHPHVDMELQIIINVENQVVIPTDWNPWWIRIMCIEPDRWDCMQKKDKVFSTHFRNINVCIRPEHRDDIFDEMYCKYPHRVECQHFSGWKGLPNINPHHRTFTTCGMDPPRMWCLRKVWIDTGKYPAFYSEAQGQFQCPKYEKDAYAKGFRTELGHEISSQYEVGNFTMTNQAIAGLA',\n 'predictions': [{'model_id': '4f5a95cc-7cd9-4d19-bd2c-768c93d8d217',\n   'model_name': 'mymodel - acetamide_normalized_fitness',\n   'properties': {'acetamide_normalized_fitness': {'y_mu': -1.052383542060852,\n     'y_var': 0.008722011931240559}}},\n  {'model_id': 'd292d4de-392f-4fc8-9e45-7d3938f63902',\n   'model_name': 'mymodel - isobutyramide_normalized_fitness',\n   'properties': {'isobutyramide_normalized_fitness': {'y_mu': -0.5801481008529663,\n     'y_var': 0.07187105715274811}}}]}\n\n\nWe can also send a single sequence for single site mutation analysis:\n\nsequence = assay.get_first().sequence[0]\n\nsspredict = session.predict.create_predict_single_site(sequence, train)\n\n\nssp_results = sspredict.wait(verbose=True)\nssp_results[0:3]\n\nWaiting: 100%|██████████| 100/100 [03:30&lt;00:00,  2.11s/it, status=SUCCESS]\n\n\n[SequencePrediction(position=0, amino_acid='A', predictions=[Prediction(model_id='4f5a95cc-7cd9-4d19-bd2c-768c93d8d217', model_name='mymodel - acetamide_normalized_fitness', properties={'acetamide_normalized_fitness': {'y_mu': -1.0585644245147705, 'y_var': 0.00865915883332491}}), Prediction(model_id='d292d4de-392f-4fc8-9e45-7d3938f63902', model_name='mymodel - isobutyramide_normalized_fitness', properties={'isobutyramide_normalized_fitness': {'y_mu': -0.509050190448761, 'y_var': 0.04599723219871521}})]),\n SequencePrediction(position=0, amino_acid='R', predictions=[Prediction(model_id='4f5a95cc-7cd9-4d19-bd2c-768c93d8d217', model_name='mymodel - acetamide_normalized_fitness', properties={'acetamide_normalized_fitness': {'y_mu': -1.0604116916656494, 'y_var': 0.008511288091540337}}), Prediction(model_id='d292d4de-392f-4fc8-9e45-7d3938f63902', model_name='mymodel - isobutyramide_normalized_fitness', properties={'isobutyramide_normalized_fitness': {'y_mu': -0.38895800709724426, 'y_var': 0.01822088658809662}})]),\n SequencePrediction(position=0, amino_acid='N', predictions=[Prediction(model_id='4f5a95cc-7cd9-4d19-bd2c-768c93d8d217', model_name='mymodel - acetamide_normalized_fitness', properties={'acetamide_normalized_fitness': {'y_mu': -1.0604782104492188, 'y_var': 0.008520051836967468}}), Prediction(model_id='d292d4de-392f-4fc8-9e45-7d3938f63902', model_name='mymodel - isobutyramide_normalized_fitness', properties={'isobutyramide_normalized_fitness': {'y_mu': -0.39489519596099854, 'y_var': 0.019712451845407486}})])]\n\n\n\nssp_results[0:3][0].dict()\n\n{'position': 0,\n 'amino_acid': 'A',\n 'predictions': [{'model_id': '4f5a95cc-7cd9-4d19-bd2c-768c93d8d217',\n   'model_name': 'mymodel - acetamide_normalized_fitness',\n   'properties': {'acetamide_normalized_fitness': {'y_mu': -1.0585644245147705,\n     'y_var': 0.00865915883332491}}},\n  {'model_id': 'd292d4de-392f-4fc8-9e45-7d3938f63902',\n   'model_name': 'mymodel - isobutyramide_normalized_fitness',\n   'properties': {'isobutyramide_normalized_fitness': {'y_mu': -0.509050190448761,\n     'y_var': 0.04599723219871521}}}]}\n\n\n\npreds = pd.DataFrame([i.dict() for i in ssp_results])\npreds['acetamide_normalized_fitness'] = [i[0]['properties']['acetamide_normalized_fitness']['y_mu'] for i in preds.predictions]\npreds.head()\n\n\n\n\n\n\n\n\nposition\namino_acid\npredictions\nacetamide_normalized_fitness\n\n\n\n\n0\n0\nA\n[{'model_id': '4f5a95cc-7cd9-4d19-bd2c-768c93d...\n-1.058564\n\n\n1\n0\nR\n[{'model_id': '4f5a95cc-7cd9-4d19-bd2c-768c93d...\n-1.060412\n\n\n2\n0\nN\n[{'model_id': '4f5a95cc-7cd9-4d19-bd2c-768c93d...\n-1.060478\n\n\n3\n0\nD\n[{'model_id': '4f5a95cc-7cd9-4d19-bd2c-768c93d...\n-1.064667\n\n\n4\n0\nC\n[{'model_id': '4f5a95cc-7cd9-4d19-bd2c-768c93d...\n-1.067287\n\n\n\n\n\n\n\n\n\ndf_pivot = preds.pivot(columns='position', index='amino_acid', values='acetamide_normalized_fitness')\n\n# Create  heatmap\nplt.figure(figsize=(14, 5))\nsns.heatmap(df_pivot, cmap='coolwarm', annot=False, fmt=\".2f\")\nplt.title('Acetamide Normalized Fitness Heatmap')\nplt.xlabel('Amino Acid')\nplt.ylabel('Position')\nplt.show()"
  },
  {
    "objectID": "core_demo.html#resume-workflows",
    "href": "core_demo.html#resume-workflows",
    "title": "Demo of Core workflow functionality",
    "section": "Resume workflows",
    "text": "Resume workflows\nLastly, it’s possible to resume from where you left off with the job id:\n\ntrain = session.train.load_job(train_id)\ntrain\n\nJobplus(status=&lt;JobStatus.SUCCESS: 'SUCCESS'&gt;, job_id='d292d4de-392f-4fc8-9e45-7d3938f63902', job_type='/workflow/train', created_date=datetime.datetime(2023, 7, 28, 1, 41, 47, 762130), start_date=datetime.datetime(2023, 7, 28, 1, 42, 48, 246124), end_date=datetime.datetime(2023, 7, 28, 1, 43, 17, 160692), prerequisite_job_id='6ba74592-91ac-47e4-9ea7-59fa0fc199fb', progress_message=None, progress_counter=None, num_records=None, sequence_length=346)\n\n\nThis reloaded job can be used as above for predict or design tasks, and those can also be reloaded!\n\npjob = session.predict.load_job(pjob_id)\npjob\n\nJob(status=&lt;JobStatus.SUCCESS: 'SUCCESS'&gt;, job_id='395645cb-2d09-46cf-bcc2-c625fb7e2063', job_type='/workflow/predict', created_date=datetime.datetime(2023, 7, 28, 1, 56, 20, 244335), start_date=datetime.datetime(2023, 7, 28, 2, 3, 3, 642814), end_date=datetime.datetime(2023, 7, 28, 2, 3, 37, 431378), prerequisite_job_id='d292d4de-392f-4fc8-9e45-7d3938f63902', progress_message=None, progress_counter=None, num_records=None)"
  },
  {
    "objectID": "embeddings_demo.html",
    "href": "embeddings_demo.html",
    "title": "Demo of Embeddings workflow functionality",
    "section": "",
    "text": "%matplotlib inline\nThis notebook will briefly cover how to run Embedding workflows.\nFor more information please read the docs.\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport time\nimport json\nimport pandas as pd\nimport seaborn as sns \nsns.set() \n\nfrom AWSTools.Batchtools.batch_utils import fakeseq # Used for creating fake protein sequences for testing"
  },
  {
    "objectID": "embeddings_demo.html#setup",
    "href": "embeddings_demo.html#setup",
    "title": "Demo of Embeddings workflow functionality",
    "section": "Setup",
    "text": "Setup\nConnect to the OpenProtein backend with your credentials:\n\nimport openprotein\n\nwith open('secrets.config', 'r') as f:\n    config = json.load(f)\n\nsession = openprotein.connect(username= config['username'], password= config['password'])\nprint(session.backend)\n\nhttps://dev.api.openprotein.ai/api/"
  },
  {
    "objectID": "embeddings_demo.html#model-metadata",
    "href": "embeddings_demo.html#model-metadata",
    "title": "Demo of Embeddings workflow functionality",
    "section": "Model metadata",
    "text": "Model metadata\nYou can list the available models, and fetch metadata for more information (inc publications and DOIs where available):\n\nsession.embedding.list_models()\n\n[esm1b_t33_650M_UR50S,\n esm1v_t33_650M_UR90S_1,\n esm1v_t33_650M_UR90S_2,\n esm1v_t33_650M_UR90S_3,\n esm1v_t33_650M_UR90S_4,\n esm1v_t33_650M_UR90S_5,\n esm2_t12_35M_UR50D,\n esm2_t30_150M_UR50D,\n esm2_t33_650M_UR50D,\n esm2_t36_3B_UR50D,\n esm2_t6_8M_UR50D,\n prot-seq,\n rotaprot-large-uniref50w,\n rotaprot-large-uniref90-ft,\n test-model]\n\n\nYou can view more information on each model:\n\nesm_model = session.embedding.list_models()[0]\nesm_model.metadata.dict()['description']\n\n{'citation_title': 'Biological Structure and Function Emerge from Scaling Unsupervised Learning to 250 Million Protein Sequences',\n 'doi': '10.1101/622803',\n 'summary': 'ESM1b model with 650M parameters'}\n\n\nThere’s data available on supported tokens and outputs too:\n\nesm_model.metadata.dict()\n\n{'model_id': 'esm1b_t33_650M_UR50S',\n 'description': {'citation_title': 'Biological Structure and Function Emerge from Scaling Unsupervised Learning to 250 Million Protein Sequences',\n  'doi': '10.1101/622803',\n  'summary': 'ESM1b model with 650M parameters'},\n 'max_sequence_length': 1022,\n 'dimension': 1280,\n 'output_types': ['attn', 'embed', 'logits'],\n 'input_tokens': ['A',\n  'R',\n  'N',\n  'D',\n  'C',\n  'Q',\n  'E',\n  'G',\n  'H',\n  'I',\n  'L',\n  'K',\n  'M',\n  'F',\n  'P',\n  'S',\n  'T',\n  'W',\n  'Y',\n  'V',\n  'X',\n  'O',\n  'U',\n  'B',\n  'Z'],\n 'output_tokens': ['&lt;cls&gt;',\n  '&lt;pad&gt;',\n  '&lt;eos&gt;',\n  '&lt;unk&gt;',\n  'L',\n  'A',\n  'G',\n  'V',\n  'S',\n  'E',\n  'R',\n  'T',\n  'I',\n  'D',\n  'P',\n  'K',\n  'Q',\n  'N',\n  'F',\n  'Y',\n  'M',\n  'H',\n  'W',\n  'C',\n  '&lt;null_0&gt;',\n  'B',\n  'U',\n  'Z',\n  'O',\n  '.',\n  '-',\n  '&lt;null_1&gt;',\n  'X'],\n 'token_descriptions': [[{'id': 0,\n    'token': '&lt;cls&gt;',\n    'primary': True,\n    'description': 'Start token'}],\n  [{'id': 1,\n    'token': '&lt;pad&gt;',\n    'primary': True,\n    'description': 'Padding token'}],\n  [{'id': 2, 'token': '&lt;eos&gt;', 'primary': True, 'description': 'Stop token'}],\n  [{'id': 3,\n    'token': '&lt;unk&gt;',\n    'primary': True,\n    'description': 'Unknown token'}],\n  [{'id': 4, 'token': 'L', 'primary': True, 'description': 'Leucine'}],\n  [{'id': 5, 'token': 'A', 'primary': True, 'description': 'Alanine'}],\n  [{'id': 6, 'token': 'G', 'primary': True, 'description': 'Glycine'}],\n  [{'id': 7, 'token': 'V', 'primary': True, 'description': 'Valine'}],\n  [{'id': 8, 'token': 'S', 'primary': True, 'description': 'Serine'}],\n  [{'id': 9, 'token': 'E', 'primary': True, 'description': 'Glutamic acid'}],\n  [{'id': 10, 'token': 'R', 'primary': True, 'description': 'Arginine'}],\n  [{'id': 11, 'token': 'T', 'primary': True, 'description': 'Threonine'}],\n  [{'id': 12, 'token': 'I', 'primary': True, 'description': 'Isoleucine'}],\n  [{'id': 13, 'token': 'D', 'primary': True, 'description': 'Aspartic acid'}],\n  [{'id': 14, 'token': 'P', 'primary': True, 'description': 'Proline'}],\n  [{'id': 15, 'token': 'K', 'primary': True, 'description': 'Lysine'}],\n  [{'id': 16, 'token': 'Q', 'primary': True, 'description': 'Glutamine'}],\n  [{'id': 17, 'token': 'N', 'primary': True, 'description': 'Asparagine'}],\n  [{'id': 18, 'token': 'F', 'primary': True, 'description': 'Phenylalanine'}],\n  [{'id': 19, 'token': 'Y', 'primary': True, 'description': 'Tyrosine'}],\n  [{'id': 20, 'token': 'M', 'primary': True, 'description': 'Methionine'}],\n  [{'id': 21, 'token': 'H', 'primary': True, 'description': 'Histidine'}],\n  [{'id': 22, 'token': 'W', 'primary': True, 'description': 'Tryptophan'}],\n  [{'id': 23, 'token': 'C', 'primary': True, 'description': 'Cysteine'}],\n  [{'id': 24,\n    'token': '&lt;null_0&gt;',\n    'primary': True,\n    'description': 'Null token, unused'}],\n  [{'id': 25,\n    'token': 'B',\n    'primary': True,\n    'description': 'Aspartic acid or Asparagine'}],\n  [{'id': 26, 'token': 'U', 'primary': True, 'description': 'Selenocysteine'}],\n  [{'id': 27,\n    'token': 'Z',\n    'primary': True,\n    'description': 'Glutamic acid or Glutamine'}],\n  [{'id': 28, 'token': 'O', 'primary': True, 'description': 'Pyrrolysine'}],\n  [{'id': 29,\n    'token': '.',\n    'primary': True,\n    'description': 'Insertion token, unused'}],\n  [{'id': 30,\n    'token': '-',\n    'primary': True,\n    'description': 'Gap token, unused'}],\n  [{'id': 31,\n    'token': '&lt;null_1&gt;',\n    'primary': True,\n    'description': 'Null token, unused'}],\n  [{'id': 32,\n    'token': 'X',\n    'primary': True,\n    'description': 'Mask token; represents any amino acid'}]]}"
  },
  {
    "objectID": "embeddings_demo.html#making-requests",
    "href": "embeddings_demo.html#making-requests",
    "title": "Demo of Embeddings workflow functionality",
    "section": "Making requests",
    "text": "Making requests\nWe can make embedding requests from the model directly or from the API:\n\n# dummy data\nsequences= [\"AAAAPLHLALA\".encode()]\n\n\n\nesm_job = esm_model.embed(sequences=sequences)\nesm_job.job\n\nJob(status=&lt;JobStatus.PENDING: 'PENDING'&gt;, job_id='f304e749-6d36-4a8b-85df-4206acfaf50b', job_type='/embeddings/embed_reduced', created_date=datetime.datetime(2023, 7, 28, 2, 57, 16, 347282, tzinfo=datetime.timezone.utc), start_date=None, end_date=None, prerequisite_job_id=None, progress_message=None, progress_counter=0, num_records=1)\n\n\n\nembedjob = session.embedding.embed(model=\"esm1b_t33_650M_UR50S\", sequences= sequences )\nembedjob.job\n\nJob(status=&lt;JobStatus.PENDING: 'PENDING'&gt;, job_id='84ed7e57-20ab-469e-bbca-0560bd294c30', job_type='/embeddings/embed_reduced', created_date=datetime.datetime(2023, 7, 28, 2, 57, 16, 361915, tzinfo=datetime.timezone.utc), start_date=None, end_date=None, prerequisite_job_id=None, progress_message=None, progress_counter=0, num_records=1)"
  },
  {
    "objectID": "embeddings_demo.html#getting-results",
    "href": "embeddings_demo.html#getting-results",
    "title": "Demo of Embeddings workflow functionality",
    "section": "Getting results",
    "text": "Getting results\nYou can get the results by wait() which will wait for the job to complete:\n\nresults = embedjob.wait(verbose=True) # wait for results\n\nWaiting: 100%|██████████| 100/100 [00:00&lt;00:00, 7605.54it/s, status=SUCCESS]\nRetrieving: 100%|██████████| 1/1 [00:00&lt;00:00, 13.12it/s]\n\n\n\nresults[0][0],results[0][1].shape\n\n(b'AAAAPLHLALA', (1280,))\n\n\n\nresults[0][1][0:3]\n\narray([ 0.15882437, -0.03162469,  0.11416737], dtype=float32)\n\n\n\nesm_job.done()\n\nFalse\n\n\n\nresults2 = esm_job.wait(verbose=True) # wait for results\n\nWaiting: 100%|██████████| 100/100 [00:00&lt;00:00, 4872.51it/s, status=SUCCESS]\nRetrieving: 100%|██████████| 1/1 [00:00&lt;00:00, 36.59it/s]\n\n\n\nresults2[0][0],results2[0][1].shape\n\n(b'AAAAPLHLALA', (1280,))\n\n\n\nresults2[0][1][0:3]\n\narray([ 0.15882437, -0.03162469,  0.11416737], dtype=float32)\n\n\nYou can aso fetch results by sequence (useful for when we have many sequence embeddings!):\n\nesm_job.get_item(b\"AAAAPLHLALA\")[0:3]\n\narray([ 0.15882437, -0.03162469,  0.11416737], dtype=float32)\n\n\nLastly, you can also use the get() method as with other workflows:\n\nesm_job.get()\n\n[(b'AAAAPLHLALA',\n  array([ 0.15882437, -0.03162469,  0.11416737, ..., -0.17913206,\n          0.19573624,  0.13490376], dtype=float32))]"
  },
  {
    "objectID": "embeddings_demo.html#resume-workflows",
    "href": "embeddings_demo.html#resume-workflows",
    "title": "Demo of Embeddings workflow functionality",
    "section": "Resume workflows",
    "text": "Resume workflows\nLastly, it’s possible to resume from where you left off with the job id:\n\nesm_job_id = esm_job.job.job_id\n\n\nreloaded_job = session.embedding.load_job(esm_job_id)\nreloaded_job.job\n\nJob(status=&lt;JobStatus.SUCCESS: 'SUCCESS'&gt;, job_id='f304e749-6d36-4a8b-85df-4206acfaf50b', job_type='/embeddings/embed_reduced', created_date=datetime.datetime(2023, 7, 28, 2, 57, 16, 347282), start_date=datetime.datetime(2023, 7, 28, 2, 57, 16, 431629), end_date=datetime.datetime(2023, 7, 28, 2, 57, 16, 431629), prerequisite_job_id=None, progress_message=None, progress_counter=100, num_records=None)\n\n\n\nreloaded_job.sequences\n\n[b'AAAAPLHLALA']\n\n\n\nreloaded_job.get_item(b\"AAAAPLHLALA\")\n\narray([ 0.15882437, -0.03162469,  0.11416737, ..., -0.17913206,\n        0.19573624,  0.13490376], dtype=float32)"
  },
  {
    "objectID": "reference/index.html",
    "href": "reference/index.html",
    "title": "Function reference",
    "section": "",
    "text": "Welcome to the OpenProtein python client documentation!  Our workflows follow an asynchronous POST and GET framework. Once you initiate a task the system will schedule the job for retrieval later, once the work is complete. This means that even for tasks that may take a while to complete, your request will return immediately.  The job objects contain a job ID (job_id) which can be used to resume a workflow from where you left off! See the notebooks for demonstrations.\n\n\n\nbase.APISession\nConnection session.\n\n\n\n\n\n\nUpload your dataset to OpenProtein’s engineering platform for train, predict and design tasks.\n\n\n\napi.data.DataAPI\nAPI interface for calling AssayData endpoints\n\n\napi.data.AssayDataset\nFuture Job for manipulating results\n\n\n\n\n\n\nTrain model(s) on your measured properties to enable predictions for new sequences! These workflows can additionally perform cross-validation on your models to estimate uncertainty. /n A trained model is required before you can utilize predict or design endpoints.\n\n\n\napi.train.TrainingAPI\nAPI interface for calling Train endpoints\n\n\napi.train.TrainFuture\nFuture Job for manipulating results\n\n\n\n\n\n\nDesign new sequences based on your stated objectives and our genetic algorithm!\n\n\n\napi.design.DesignAPI\nAPI interface for calling Design endpoints\n\n\napi.design.DesignFuture\nFuture Job for manipulating results\n\n\n\n\n\n\nPredict properties on arbitary sequences with your OpenProtein trained models! You can make predictions for single sequences as well as single mutant variants of the sequence. Note, that you must first train a model with the train endpoints (see above).\n\n\n\napi.predict.PredictAPI\nAPI interface for calling Predict endpoints\n\n\napi.predict.PredictFuture\nFuture Job for manipulating results\n\n\n\n\n\n\nUse our generative Protein Evolutionary Transformer (PoET) model for de novo generation of proteins, evaluation of protein fitness, and single site mutant analysis of proteins. These workflows are all possible without prior wetlab data, and therefore do not require assaydata to be pre-loaded!\n\n\n\napi.poet.PoetAPI\nAPI interface for calling Poet and Align endpoints\n\n\napi.poet.PoetScoreFuture\nRepresents a result of a PoET scoring job.\n\n\napi.poet.PoetSingleSiteFuture\nRepresents a result of a PoET single-site analysis job.\n\n\napi.poet.PoetGenerateFuture\nRepresents a result of a PoET generation job.\n\n\napi.poet.PromptFuture\nRepresents a result of a prompt job.\n\n\napi.poet.MSAFuture\nRepresents a result of a MSA job.\n\n\n\n\n\n\nCreate embeddings for your protein sequences using open-source and proprietary models!\n\n\n\napi.embedding.EmbeddingAPI\nThis class defines a high level interface for accessing the embeddings API.\n\n\napi.embedding.EmbeddingResultFuture\nFuture Job for manipulating results\n\n\napi.embedding.ProtembedModel\nClass providing inference endpoints for protein embedding models served by OpenProtein.\n\n\napi.embedding.SVDModel\nClass providing embedding endpoint for SVD models. Also allows retrieving embeddings of sequences used to fit the SVD with get."
  },
  {
    "objectID": "reference/index.html#some-functions",
    "href": "reference/index.html#some-functions",
    "title": "Function reference",
    "section": "",
    "text": "Functions to inspect docstrings.\n\n\n\napi.data.DataAPI\nAPI interface for calling AssayData endpoints\n\n\napi.data.AssayDataset"
  },
  {
    "objectID": "reference/get_object.html",
    "href": "reference/get_object.html",
    "title": "get_object",
    "section": "",
    "text": "get_object(path, object_name=None, parser='numpy', load_aliases=True, dynamic=False, loader=None)\nFetch a griffe object.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\npath\nstr\nAn import path to the object. This should have the form path.to.module:object. For example, quartodoc:get_object or quartodoc:MdRenderer.render.\nrequired\n\n\nobject_name\n’str\nNone’\n(Deprecated). A function name.\n\n\nparser\nstr\nA docstring parser to use.\n'numpy'\n\n\nload_aliases\n\nFor aliases that were imported from other modules, should we load that module?\nTrue\n\n\ndynamic\n\nWhether to dynamically import object. Useful if docstring is not hard-coded, but was set on object by running python code.\nFalse\n\n\n\n\n\n\npreview: print a user-friendly preview of a griffe object.\n\n\n\n&gt;&gt;&gt; get_function(\"quartodoc\", \"get_function\")\n&lt;Function('get_function', ...\n\n\n\n\n\n\nType\nDescription\n\n\n\n\ngriffe.dataclasses.Object\nabc"
  },
  {
    "objectID": "reference/get_object.html#parameters",
    "href": "reference/get_object.html#parameters",
    "title": "get_object",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\npath\nstr\nAn import path to the object. This should have the form path.to.module:object. For example, quartodoc:get_object or quartodoc:MdRenderer.render.\nrequired\n\n\nobject_name\n’str\nNone’\n(Deprecated). A function name.\n\n\nparser\nstr\nA docstring parser to use.\n'numpy'\n\n\nload_aliases\n\nFor aliases that were imported from other modules, should we load that module?\nTrue\n\n\ndynamic\n\nWhether to dynamically import object. Useful if docstring is not hard-coded, but was set on object by running python code.\nFalse"
  },
  {
    "objectID": "reference/get_object.html#see-also",
    "href": "reference/get_object.html#see-also",
    "title": "get_object",
    "section": "",
    "text": "preview: print a user-friendly preview of a griffe object."
  },
  {
    "objectID": "reference/get_object.html#examples",
    "href": "reference/get_object.html#examples",
    "title": "get_object",
    "section": "",
    "text": "&gt;&gt;&gt; get_function(\"quartodoc\", \"get_function\")\n&lt;Function('get_function', ..."
  },
  {
    "objectID": "reference/get_object.html#returns",
    "href": "reference/get_object.html#returns",
    "title": "get_object",
    "section": "",
    "text": "Type\nDescription\n\n\n\n\ngriffe.dataclasses.Object\nabc"
  },
  {
    "objectID": "reference/preview.html",
    "href": "reference/preview.html",
    "title": "preview",
    "section": "",
    "text": "preview(ast, max_depth=999, compact=False, as_string=False)\nPrint a friendly representation of a griffe object (e.g. function, docstring)\n\n\n&gt;&gt;&gt; from quartodoc import get_object\n&gt;&gt;&gt; obj = get_object(\"quartodoc\", \"get_object\")\n&gt;&gt;&gt; preview(obj.docstring.parsed)\n ...\n&gt;&gt;&gt; preview(obj)\n ..."
  },
  {
    "objectID": "reference/preview.html#examples",
    "href": "reference/preview.html#examples",
    "title": "preview",
    "section": "",
    "text": "&gt;&gt;&gt; from quartodoc import get_object\n&gt;&gt;&gt; obj = get_object(\"quartodoc\", \"get_object\")\n&gt;&gt;&gt; preview(obj.docstring.parsed)\n ...\n&gt;&gt;&gt; preview(obj)\n ..."
  },
  {
    "objectID": "reference/api.data.html",
    "href": "reference/api.data.html",
    "title": "api.data",
    "section": "",
    "text": "api.data\n\n\n\n\n\nName\nDescription\n\n\n\n\nDataAPI\nAPI interface for calling AssayData endpoints\n\n\n\n\n\napi.data.DataAPI(self, session)\nAPI interface for calling AssayData endpoints\n\n\n\n\n\nName\nDescription\n\n\n\n\ncreate\nCreate a new assay dataset.\n\n\nget\nGet an assay dataset by its ID.\n\n\nlist\nList all assay datasets.\n\n\nload_job\nReload a Submitted job to resume from where you left off!\n\n\n\n\n\napi.data.DataAPI.create(self, table, name, description=None)\nCreate a new assay dataset.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ntable\npandas.DataFrame\nDataFrame containing the assay data.\nrequired\n\n\nname\nstr\nName of the assay dataset.\nrequired\n\n\ndescription\nstr\nDescription of the assay dataset, by default None.\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nAssayDataset\nCreated assay dataset.\n\n\n\n\n\n\n\napi.data.DataAPI.get(self, assay_id)\nGet an assay dataset by its ID.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nassay_id\nstr\nID of the assay dataset.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nAssayDataset\nAssay dataset with the specified ID.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nKeyError\nIf no assay dataset with the given ID is found.\n\n\n\n\n\n\n\napi.data.DataAPI.list(self)\nList all assay datasets.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\ntyping.List[openprotein.api.data.AssayDataset]\nList of all assay datasets.\n\n\n\n\n\n\n\napi.data.DataAPI.load_job(self, assay_id)\nReload a Submitted job to resume from where you left off!\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nassay_id\nstr\nThe identifier of the job whose details are to be loaded.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nJob\nJob\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nHTTPError\nIf the request to the server fails.\n\n\nInvalidJob\nIf the Job is of the wrong type\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nassaydata_list\nGet a list of all assay metadata.\n\n\nassaydata_page_get\nGet a page of assay data.\n\n\nassaydata_post\nPost assay data.\n\n\nassaydata_put\nUpdate assay metadata.\n\n\nget_assay_metadata\nRetrieve metadata for a specified assay.\n\n\nlist_models\nList models assoicated with assay.\n\n\n\n\n\napi.data.assaydata_list(session)\nGet a list of all assay metadata.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsession\nAPISession\nSession object for API communication.\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\ntyping.List[openprotein.models.AssayMetadata]\nList of all assay metadata.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nAPIError\nIf an error occurs during the API request.\n\n\n\n\n\n\n\napi.data.assaydata_page_get(session, assay_id, measurement_name=None, page_offset=0, page_size=1000, data_format='wide')\nGet a page of assay data.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsession\nAPISession\nSession object for API communication.\nrequired\n\n\nassay_id\nstr\nId of the assay.\nrequired\n\n\nmeasurement_name\nstr\nName of the measurement, by default None.\nNone\n\n\npage_offset\nint\nOffset of the page, by default 0.\n0\n\n\npage_size\nint\nSize of the page, by default 1000.\n1000\n\n\ndata_format\nstr\ndata_format of the data, by default ‘wide’.\n'wide'\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nAssayDataPage\nPage of assay data.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nAPIError\nIf an error occurs during the API request.\n\n\n\n\n\n\n\napi.data.assaydata_post(session, assay_file, assay_name, assay_description='')\nPost assay data.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsession\nAPISession\nSession object for API communication.\nrequired\n\n\nassay_file\nstr\nPath to the assay data file.\nrequired\n\n\nassay_name\nstr\nName of the assay.\nrequired\n\n\nassay_description\nstr\nDescription of the assay, by default ’’.\n''\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nAssayMetadata\nMetadata of the posted assay data.\n\n\n\n\n\n\n\napi.data.assaydata_put(session, assay_id, assay_name=None, assay_description=None)\nUpdate assay metadata.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsession\nAPISession\nSession object for API communication.\nrequired\n\n\nassay_id\nstr\nId of the assay.\nrequired\n\n\nassay_name\nstr\nNew name of the assay, by default None.\nNone\n\n\nassay_description\nstr\nNew description of the assay, by default None.\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nAssayMetadata\nUpdated metadata of the assay.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nAPIError\nIf an error occurs during the API request.\n\n\n\n\n\n\n\napi.data.get_assay_metadata(session, assay_id)\nRetrieve metadata for a specified assay.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsession\nAPISession\nThe current API session for communication with the server.\nrequired\n\n\nassay_id\nstr\nThe identifier of the assay for which metadata is to be retrieved.\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nAssayMetadata\nAn AssayMetadata that contains the metadata for the specified assay.\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nInvalidJob\nIf no assay metadata with the specified assay_id is found.\n\n\n\n\n\n\n\napi.data.list_models(session, assay_id)\nList models assoicated with assay.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsession\nAPISession\nSession object for API communication.\nrequired\n\n\nassay_id\nstr\nassay ID\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nList\nList of models"
  },
  {
    "objectID": "reference/api.data.html#classes",
    "href": "reference/api.data.html#classes",
    "title": "api.data",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nDataAPI\nAPI interface for calling AssayData endpoints\n\n\n\n\n\napi.data.DataAPI(self, session)\nAPI interface for calling AssayData endpoints\n\n\n\n\n\nName\nDescription\n\n\n\n\ncreate\nCreate a new assay dataset.\n\n\nget\nGet an assay dataset by its ID.\n\n\nlist\nList all assay datasets.\n\n\nload_job\nReload a Submitted job to resume from where you left off!\n\n\n\n\n\napi.data.DataAPI.create(self, table, name, description=None)\nCreate a new assay dataset.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ntable\npandas.DataFrame\nDataFrame containing the assay data.\nrequired\n\n\nname\nstr\nName of the assay dataset.\nrequired\n\n\ndescription\nstr\nDescription of the assay dataset, by default None.\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nAssayDataset\nCreated assay dataset.\n\n\n\n\n\n\n\napi.data.DataAPI.get(self, assay_id)\nGet an assay dataset by its ID.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nassay_id\nstr\nID of the assay dataset.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nAssayDataset\nAssay dataset with the specified ID.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nKeyError\nIf no assay dataset with the given ID is found.\n\n\n\n\n\n\n\napi.data.DataAPI.list(self)\nList all assay datasets.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\ntyping.List[openprotein.api.data.AssayDataset]\nList of all assay datasets.\n\n\n\n\n\n\n\napi.data.DataAPI.load_job(self, assay_id)\nReload a Submitted job to resume from where you left off!\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nassay_id\nstr\nThe identifier of the job whose details are to be loaded.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nJob\nJob\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nHTTPError\nIf the request to the server fails.\n\n\nInvalidJob\nIf the Job is of the wrong type"
  },
  {
    "objectID": "reference/api.data.html#functions",
    "href": "reference/api.data.html#functions",
    "title": "api.data",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nassaydata_list\nGet a list of all assay metadata.\n\n\nassaydata_page_get\nGet a page of assay data.\n\n\nassaydata_post\nPost assay data.\n\n\nassaydata_put\nUpdate assay metadata.\n\n\nget_assay_metadata\nRetrieve metadata for a specified assay.\n\n\nlist_models\nList models assoicated with assay.\n\n\n\n\n\napi.data.assaydata_list(session)\nGet a list of all assay metadata.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsession\nAPISession\nSession object for API communication.\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\ntyping.List[openprotein.models.AssayMetadata]\nList of all assay metadata.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nAPIError\nIf an error occurs during the API request.\n\n\n\n\n\n\n\napi.data.assaydata_page_get(session, assay_id, measurement_name=None, page_offset=0, page_size=1000, data_format='wide')\nGet a page of assay data.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsession\nAPISession\nSession object for API communication.\nrequired\n\n\nassay_id\nstr\nId of the assay.\nrequired\n\n\nmeasurement_name\nstr\nName of the measurement, by default None.\nNone\n\n\npage_offset\nint\nOffset of the page, by default 0.\n0\n\n\npage_size\nint\nSize of the page, by default 1000.\n1000\n\n\ndata_format\nstr\ndata_format of the data, by default ‘wide’.\n'wide'\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nAssayDataPage\nPage of assay data.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nAPIError\nIf an error occurs during the API request.\n\n\n\n\n\n\n\napi.data.assaydata_post(session, assay_file, assay_name, assay_description='')\nPost assay data.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsession\nAPISession\nSession object for API communication.\nrequired\n\n\nassay_file\nstr\nPath to the assay data file.\nrequired\n\n\nassay_name\nstr\nName of the assay.\nrequired\n\n\nassay_description\nstr\nDescription of the assay, by default ’’.\n''\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nAssayMetadata\nMetadata of the posted assay data.\n\n\n\n\n\n\n\napi.data.assaydata_put(session, assay_id, assay_name=None, assay_description=None)\nUpdate assay metadata.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsession\nAPISession\nSession object for API communication.\nrequired\n\n\nassay_id\nstr\nId of the assay.\nrequired\n\n\nassay_name\nstr\nNew name of the assay, by default None.\nNone\n\n\nassay_description\nstr\nNew description of the assay, by default None.\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nAssayMetadata\nUpdated metadata of the assay.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nAPIError\nIf an error occurs during the API request.\n\n\n\n\n\n\n\napi.data.get_assay_metadata(session, assay_id)\nRetrieve metadata for a specified assay.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsession\nAPISession\nThe current API session for communication with the server.\nrequired\n\n\nassay_id\nstr\nThe identifier of the assay for which metadata is to be retrieved.\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nAssayMetadata\nAn AssayMetadata that contains the metadata for the specified assay.\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nInvalidJob\nIf no assay metadata with the specified assay_id is found.\n\n\n\n\n\n\n\napi.data.list_models(session, assay_id)\nList models assoicated with assay.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsession\nAPISession\nSession object for API communication.\nrequired\n\n\nassay_id\nstr\nassay ID\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nList\nList of models"
  },
  {
    "objectID": "reference/api.data.AssayDataset.html",
    "href": "reference/api.data.AssayDataset.html",
    "title": "api.data.AssayDataset",
    "section": "",
    "text": "api.data.AssayDataset(self, session, metadata)\nFuture Job for manipulating results\n\n\n\n\n\nName\nDescription\n\n\n\n\nget_first\nGet head slice of assay data.\n\n\nget_slice\nGet a slice of assay data.\n\n\nlist_models\nList models assoicated with assay.\n\n\nupdate\nUpdate the assay metadata.\n\n\n\n\n\napi.data.AssayDataset.get_first(self)\nGet head slice of assay data.\n\n\n\n\n\nType\nDescription\n\n\n\n\npandas.DataFrame\nDataframe containing the slice of assay data.\n\n\n\n\n\n\n\napi.data.AssayDataset.get_slice(self, start, end)\nGet a slice of assay data.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nstart\nint\nStart index of the slice.\nrequired\n\n\nend\nint\nEnd index of the slice.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npandas.DataFrame\nDataframe containing the slice of assay data.\n\n\n\n\n\n\n\napi.data.AssayDataset.list_models(self)\nList models assoicated with assay.\n\n\n\n\n\nType\nDescription\n\n\n\n\nList\nList of models\n\n\n\n\n\n\n\napi.data.AssayDataset.update(self, assay_name=None, assay_description=None)\nUpdate the assay metadata.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nassay_name\nstr\nNew name of the assay, by default None.\nNone\n\n\nassay_description\nstr\nNew description of the assay, by default None.\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone"
  },
  {
    "objectID": "reference/api.data.AssayDataset.html#methods",
    "href": "reference/api.data.AssayDataset.html#methods",
    "title": "api.data.AssayDataset",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nget_first\nGet head slice of assay data.\n\n\nget_slice\nGet a slice of assay data.\n\n\nlist_models\nList models assoicated with assay.\n\n\nupdate\nUpdate the assay metadata.\n\n\n\n\n\napi.data.AssayDataset.get_first(self)\nGet head slice of assay data.\n\n\n\n\n\nType\nDescription\n\n\n\n\npandas.DataFrame\nDataframe containing the slice of assay data.\n\n\n\n\n\n\n\napi.data.AssayDataset.get_slice(self, start, end)\nGet a slice of assay data.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nstart\nint\nStart index of the slice.\nrequired\n\n\nend\nint\nEnd index of the slice.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npandas.DataFrame\nDataframe containing the slice of assay data.\n\n\n\n\n\n\n\napi.data.AssayDataset.list_models(self)\nList models assoicated with assay.\n\n\n\n\n\nType\nDescription\n\n\n\n\nList\nList of models\n\n\n\n\n\n\n\napi.data.AssayDataset.update(self, assay_name=None, assay_description=None)\nUpdate the assay metadata.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nassay_name\nstr\nNew name of the assay, by default None.\nNone\n\n\nassay_description\nstr\nNew description of the assay, by default None.\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone"
  },
  {
    "objectID": "reference/api.data.DataAPI.html",
    "href": "reference/api.data.DataAPI.html",
    "title": "api.data.DataAPI",
    "section": "",
    "text": "api.data.DataAPI(self, session)\nAPI interface for calling AssayData endpoints\n\n\n\n\n\nName\nDescription\n\n\n\n\ncreate\nCreate a new assay dataset.\n\n\nget\nGet an assay dataset by its ID.\n\n\nlist\nList all assay datasets.\n\n\nload_job\nReload a Submitted job to resume from where you left off!\n\n\n\n\n\napi.data.DataAPI.create(self, table, name, description=None)\nCreate a new assay dataset.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ntable\npandas.DataFrame\nDataFrame containing the assay data.\nrequired\n\n\nname\nstr\nName of the assay dataset.\nrequired\n\n\ndescription\nstr\nDescription of the assay dataset, by default None.\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nAssayDataset\nCreated assay dataset.\n\n\n\n\n\n\n\napi.data.DataAPI.get(self, assay_id)\nGet an assay dataset by its ID.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nassay_id\nstr\nID of the assay dataset.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nAssayDataset\nAssay dataset with the specified ID.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nKeyError\nIf no assay dataset with the given ID is found.\n\n\n\n\n\n\n\napi.data.DataAPI.list(self)\nList all assay datasets.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\ntyping.List[openprotein.api.data.AssayDataset]\nList of all assay datasets.\n\n\n\n\n\n\n\napi.data.DataAPI.load_job(self, assay_id)\nReload a Submitted job to resume from where you left off!\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nassay_id\nstr\nThe identifier of the job whose details are to be loaded.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nJob\nJob\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nHTTPError\nIf the request to the server fails.\n\n\nInvalidJob\nIf the Job is of the wrong type"
  },
  {
    "objectID": "reference/api.data.DataAPI.html#methods",
    "href": "reference/api.data.DataAPI.html#methods",
    "title": "api.data.DataAPI",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ncreate\nCreate a new assay dataset.\n\n\nget\nGet an assay dataset by its ID.\n\n\nlist\nList all assay datasets.\n\n\nload_job\nReload a Submitted job to resume from where you left off!\n\n\n\n\n\napi.data.DataAPI.create(self, table, name, description=None)\nCreate a new assay dataset.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ntable\npandas.DataFrame\nDataFrame containing the assay data.\nrequired\n\n\nname\nstr\nName of the assay dataset.\nrequired\n\n\ndescription\nstr\nDescription of the assay dataset, by default None.\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nAssayDataset\nCreated assay dataset.\n\n\n\n\n\n\n\napi.data.DataAPI.get(self, assay_id)\nGet an assay dataset by its ID.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nassay_id\nstr\nID of the assay dataset.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nAssayDataset\nAssay dataset with the specified ID.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nKeyError\nIf no assay dataset with the given ID is found.\n\n\n\n\n\n\n\napi.data.DataAPI.list(self)\nList all assay datasets.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\ntyping.List[openprotein.api.data.AssayDataset]\nList of all assay datasets.\n\n\n\n\n\n\n\napi.data.DataAPI.load_job(self, assay_id)\nReload a Submitted job to resume from where you left off!\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nassay_id\nstr\nThe identifier of the job whose details are to be loaded.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nJob\nJob\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nHTTPError\nIf the request to the server fails.\n\n\nInvalidJob\nIf the Job is of the wrong type"
  },
  {
    "objectID": "reference/index.html#some-functions-1",
    "href": "reference/index.html#some-functions-1",
    "title": "Function reference",
    "section": "",
    "text": "Functions to inspect docstrings.\n\n\n\napi.train.TrainingAPI\nAPI interface for calling Train endpoints\n\n\napi.train.TrainFuture"
  },
  {
    "objectID": "reference/api.train.TrainFuture.html",
    "href": "reference/api.train.TrainFuture.html",
    "title": "api.train.TrainFuture",
    "section": "",
    "text": "api.train.TrainFuture(self, session, job, assaymetadata=None)\nFuture Job for manipulating results\n\n\n\n\n\nName\nDescription\n\n\n\n\nget_assay_data\nNOT IMPLEMENTED.\n\n\n\n\n\napi.train.TrainFuture.get_assay_data(self)\nNOT IMPLEMENTED.\nGet the assay data used for the training job.\nReturns: The assay data."
  },
  {
    "objectID": "reference/api.train.TrainFuture.html#methods",
    "href": "reference/api.train.TrainFuture.html#methods",
    "title": "api.train.TrainFuture",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nget_assay_data\nNOT IMPLEMENTED.\n\n\n\n\n\napi.train.TrainFuture.get_assay_data(self)\nNOT IMPLEMENTED.\nGet the assay data used for the training job.\nReturns: The assay data."
  },
  {
    "objectID": "reference/api.train.TrainingAPI.html",
    "href": "reference/api.train.TrainingAPI.html",
    "title": "api.train.TrainingAPI",
    "section": "",
    "text": "api.train.TrainingAPI(self, session)\nAPI interface for calling Train endpoints\n\n\n\n\n\nName\nDescription\n\n\n\n\ncreate_training_job\nCreate a training job on your data.\n\n\nget_training_results\nGet training results (e.g. loss etc).\n\n\nload_job\nReload a Submitted job to resume from where you left off!\n\n\n\n\n\napi.train.TrainingAPI.create_training_job(self, assaydataset, measurement_name, model_name='', force_preprocess=False)\nCreate a training job on your data.\nThis function validates the inputs, formats the data, and sends the job.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nassaydataset\nAssayDataset\nAn AssayDataset object from which the assay_id is extracted.\nrequired\n\n\nmeasurement_name\nstr or typing.List[str]\nThe name(s) of the measurement(s) to be used in the training job.\nrequired\n\n\nmodel_name\nstr\nThe name to give the model.\n''\n\n\nforce_preprocess\nbool\nIf set to True, preprocessing is forced even if data already exists.\nFalse\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nTrainFuture\nA TrainFuture Job\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nInvalidParameterError\nIf the assaydataset is not an AssayDataset object, If any measurement name provided does not exist in the AssayDataset, or if the AssayDataset has fewer than 3 data points.\n\n\nHTTPError\nIf the request to the server fails.\n\n\n\n\n\n\n\napi.train.TrainingAPI.get_training_results(self, job_id)\nGet training results (e.g. loss etc).\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\njob_id\nstr\njob_id to get\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nTrainFuture\nA TrainFuture Job\n\n\n\n\n\n\n\napi.train.TrainingAPI.load_job(self, job_id)\nReload a Submitted job to resume from where you left off!\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\njob_id\nstr\nThe identifier of the job whose details are to be loaded.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nJob\nJob\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nHTTPError\nIf the request to the server fails.\n\n\nInvalidJob\nIf the Job is of the wrong type"
  },
  {
    "objectID": "reference/api.train.TrainingAPI.html#methods",
    "href": "reference/api.train.TrainingAPI.html#methods",
    "title": "api.train.TrainingAPI",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ncreate_training_job\nCreate a training job on your data.\n\n\nget_training_results\nGet training results (e.g. loss etc).\n\n\nload_job\nReload a Submitted job to resume from where you left off!\n\n\n\n\n\napi.train.TrainingAPI.create_training_job(self, assaydataset, measurement_name, model_name='', force_preprocess=False)\nCreate a training job on your data.\nThis function validates the inputs, formats the data, and sends the job.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nassaydataset\nAssayDataset\nAn AssayDataset object from which the assay_id is extracted.\nrequired\n\n\nmeasurement_name\nstr or typing.List[str]\nThe name(s) of the measurement(s) to be used in the training job.\nrequired\n\n\nmodel_name\nstr\nThe name to give the model.\n''\n\n\nforce_preprocess\nbool\nIf set to True, preprocessing is forced even if data already exists.\nFalse\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nTrainFuture\nA TrainFuture Job\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nInvalidParameterError\nIf the assaydataset is not an AssayDataset object, If any measurement name provided does not exist in the AssayDataset, or if the AssayDataset has fewer than 3 data points.\n\n\nHTTPError\nIf the request to the server fails.\n\n\n\n\n\n\n\napi.train.TrainingAPI.get_training_results(self, job_id)\nGet training results (e.g. loss etc).\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\njob_id\nstr\njob_id to get\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nTrainFuture\nA TrainFuture Job\n\n\n\n\n\n\n\napi.train.TrainingAPI.load_job(self, job_id)\nReload a Submitted job to resume from where you left off!\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\njob_id\nstr\nThe identifier of the job whose details are to be loaded.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nJob\nJob\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nHTTPError\nIf the request to the server fails.\n\n\nInvalidJob\nIf the Job is of the wrong type"
  },
  {
    "objectID": "reference/index.html#some-functions-2",
    "href": "reference/index.html#some-functions-2",
    "title": "Function reference",
    "section": "",
    "text": "Functions to inspect docstrings.\n\n\n\napi.design.DesignAPI\nAPI interface for calling Design endpoints\n\n\napi.design.DesignFuture"
  },
  {
    "objectID": "reference/index.html#some-functions-3",
    "href": "reference/index.html#some-functions-3",
    "title": "Function reference",
    "section": "",
    "text": "Functions to inspect docstrings.\n\n\n\napi.predict.PredictAPI\nAPI interface for calling Predict endpoints\n\n\napi.predict.PredictFuture"
  },
  {
    "objectID": "reference/index.html#some-functions-4",
    "href": "reference/index.html#some-functions-4",
    "title": "Function reference",
    "section": "",
    "text": "Functions to inspect docstrings.\n\n\n\napi.poet.PoetAPI\nAPI interface for calling Poet and AlignFF endpoints\n\n\napi.poet.PoetScoreFuture\nRepresents a result of a PoET scoring job.\n\n\napi.poet.PoetSingleSiteFuture\nRepresents a result of a PoET single-site analysis job.\n\n\napi.poet.PoetGenerateFuture\nRepresents a result of a PoET generation job.\n\n\napi.poet.PromptFuture\nRepresents a result of a prompt job.\n\n\napi.poet.MSAFuture\nRepresents a result of a MSA job."
  },
  {
    "objectID": "reference/index.html#some-functions-5",
    "href": "reference/index.html#some-functions-5",
    "title": "Function reference",
    "section": "",
    "text": "Functions to inspect docstrings.\n\n\n\napi.embedding.EmbeddingAPI\nThis class defines a high level interface for accessing the embeddings API.\n\n\napi.embedding.EmbeddingResultFuture\nThis class defines a future result from an inference request. Results are viewed as a mapping from\n\n\napi.embedding.ProtembedModel\nClass providing inference endpoints for protein embedding models served by OpenProtein.\n\n\napi.embedding.SVDModel\nClass providing embedding endpoint for SVD models. Also allows retrieving embeddings of sequences used to fit the SVD with get."
  },
  {
    "objectID": "reference/api.predict.PredictFuture.html",
    "href": "reference/api.predict.PredictFuture.html",
    "title": "api.predict.PredictFuture",
    "section": "",
    "text": "api.predict.PredictFuture(self, session, job, page_size=1000)\nFuture Job for manipulating results\n\n\n\n\n\nName\nDescription\n\n\n\n\nget\nGet all the results of the predict job.\n\n\n\n\n\napi.predict.PredictFuture.get(self, verbose=False)\nGet all the results of the predict job.\nArgs: verbose (bool, optional): If True, print verbose output. Defaults False.\nRaises: APIError: If there is an issue with the API request.\nReturns: PredictJob: A list of predict objects representing the results."
  },
  {
    "objectID": "reference/api.predict.PredictFuture.html#methods",
    "href": "reference/api.predict.PredictFuture.html#methods",
    "title": "api.predict.PredictFuture",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nget\nGet all the results of the predict job.\n\n\n\n\n\napi.predict.PredictFuture.get(self, verbose=False)\nGet all the results of the predict job.\nArgs: verbose (bool, optional): If True, print verbose output. Defaults False.\nRaises: APIError: If there is an issue with the API request.\nReturns: PredictJob: A list of predict objects representing the results."
  },
  {
    "objectID": "reference/api.embedding.ProtembedModel.html",
    "href": "reference/api.embedding.ProtembedModel.html",
    "title": "api.embedding.ProtembedModel",
    "section": "",
    "text": "api.embedding.ProtembedModel(self, session, model_id, metadata=None)\nClass providing inference endpoints for protein embedding models served by OpenProtein.\n\n\n\n\n\nName\nDescription\n\n\n\n\nattn\nAttention embeddings for sequences using this model.\n\n\nembed\nEmbed sequences using this model.\n\n\nfit_svd\nFit an SVD on the embedding results of this model.\n\n\nget_metadata\nGet model metadata for this model.\n\n\nlogits\nlogit embeddings for sequences using this model.\n\n\n\n\n\napi.embedding.ProtembedModel.attn(self, sequences)\nAttention embeddings for sequences using this model.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsequences\ntyping.List[bytes]\nsequences to SVD\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nEmbeddingResultFuture\n\n\n\n\n\n\n\n\napi.embedding.ProtembedModel.embed(self, sequences, reduction='MEAN')\nEmbed sequences using this model.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsequences\ntyping.List[bytes]\nsequences to SVD\nrequired\n\n\nreduction\ntyping.Optional[str]\nembeddings reduction to use (e.g. mean)\n'MEAN'\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nEmbeddingResultFuture\n\n\n\n\n\n\n\n\napi.embedding.ProtembedModel.fit_svd(self, sequences, n_components=1024, reduction=None)\nFit an SVD on the embedding results of this model.\nThis function will create an SVDModel based on the embeddings from this model as well as the hyperparameters specified in the args.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsequences\ntyping.List[bytes]\nsequences to SVD\nrequired\n\n\nn_components\nint\nnumber of components in SVD. Will determine output shapes\n1024\n\n\nreduction\ntyping.Optional[str]\nembeddings reduction to use (e.g. mean)\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nSVDModel\n\n\n\n\n\n\n\n\napi.embedding.ProtembedModel.get_metadata(self)\nGet model metadata for this model.\n\n\n\n\n\nType\nDescription\n\n\n\n\nModelMetadata\n\n\n\n\n\n\n\n\napi.embedding.ProtembedModel.logits(self, sequences)\nlogit embeddings for sequences using this model.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsequences\ntyping.List[bytes]\nsequences to SVD\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nEmbeddingResultFuture"
  },
  {
    "objectID": "reference/api.embedding.ProtembedModel.html#methods",
    "href": "reference/api.embedding.ProtembedModel.html#methods",
    "title": "api.embedding.ProtembedModel",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nattn\nAttention embeddings for sequences using this model.\n\n\nembed\nEmbed sequences using this model.\n\n\nfit_svd\nFit an SVD on the embedding results of this model.\n\n\nget_metadata\nGet model metadata for this model.\n\n\nlogits\nlogit embeddings for sequences using this model.\n\n\n\n\n\napi.embedding.ProtembedModel.attn(self, sequences)\nAttention embeddings for sequences using this model.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsequences\ntyping.List[bytes]\nsequences to SVD\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nEmbeddingResultFuture\n\n\n\n\n\n\n\n\napi.embedding.ProtembedModel.embed(self, sequences, reduction='MEAN')\nEmbed sequences using this model.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsequences\ntyping.List[bytes]\nsequences to SVD\nrequired\n\n\nreduction\ntyping.Optional[str]\nembeddings reduction to use (e.g. mean)\n'MEAN'\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nEmbeddingResultFuture\n\n\n\n\n\n\n\n\napi.embedding.ProtembedModel.fit_svd(self, sequences, n_components=1024, reduction=None)\nFit an SVD on the embedding results of this model.\nThis function will create an SVDModel based on the embeddings from this model as well as the hyperparameters specified in the args.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsequences\ntyping.List[bytes]\nsequences to SVD\nrequired\n\n\nn_components\nint\nnumber of components in SVD. Will determine output shapes\n1024\n\n\nreduction\ntyping.Optional[str]\nembeddings reduction to use (e.g. mean)\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nSVDModel\n\n\n\n\n\n\n\n\napi.embedding.ProtembedModel.get_metadata(self)\nGet model metadata for this model.\n\n\n\n\n\nType\nDescription\n\n\n\n\nModelMetadata\n\n\n\n\n\n\n\n\napi.embedding.ProtembedModel.logits(self, sequences)\nlogit embeddings for sequences using this model.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsequences\ntyping.List[bytes]\nsequences to SVD\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nEmbeddingResultFuture"
  },
  {
    "objectID": "reference/api.poet.PoetScoreFuture.html",
    "href": "reference/api.poet.PoetScoreFuture.html",
    "title": "api.poet.PoetScoreFuture",
    "section": "",
    "text": "api.poet.PoetScoreFuture(self, session, job, page_size=config.POET_PAGE_SIZE)\nRepresents a result of a PoET scoring job.\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\nsession\nAPISession\nAn instance of APISession for API interactions.\n\n\njob\nJob\nThe PoET scoring job.\n\n\npage_size\nint\nThe number of results to fetch in a single page.\n\n\n\n\n\n\nget(verbose=False) Get the final results of the PoET job.\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nget\nGet the final results of the PoET scoring job.\n\n\n\n\n\napi.poet.PoetScoreFuture.get(self, verbose=False)\nGet the final results of the PoET scoring job.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nverbose\nbool\nIf True, print verbose output. Defaults to False.\nFalse\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nAPIError\nIf there is an issue with the API request.\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\ntyping.List[openprotein.models.PoetScoreResult]\nA list of PoetScoreResult objects representing the scoring results."
  },
  {
    "objectID": "reference/api.poet.PoetScoreFuture.html#attributes",
    "href": "reference/api.poet.PoetScoreFuture.html#attributes",
    "title": "api.poet.PoetScoreFuture",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\nsession\nAPISession\nAn instance of APISession for API interactions.\n\n\njob\nJob\nThe PoET scoring job.\n\n\npage_size\nint\nThe number of results to fetch in a single page."
  },
  {
    "objectID": "reference/api.poet.PoetScoreFuture.html#methods",
    "href": "reference/api.poet.PoetScoreFuture.html#methods",
    "title": "api.poet.PoetScoreFuture",
    "section": "",
    "text": "get(verbose=False) Get the final results of the PoET job."
  },
  {
    "objectID": "reference/api.poet.PoetScoreFuture.html#methods-1",
    "href": "reference/api.poet.PoetScoreFuture.html#methods-1",
    "title": "api.poet.PoetScoreFuture",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nget\nGet the final results of the PoET scoring job.\n\n\n\n\n\napi.poet.PoetScoreFuture.get(self, verbose=False)\nGet the final results of the PoET scoring job.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nverbose\nbool\nIf True, print verbose output. Defaults to False.\nFalse\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nAPIError\nIf there is an issue with the API request.\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\ntyping.List[openprotein.models.PoetScoreResult]\nA list of PoetScoreResult objects representing the scoring results."
  },
  {
    "objectID": "reference/api.poet.PoetAPI.html",
    "href": "reference/api.poet.PoetAPI.html",
    "title": "api.poet.PoetAPI",
    "section": "",
    "text": "api.poet.PoetAPI(self, session)\nAPI interface for calling Poet and Align endpoints\n\n\n\n\n\nName\nDescription\n\n\n\n\ncreate_msa\nConstruct an MSA via homology search with the seed sequence.\n\n\ngenerate\nGenerate protein sequences conditioned on a prompt.\n\n\nget_msa\nGet generated MSA for a given job.\n\n\nget_msa_job\nGet MSA job based on job_id.\n\n\nget_prompt\nGet prompts for a given job.\n\n\nget_prompt_job\nGet prompt job based on job_id.\n\n\nget_seed\nGet input data for a given msa job.\n\n\nload_msa_job\nReload a previously ran MSA job to resume where you left off.\n\n\nload_poet_job\nReload a previously ran Poet job to resume where you left off.\n\n\nload_prompt_job\nReload a previously ran prompt job to resume where you left off.\n\n\nscore\nScore query sequences using the specified prompt.\n\n\nsingle_site\nScore all single substitutions of the query sequence using the specified prompt.\n\n\nupload_msa\nUpload an MSA from file.\n\n\nupload_prompt\nDirectly upload a prompt.\n\n\n\n\n\napi.poet.PoetAPI.create_msa(self, seed)\nConstruct an MSA via homology search with the seed sequence.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nseed\nbytes\nSeed sequence for the MSA construction.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nAPIError\nIf there is an issue with the API request.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nMSAJob\nJob object containing the details of the MSA construction.\n\n\n\n\n\n\n\napi.poet.PoetAPI.generate(self, prompt, num_samples=100, temperature=1.0, topk=None, topp=None, max_length=1000, seed=None)\nGenerate protein sequences conditioned on a prompt.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nprompt\nPromptJob\nThe prompt to use for generating sequences.\nrequired\n\n\nnum_samples\nint\nThe number of samples to generate, by default 100.\n100\n\n\ntemperature\nfloat\nThe temperature for sampling. Higher values produce more random outputs, by default 1.0.\n1.0\n\n\ntopk\nint\nThe number of top-k residues to consider during sampling, by default None.\nNone\n\n\ntopp\nfloat\nThe cumulative probability threshold for top-p sampling, by default None.\nNone\n\n\nmax_length\nint\nThe maximum length of generated proteins, by default 1000.\n1000\n\n\nseed\nint\nSeed for random number generation, by default a random number.\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nAPIError\nIf there is an issue with the API request.\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nJob\nAn object representing the status and information about the generation job.\n\n\n\n\n\n\n\napi.poet.PoetAPI.get_msa(self, job)\nGet generated MSA for a given job.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\njob\nJob\nThe job for which to retrieve data.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\ncsv.reader\nA CSV reader for the response data.\n\n\n\n\n\n\n\napi.poet.PoetAPI.get_msa_job(self, job_id)\nGet MSA job based on job_id.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\njob_id\nstr\njob ID for a prompt job\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nMSAJob\nA prompt job instance\n\n\n\n\n\n\n\napi.poet.PoetAPI.get_prompt(self, job, prompt_index=None)\nGet prompts for a given job.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\njob\nJob\nThe job for which to retrieve data.\nrequired\n\n\nprompt_index\ntyping.Optional[int]\nThe replicate number for the prompt (input_type=-PROMPT only)\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\ncsv.reader\nA CSV reader for the response data.\n\n\n\n\n\n\n\napi.poet.PoetAPI.get_prompt_job(self, job_id)\nGet prompt job based on job_id.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\njob_id\nstr\njob ID for a prompt job\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nPromptJob\nA prompt job instance\n\n\n\n\n\n\n\napi.poet.PoetAPI.get_seed(self, job)\nGet input data for a given msa job.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\njob\nJob\nThe job for which to retrieve data.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\ncsv.reader\nA CSV reader for the response data.\n\n\n\n\n\n\n\napi.poet.PoetAPI.load_msa_job(self, msa_id)\nReload a previously ran MSA job to resume where you left off.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmsa_id\nstr\nID for job.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nInvalidJob\nIf job is of incorrect type.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nPromptFuture\nJob to resume workflows.\n\n\n\n\n\n\n\napi.poet.PoetAPI.load_poet_job(self, job_id)\nReload a previously ran Poet job to resume where you left off.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\njob_id\nstr\nID for job.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nInvalidJob\nIf job is of incorrect type.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nPoetFuture\nJob to resume workflows.\n\n\n\n\n\n\n\napi.poet.PoetAPI.load_prompt_job(self, prompt_id)\nReload a previously ran prompt job to resume where you left off.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nprompt_id\nstr\nID for job.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nInvalidJob\nIf job is of incorrect type.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nPromptFuture\nJob to resume workflows.\n\n\n\n\n\n\n\napi.poet.PoetAPI.score(self, prompt, queries)\nScore query sequences using the specified prompt.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nprompt\nPrompt\nPrompt job to use for scoring the sequences.\nrequired\n\n\nqueries\ntyping.List[bytes]\nSequences to score.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nresults\nThe scores of the query sequences.\n\n\n\n\n\n\n\napi.poet.PoetAPI.single_site(self, prompt, sequence)\nScore all single substitutions of the query sequence using the specified prompt.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nprompt\nPrompt\nPrompt job to use for scoring the sequences.\nrequired\n\n\nsequence\nbytes\nSequence to analyse.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nresults\nThe scores of the mutated sequence.\n\n\n\n\n\n\n\napi.poet.PoetAPI.upload_msa(self, msa_file)\nUpload an MSA from file.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmsa_file\nstr\nReady-made MSA. If not provided, default value is None.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nAPIError\nIf there is an issue with the API request.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nMSAJob\nJob object containing the details of the MSA upload.\n\n\n\n\n\n\n\napi.poet.PoetAPI.upload_prompt(self, prompt_file)\nDirectly upload a prompt.\nBypass post_msa and prompt_post steps entirely. In this case PoET will use the prompt as is. You can specify multiple prompts (one per replicate) with an  and newline between CSVs.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nprompt_file\nBinaryIO\nBinary I/O object representing the prompt file.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nAPIError\nIf there is an issue with the API request.\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nPromptJob\nAn object representing the status and results of the prompt job."
  },
  {
    "objectID": "reference/api.poet.PoetAPI.html#methods",
    "href": "reference/api.poet.PoetAPI.html#methods",
    "title": "api.poet.PoetAPI",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ncreate_msa\nConstruct an MSA via homology search with the seed sequence.\n\n\ngenerate\nGenerate protein sequences conditioned on a prompt.\n\n\nget_msa\nGet generated MSA for a given job.\n\n\nget_msa_job\nGet MSA job based on job_id.\n\n\nget_prompt\nGet prompts for a given job.\n\n\nget_prompt_job\nGet prompt job based on job_id.\n\n\nget_seed\nGet input data for a given msa job.\n\n\nload_msa_job\nReload a previously ran MSA job to resume where you left off.\n\n\nload_poet_job\nReload a previously ran Poet job to resume where you left off.\n\n\nload_prompt_job\nReload a previously ran prompt job to resume where you left off.\n\n\nscore\nScore query sequences using the specified prompt.\n\n\nsingle_site\nScore all single substitutions of the query sequence using the specified prompt.\n\n\nupload_msa\nUpload an MSA from file.\n\n\nupload_prompt\nDirectly upload a prompt.\n\n\n\n\n\napi.poet.PoetAPI.create_msa(self, seed)\nConstruct an MSA via homology search with the seed sequence.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nseed\nbytes\nSeed sequence for the MSA construction.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nAPIError\nIf there is an issue with the API request.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nMSAJob\nJob object containing the details of the MSA construction.\n\n\n\n\n\n\n\napi.poet.PoetAPI.generate(self, prompt, num_samples=100, temperature=1.0, topk=None, topp=None, max_length=1000, seed=None)\nGenerate protein sequences conditioned on a prompt.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nprompt\nPromptJob\nThe prompt to use for generating sequences.\nrequired\n\n\nnum_samples\nint\nThe number of samples to generate, by default 100.\n100\n\n\ntemperature\nfloat\nThe temperature for sampling. Higher values produce more random outputs, by default 1.0.\n1.0\n\n\ntopk\nint\nThe number of top-k residues to consider during sampling, by default None.\nNone\n\n\ntopp\nfloat\nThe cumulative probability threshold for top-p sampling, by default None.\nNone\n\n\nmax_length\nint\nThe maximum length of generated proteins, by default 1000.\n1000\n\n\nseed\nint\nSeed for random number generation, by default a random number.\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nAPIError\nIf there is an issue with the API request.\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nJob\nAn object representing the status and information about the generation job.\n\n\n\n\n\n\n\napi.poet.PoetAPI.get_msa(self, job)\nGet generated MSA for a given job.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\njob\nJob\nThe job for which to retrieve data.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\ncsv.reader\nA CSV reader for the response data.\n\n\n\n\n\n\n\napi.poet.PoetAPI.get_msa_job(self, job_id)\nGet MSA job based on job_id.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\njob_id\nstr\njob ID for a prompt job\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nMSAJob\nA prompt job instance\n\n\n\n\n\n\n\napi.poet.PoetAPI.get_prompt(self, job, prompt_index=None)\nGet prompts for a given job.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\njob\nJob\nThe job for which to retrieve data.\nrequired\n\n\nprompt_index\ntyping.Optional[int]\nThe replicate number for the prompt (input_type=-PROMPT only)\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\ncsv.reader\nA CSV reader for the response data.\n\n\n\n\n\n\n\napi.poet.PoetAPI.get_prompt_job(self, job_id)\nGet prompt job based on job_id.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\njob_id\nstr\njob ID for a prompt job\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nPromptJob\nA prompt job instance\n\n\n\n\n\n\n\napi.poet.PoetAPI.get_seed(self, job)\nGet input data for a given msa job.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\njob\nJob\nThe job for which to retrieve data.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\ncsv.reader\nA CSV reader for the response data.\n\n\n\n\n\n\n\napi.poet.PoetAPI.load_msa_job(self, msa_id)\nReload a previously ran MSA job to resume where you left off.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmsa_id\nstr\nID for job.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nInvalidJob\nIf job is of incorrect type.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nPromptFuture\nJob to resume workflows.\n\n\n\n\n\n\n\napi.poet.PoetAPI.load_poet_job(self, job_id)\nReload a previously ran Poet job to resume where you left off.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\njob_id\nstr\nID for job.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nInvalidJob\nIf job is of incorrect type.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nPoetFuture\nJob to resume workflows.\n\n\n\n\n\n\n\napi.poet.PoetAPI.load_prompt_job(self, prompt_id)\nReload a previously ran prompt job to resume where you left off.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nprompt_id\nstr\nID for job.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nInvalidJob\nIf job is of incorrect type.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nPromptFuture\nJob to resume workflows.\n\n\n\n\n\n\n\napi.poet.PoetAPI.score(self, prompt, queries)\nScore query sequences using the specified prompt.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nprompt\nPrompt\nPrompt job to use for scoring the sequences.\nrequired\n\n\nqueries\ntyping.List[bytes]\nSequences to score.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nresults\nThe scores of the query sequences.\n\n\n\n\n\n\n\napi.poet.PoetAPI.single_site(self, prompt, sequence)\nScore all single substitutions of the query sequence using the specified prompt.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nprompt\nPrompt\nPrompt job to use for scoring the sequences.\nrequired\n\n\nsequence\nbytes\nSequence to analyse.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nresults\nThe scores of the mutated sequence.\n\n\n\n\n\n\n\napi.poet.PoetAPI.upload_msa(self, msa_file)\nUpload an MSA from file.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmsa_file\nstr\nReady-made MSA. If not provided, default value is None.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nAPIError\nIf there is an issue with the API request.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nMSAJob\nJob object containing the details of the MSA upload.\n\n\n\n\n\n\n\napi.poet.PoetAPI.upload_prompt(self, prompt_file)\nDirectly upload a prompt.\nBypass post_msa and prompt_post steps entirely. In this case PoET will use the prompt as is. You can specify multiple prompts (one per replicate) with an  and newline between CSVs.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nprompt_file\nBinaryIO\nBinary I/O object representing the prompt file.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nAPIError\nIf there is an issue with the API request.\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nPromptJob\nAn object representing the status and results of the prompt job."
  },
  {
    "objectID": "reference/api.poet.MSAFuture.html",
    "href": "reference/api.poet.MSAFuture.html",
    "title": "api.poet.MSAFuture",
    "section": "",
    "text": "api.poet.MSAFuture(self, session, job, page_size=config.POET_PAGE_SIZE)\nRepresents a result of a MSA job.\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\nsession\nAPISession\nAn instance of APISession for API interactions.\n\n\njob\nJob\nThe PoET scoring job.\n\n\npage_size\nint\nThe number of results to fetch in a single page.\n\n\n\n\n\n\nget(verbose=False) Get the final results of the PoET scoring job.\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\ntyping.List[openprotein.models.PoetScoreResult]\nThe list of results from the PoET scoring job.\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nsample_prompt\nCreate a protein sequence prompt from a linked MSA (Multiple Sequence Alignment) for PoET Jobs.\n\n\n\n\n\napi.poet.MSAFuture.sample_prompt(self, num_sequences=None, num_residues=None, method=MSASamplingMethod.NEIGHBORS_NONGAP_NORM_NO_LIMIT, homology_level=0.8, max_similarity=1.0, min_similarity=0.0, always_include_seed_sequence=False, num_ensemble_prompts=1, random_seed=None)\nCreate a protein sequence prompt from a linked MSA (Multiple Sequence Alignment) for PoET Jobs.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nnum_sequences\nint\nMaximum number of sequences in the prompt. Must be &lt;100.\nNone\n\n\nnum_residues\nint\nMaximum number of residues (tokens) in the prompt. Must be less than 24577.\nNone\n\n\nmethod\nMSASamplingMethod\nMethod to use for MSA sampling. Defaults to NEIGHBORS_NONGAP_NORM_NO_LIMIT.\nMSASamplingMethod.NEIGHBORS_NONGAP_NORM_NO_LIMIT\n\n\nhomology_level\nfloat\nLevel of homology for sequences in the MSA (neighbors methods only). Must be between 0 and 1. Defaults to 0.8.\n0.8\n\n\nmax_similarity\nfloat\nMaximum similarity between sequences in the MSA and the seed. Must be between 0 and 1. Defaults to 1.0.\n1.0\n\n\nmin_similarity\nfloat\nMinimum similarity between sequences in the MSA and the seed. Must be between 0 and 1. Defaults to 0.0.\n0.0\n\n\nalways_include_seed_sequence\nbool\nWhether to always include the seed sequence in the MSA. Defaults to False.\nFalse\n\n\nnum_ensemble_prompts\nint\nNumber of ensemble jobs to run. Defaults to 1.\n1\n\n\nrandom_seed\nint\nSeed for random number generation. Defaults to a random number between 0 and 2**32-1.\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nInvalidParameterError\nIf provided parameter values are not in the allowed range.\n\n\nMissingParameterError\nIf both or none of ‘num_sequences’, ‘num_residues’ is specified.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nPromptJob"
  },
  {
    "objectID": "reference/api.poet.MSAFuture.html#attributes",
    "href": "reference/api.poet.MSAFuture.html#attributes",
    "title": "api.poet.MSAFuture",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\nsession\nAPISession\nAn instance of APISession for API interactions.\n\n\njob\nJob\nThe PoET scoring job.\n\n\npage_size\nint\nThe number of results to fetch in a single page."
  },
  {
    "objectID": "reference/api.poet.MSAFuture.html#methods",
    "href": "reference/api.poet.MSAFuture.html#methods",
    "title": "api.poet.MSAFuture",
    "section": "",
    "text": "get(verbose=False) Get the final results of the PoET scoring job."
  },
  {
    "objectID": "reference/api.poet.MSAFuture.html#returns",
    "href": "reference/api.poet.MSAFuture.html#returns",
    "title": "api.poet.MSAFuture",
    "section": "",
    "text": "Type\nDescription\n\n\n\n\ntyping.List[openprotein.models.PoetScoreResult]\nThe list of results from the PoET scoring job."
  },
  {
    "objectID": "reference/api.poet.MSAFuture.html#methods-1",
    "href": "reference/api.poet.MSAFuture.html#methods-1",
    "title": "api.poet.MSAFuture",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nsample_prompt\nCreate a protein sequence prompt from a linked MSA (Multiple Sequence Alignment) for PoET Jobs.\n\n\n\n\n\napi.poet.MSAFuture.sample_prompt(self, num_sequences=None, num_residues=None, method=MSASamplingMethod.NEIGHBORS_NONGAP_NORM_NO_LIMIT, homology_level=0.8, max_similarity=1.0, min_similarity=0.0, always_include_seed_sequence=False, num_ensemble_prompts=1, random_seed=None)\nCreate a protein sequence prompt from a linked MSA (Multiple Sequence Alignment) for PoET Jobs.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nnum_sequences\nint\nMaximum number of sequences in the prompt. Must be &lt;100.\nNone\n\n\nnum_residues\nint\nMaximum number of residues (tokens) in the prompt. Must be less than 24577.\nNone\n\n\nmethod\nMSASamplingMethod\nMethod to use for MSA sampling. Defaults to NEIGHBORS_NONGAP_NORM_NO_LIMIT.\nMSASamplingMethod.NEIGHBORS_NONGAP_NORM_NO_LIMIT\n\n\nhomology_level\nfloat\nLevel of homology for sequences in the MSA (neighbors methods only). Must be between 0 and 1. Defaults to 0.8.\n0.8\n\n\nmax_similarity\nfloat\nMaximum similarity between sequences in the MSA and the seed. Must be between 0 and 1. Defaults to 1.0.\n1.0\n\n\nmin_similarity\nfloat\nMinimum similarity between sequences in the MSA and the seed. Must be between 0 and 1. Defaults to 0.0.\n0.0\n\n\nalways_include_seed_sequence\nbool\nWhether to always include the seed sequence in the MSA. Defaults to False.\nFalse\n\n\nnum_ensemble_prompts\nint\nNumber of ensemble jobs to run. Defaults to 1.\n1\n\n\nrandom_seed\nint\nSeed for random number generation. Defaults to a random number between 0 and 2**32-1.\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nInvalidParameterError\nIf provided parameter values are not in the allowed range.\n\n\nMissingParameterError\nIf both or none of ‘num_sequences’, ‘num_residues’ is specified.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nPromptJob"
  },
  {
    "objectID": "reference/api.poet.PoetSingleSiteFuture.html",
    "href": "reference/api.poet.PoetSingleSiteFuture.html",
    "title": "api.poet.PoetSingleSiteFuture",
    "section": "",
    "text": "api.poet.PoetSingleSiteFuture(self, session, job, page_size=config.POET_PAGE_SIZE)\nRepresents a result of a PoET single-site analysis job.\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\nsession\nAPISession\nAn instance of APISession for API interactions.\n\n\njob\nJob\nThe PoET scoring job.\n\n\npage_size\nint\nThe number of results to fetch in a single page.\n\n\n\n\n\n\nget(verbose=False) Get the final results of the PoET job.\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nget\nGet the results of a PoET single-site analysis job.\n\n\n\n\n\napi.poet.PoetSingleSiteFuture.get(self, verbose=False)\nGet the results of a PoET single-site analysis job.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nverbose\nbool\nIf True, print verbose output. Defaults to False.\nFalse\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nDict[bytes, float]\nA dictionary mapping mutation codes to scores.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nAPIError\nIf there is an issue with the API request."
  },
  {
    "objectID": "reference/api.poet.PoetSingleSiteFuture.html#attributes",
    "href": "reference/api.poet.PoetSingleSiteFuture.html#attributes",
    "title": "api.poet.PoetSingleSiteFuture",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\nsession\nAPISession\nAn instance of APISession for API interactions.\n\n\njob\nJob\nThe PoET scoring job.\n\n\npage_size\nint\nThe number of results to fetch in a single page."
  },
  {
    "objectID": "reference/api.poet.PoetSingleSiteFuture.html#methods",
    "href": "reference/api.poet.PoetSingleSiteFuture.html#methods",
    "title": "api.poet.PoetSingleSiteFuture",
    "section": "",
    "text": "get(verbose=False) Get the final results of the PoET job."
  },
  {
    "objectID": "reference/api.poet.PoetSingleSiteFuture.html#methods-1",
    "href": "reference/api.poet.PoetSingleSiteFuture.html#methods-1",
    "title": "api.poet.PoetSingleSiteFuture",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nget\nGet the results of a PoET single-site analysis job.\n\n\n\n\n\napi.poet.PoetSingleSiteFuture.get(self, verbose=False)\nGet the results of a PoET single-site analysis job.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nverbose\nbool\nIf True, print verbose output. Defaults to False.\nFalse\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nDict[bytes, float]\nA dictionary mapping mutation codes to scores.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nAPIError\nIf there is an issue with the API request."
  },
  {
    "objectID": "reference/api.poet.PromptFuture.html",
    "href": "reference/api.poet.PromptFuture.html",
    "title": "api.poet.PromptFuture",
    "section": "",
    "text": "api.poet.PromptFuture(self, session, job, page_size=config.POET_PAGE_SIZE, msa_id=None)\nRepresents a result of a prompt job.\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\nsession\nAPISession\nAn instance of APISession for API interactions.\n\n\njob\nJob\nThe PoET scoring job.\n\n\npage_size\nint\nThe number of results to fetch in a single page.\n\n\n\n\n\n\nget(verbose=False) Get the final results of the PoET scoring job.\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\ntyping.List[openprotein.models.PoetScoreResult]\nThe list of results from the PoET scoring job."
  },
  {
    "objectID": "reference/api.poet.PromptFuture.html#attributes",
    "href": "reference/api.poet.PromptFuture.html#attributes",
    "title": "api.poet.PromptFuture",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\nsession\nAPISession\nAn instance of APISession for API interactions.\n\n\njob\nJob\nThe PoET scoring job.\n\n\npage_size\nint\nThe number of results to fetch in a single page."
  },
  {
    "objectID": "reference/api.poet.PromptFuture.html#methods",
    "href": "reference/api.poet.PromptFuture.html#methods",
    "title": "api.poet.PromptFuture",
    "section": "",
    "text": "get(verbose=False) Get the final results of the PoET scoring job."
  },
  {
    "objectID": "reference/api.poet.PromptFuture.html#returns",
    "href": "reference/api.poet.PromptFuture.html#returns",
    "title": "api.poet.PromptFuture",
    "section": "",
    "text": "Type\nDescription\n\n\n\n\ntyping.List[openprotein.models.PoetScoreResult]\nThe list of results from the PoET scoring job."
  },
  {
    "objectID": "reference/api.predict.PredictAPI.html",
    "href": "reference/api.predict.PredictAPI.html",
    "title": "api.predict.PredictAPI",
    "section": "",
    "text": "api.predict.PredictAPI(self, session)\nAPI interface for calling Predict endpoints\n\n\n\n\n\nName\nDescription\n\n\n\n\ncreate_predict_job\nCreates a new Predict job for a given list of sequences and a trained model.\n\n\ncreate_predict_single_site\nCreates a new Predict job for single site mutation analysis with a trained model.\n\n\nget_prediction_results\nRetrieves the results of a Predict job.\n\n\nget_single_site_prediction_results\nRetrieves the results of a single site Predict job.\n\n\nload_job\nReload a Submitted job to resume from where you left off!\n\n\n\n\n\napi.predict.PredictAPI.create_predict_job(self, sequences, train_job, model_ids=None)\nCreates a new Predict job for a given list of sequences and a trained model.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsequences\nList\nThe list of sequences to be used for the Predict job.\nrequired\n\n\ntrain_job\nTrainFuture\nThe train job object representing the trained model.\nrequired\n\n\nmodel_ids\ntyping.List[str]\nThe list of model ids to be used for Predict. Default is None.\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nPredictFuture\nThe job object representing the Predict job.\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nInvalidParameterError\nIf the sequences are not of the same length as the assay data or if the train job has not completed successfully.\n\n\nInvalidParameterError\nIf BOTH train_job and model_ids are specified\n\n\nInvalidParameterError\nIf NEITHER train_job or model_ids is specified\n\n\nAPIError\nIf the backend refuses the job (due to sequence length or invalid inputs)\n\n\n\n\n\n\n\napi.predict.PredictAPI.create_predict_single_site(self, sequence, train_job, model_ids=None)\nCreates a new Predict job for single site mutation analysis with a trained model.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsequence\nstr\nThe sequence for single site analysis.\nrequired\n\n\ntrain_job\nTrainFuture\nThe train job object representing the trained model.\nrequired\n\n\nmodel_ids\ntyping.List[str]\nThe list of model ids to be used for Predict. Default is None.\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nPredictFuture\nThe job object representing the Predict job.\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nInvalidParameterError\nIf the sequences are not of the same length as the assay data or if the train job has not completed successfully.\n\n\nInvalidParameterError\nIf BOTH train_job and model_ids are specified\n\n\nInvalidParameterError\nIf NEITHER train_job or model_ids is specified\n\n\nAPIError\nIf the backend refuses the job (due to sequence length or invalid inputs)\n\n\n\n\n\n\n\napi.predict.PredictAPI.get_prediction_results(self, job_id, page_size=None, page_offset=None)\nRetrieves the results of a Predict job.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\njob_id\nstr\nThe ID of the Predict job.\nrequired\n\n\npage_size\ntyping.Optional[int]\nThe number of results to be returned per page. If None, all results are returned.\nis None\n\n\npage_offset\ntyping.Optional[int]\nThe number of results to skip. If None, defaults to 0.\nis None\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nPredictJob\nThe job object representing the Predict job.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nHTTPError\nIf the GET request does not succeed.\n\n\n\n\n\n\n\napi.predict.PredictAPI.get_single_site_prediction_results(self, job_id, page_size=None, page_offset=None)\nRetrieves the results of a single site Predict job.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\njob_id\nstr\nThe ID of the Predict job.\nrequired\n\n\npage_size\ntyping.Optional[int]\nThe number of results to be returned per page. If None, all results are returned.\nis None\n\n\npage_offset\ntyping.Optional[int]\nThe page number to start retrieving results from. If None, defaults to 0.\nis None\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nPredictSingleSiteJob\nThe job object representing the single site Predict job.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nHTTPError\nIf the GET request does not succeed.\n\n\n\n\n\n\n\napi.predict.PredictAPI.load_job(self, job_id)\nReload a Submitted job to resume from where you left off!\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\njob_id\nstr\nThe identifier of the job whose details are to be loaded.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nJob\nJob\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nHTTPError\nIf the request to the server fails.\n\n\nInvalidJob\nIf the Job is of the wrong type"
  },
  {
    "objectID": "reference/api.predict.PredictAPI.html#methods",
    "href": "reference/api.predict.PredictAPI.html#methods",
    "title": "api.predict.PredictAPI",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ncreate_predict_job\nCreates a new Predict job for a given list of sequences and a trained model.\n\n\ncreate_predict_single_site\nCreates a new Predict job for single site mutation analysis with a trained model.\n\n\nget_prediction_results\nRetrieves the results of a Predict job.\n\n\nget_single_site_prediction_results\nRetrieves the results of a single site Predict job.\n\n\nload_job\nReload a Submitted job to resume from where you left off!\n\n\n\n\n\napi.predict.PredictAPI.create_predict_job(self, sequences, train_job, model_ids=None)\nCreates a new Predict job for a given list of sequences and a trained model.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsequences\nList\nThe list of sequences to be used for the Predict job.\nrequired\n\n\ntrain_job\nTrainFuture\nThe train job object representing the trained model.\nrequired\n\n\nmodel_ids\ntyping.List[str]\nThe list of model ids to be used for Predict. Default is None.\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nPredictFuture\nThe job object representing the Predict job.\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nInvalidParameterError\nIf the sequences are not of the same length as the assay data or if the train job has not completed successfully.\n\n\nInvalidParameterError\nIf BOTH train_job and model_ids are specified\n\n\nInvalidParameterError\nIf NEITHER train_job or model_ids is specified\n\n\nAPIError\nIf the backend refuses the job (due to sequence length or invalid inputs)\n\n\n\n\n\n\n\napi.predict.PredictAPI.create_predict_single_site(self, sequence, train_job, model_ids=None)\nCreates a new Predict job for single site mutation analysis with a trained model.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsequence\nstr\nThe sequence for single site analysis.\nrequired\n\n\ntrain_job\nTrainFuture\nThe train job object representing the trained model.\nrequired\n\n\nmodel_ids\ntyping.List[str]\nThe list of model ids to be used for Predict. Default is None.\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nPredictFuture\nThe job object representing the Predict job.\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nInvalidParameterError\nIf the sequences are not of the same length as the assay data or if the train job has not completed successfully.\n\n\nInvalidParameterError\nIf BOTH train_job and model_ids are specified\n\n\nInvalidParameterError\nIf NEITHER train_job or model_ids is specified\n\n\nAPIError\nIf the backend refuses the job (due to sequence length or invalid inputs)\n\n\n\n\n\n\n\napi.predict.PredictAPI.get_prediction_results(self, job_id, page_size=None, page_offset=None)\nRetrieves the results of a Predict job.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\njob_id\nstr\nThe ID of the Predict job.\nrequired\n\n\npage_size\ntyping.Optional[int]\nThe number of results to be returned per page. If None, all results are returned.\nis None\n\n\npage_offset\ntyping.Optional[int]\nThe number of results to skip. If None, defaults to 0.\nis None\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nPredictJob\nThe job object representing the Predict job.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nHTTPError\nIf the GET request does not succeed.\n\n\n\n\n\n\n\napi.predict.PredictAPI.get_single_site_prediction_results(self, job_id, page_size=None, page_offset=None)\nRetrieves the results of a single site Predict job.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\njob_id\nstr\nThe ID of the Predict job.\nrequired\n\n\npage_size\ntyping.Optional[int]\nThe number of results to be returned per page. If None, all results are returned.\nis None\n\n\npage_offset\ntyping.Optional[int]\nThe page number to start retrieving results from. If None, defaults to 0.\nis None\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nPredictSingleSiteJob\nThe job object representing the single site Predict job.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nHTTPError\nIf the GET request does not succeed.\n\n\n\n\n\n\n\napi.predict.PredictAPI.load_job(self, job_id)\nReload a Submitted job to resume from where you left off!\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\njob_id\nstr\nThe identifier of the job whose details are to be loaded.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nJob\nJob\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nHTTPError\nIf the request to the server fails.\n\n\nInvalidJob\nIf the Job is of the wrong type"
  },
  {
    "objectID": "reference/api.design.DesignAPI.html",
    "href": "reference/api.design.DesignAPI.html",
    "title": "api.design.DesignAPI",
    "section": "",
    "text": "api.design.DesignAPI(self, session)\nAPI interface for calling Design endpoints\n\n\n\n\n\nName\nDescription\n\n\n\n\ncreate_design_job\nStart a protein design job based on your assaydata, a trained ML model and Criteria (specified here).\n\n\nget_design_results\nRetrieves the results of a Design job.\n\n\nload_job\nReload a Submitted job to resume from where you left off!\n\n\n\n\n\napi.design.DesignAPI.create_design_job(self, design_job)\nStart a protein design job based on your assaydata, a trained ML model and Criteria (specified here).\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndesign_job\nDesignJobCreate\nThe details of the design job to be created, with the following parameters: - assay_id: The ID for the assay. - criteria: A list of CriterionItem lists for evaluating the design. - num_steps: The number of steps in the genetic algo. Default is 8. - pop_size: The population size for the genetic algo. Default is None. - n_offsprings: The number of offspring for the genetic algo. Default is None. - crossover_prob: The crossover probability for the genetic algo. Default is None. - crossover_prob_pointwise: The pointwise crossover probability for the genetic algo. Default is None. - mutation_average_mutations_per_seq: The average number of mutations per sequence. Default is None. - mutation_positions: A list of positions where mutations may occur. Default is None.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nDesignFuture\nThe created job as a DesignFuture instance.\n\n\n\n\n\n\n\napi.design.DesignAPI.get_design_results(self, job_id, page_size=None, page_offset=None)\nRetrieves the results of a Design job.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\njob_id\nstr\nThe ID for the design job\nrequired\n\n\npage_size\ntyping.Optional[int]\nThe number of results to be returned per page. If None, all results are returned.\nis None\n\n\npage_offset\ntyping.Optional[int]\nThe number of results to skip. If None, defaults to 0.\nis None\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nDesignJob\nThe job object representing the Design job.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nHTTPError\nIf the GET request does not succeed.\n\n\n\n\n\n\n\napi.design.DesignAPI.load_job(self, job_id)\nReload a Submitted job to resume from where you left off!\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\njob_id\nstr\nThe identifier of the job whose details are to be loaded.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nJob\nJob\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nHTTPError\nIf the request to the server fails.\n\n\nInvalidJob\nIf the Job is of the wrong type"
  },
  {
    "objectID": "reference/api.design.DesignAPI.html#methods",
    "href": "reference/api.design.DesignAPI.html#methods",
    "title": "api.design.DesignAPI",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ncreate_design_job\nStart a protein design job based on your assaydata, a trained ML model and Criteria (specified here).\n\n\nget_design_results\nRetrieves the results of a Design job.\n\n\nload_job\nReload a Submitted job to resume from where you left off!\n\n\n\n\n\napi.design.DesignAPI.create_design_job(self, design_job)\nStart a protein design job based on your assaydata, a trained ML model and Criteria (specified here).\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndesign_job\nDesignJobCreate\nThe details of the design job to be created, with the following parameters: - assay_id: The ID for the assay. - criteria: A list of CriterionItem lists for evaluating the design. - num_steps: The number of steps in the genetic algo. Default is 8. - pop_size: The population size for the genetic algo. Default is None. - n_offsprings: The number of offspring for the genetic algo. Default is None. - crossover_prob: The crossover probability for the genetic algo. Default is None. - crossover_prob_pointwise: The pointwise crossover probability for the genetic algo. Default is None. - mutation_average_mutations_per_seq: The average number of mutations per sequence. Default is None. - mutation_positions: A list of positions where mutations may occur. Default is None.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nDesignFuture\nThe created job as a DesignFuture instance.\n\n\n\n\n\n\n\napi.design.DesignAPI.get_design_results(self, job_id, page_size=None, page_offset=None)\nRetrieves the results of a Design job.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\njob_id\nstr\nThe ID for the design job\nrequired\n\n\npage_size\ntyping.Optional[int]\nThe number of results to be returned per page. If None, all results are returned.\nis None\n\n\npage_offset\ntyping.Optional[int]\nThe number of results to skip. If None, defaults to 0.\nis None\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nDesignJob\nThe job object representing the Design job.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nHTTPError\nIf the GET request does not succeed.\n\n\n\n\n\n\n\napi.design.DesignAPI.load_job(self, job_id)\nReload a Submitted job to resume from where you left off!\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\njob_id\nstr\nThe identifier of the job whose details are to be loaded.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nJob\nJob\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nHTTPError\nIf the request to the server fails.\n\n\nInvalidJob\nIf the Job is of the wrong type"
  },
  {
    "objectID": "reference/api.poet.PoetGenerateFuture.html",
    "href": "reference/api.poet.PoetGenerateFuture.html",
    "title": "api.poet.PoetGenerateFuture",
    "section": "",
    "text": "api.poet.PoetGenerateFuture()\nRepresents a result of a PoET generation job.\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\nsession\nAPISession\nAn instance of APISession for API interactions.\n\n\njob\nJob\nThe PoET scoring job.\n\n\n\nMethods: stream() -&gt; Iterator[PoetScoreResult]: Stream the results of the PoET generation job.\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nstream\nStream the results from the response.\n\n\n\n\n\napi.poet.PoetGenerateFuture.stream(self)\nStream the results from the response.\n\n\n\n\n\nType\nDescription\n\n\n\n\nYield\nA result object containing the sequence, score, and name.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nAPIError\nIf the request fails."
  },
  {
    "objectID": "reference/api.poet.PoetGenerateFuture.html#attributes",
    "href": "reference/api.poet.PoetGenerateFuture.html#attributes",
    "title": "api.poet.PoetGenerateFuture",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\nsession\nAPISession\nAn instance of APISession for API interactions.\n\n\njob\nJob\nThe PoET scoring job.\n\n\n\nMethods: stream() -&gt; Iterator[PoetScoreResult]: Stream the results of the PoET generation job."
  },
  {
    "objectID": "reference/api.poet.PoetGenerateFuture.html#methods",
    "href": "reference/api.poet.PoetGenerateFuture.html#methods",
    "title": "api.poet.PoetGenerateFuture",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nstream\nStream the results from the response.\n\n\n\n\n\napi.poet.PoetGenerateFuture.stream(self)\nStream the results from the response.\n\n\n\n\n\nType\nDescription\n\n\n\n\nYield\nA result object containing the sequence, score, and name.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nAPIError\nIf the request fails."
  },
  {
    "objectID": "reference/api.embedding.EmbeddingAPI.html",
    "href": "reference/api.embedding.EmbeddingAPI.html",
    "title": "api.embedding.EmbeddingAPI",
    "section": "",
    "text": "api.embedding.EmbeddingAPI(self, session)\nThis class defines a high level interface for accessing the embeddings API.\n\n\n\n\n\nName\nDescription\n\n\n\n\ndelete_svd\nDelete SVD model.\n\n\nembed\nEmbed sequences using the specified model.\n\n\nfit_svd\nFit an SVD on the sequences with the specified model_id and hyperparameters (n_components).\n\n\nget_model\nGet model by model_id.\n\n\nget_results\nRetrieves the results of an embedding job.\n\n\nget_svd\nGet SVD job results. Including SVD dimension and sequence lengths.\n\n\nget_svd_results\nGet SVD job results. Including SVD dimension and sequence lengths.\n\n\nlist_models\nlist models available for creating embeddings of your sequences\n\n\nlist_svd\nList SVD models made by user.\n\n\nload_job\nReload a Submitted job to resume from where you left off!\n\n\n\n\n\napi.embedding.EmbeddingAPI.delete_svd(self, svd_id)\nDelete SVD model.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsvd_id\nstr\nThe ID of the SVD job.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nbool\nTrue: successful deletion\n\n\n\n\n\n\n\napi.embedding.EmbeddingAPI.embed(self, model, sequences, reduction='MEAN')\nEmbed sequences using the specified model.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmodel\ntyping.Union[openprotein.api.embedding.ProtembedModel, openprotein.api.embedding.SVDModel, str]\nThe model to use for embedding. This can be an instance of ProtembedModel, SVDModel, or a string representing the model_id.\nrequired\n\n\nsequences\ntyping.List[bytes]\nList of byte sequences to be embedded.\nrequired\n\n\nreduction\nstr\nThe reduction operation to be applied on the embeddings. Options are None, “MEAN”, or “SUM”. Default is None.\n'MEAN'\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nEmbeddingResultFuture\nAn instance of EmbeddingResultFuture\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nTypeError\nIf the input model is neither ProtembedModel, SVDModel, nor str.\n\n\n\n\n\n\n\napi.embedding.EmbeddingAPI.fit_svd(self, model_id, sequences, n_components=1024, reduction=None)\nFit an SVD on the sequences with the specified model_id and hyperparameters (n_components).\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmodel_id\nstr\nThe ID of the model to fit the SVD on.\nrequired\n\n\nsequences\ntyping.List[bytes]\nThe list of sequences to use for the SVD fitting.\nrequired\n\n\nn_components\nint\nThe number of components for the SVD, by default 1024.\n1024\n\n\nreduction\ntyping.Optional[str]\nThe reduction method to apply to the embeddings, by default None.\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nSVDModel\nThe model with the SVD fit.\n\n\n\n\n\n\n\napi.embedding.EmbeddingAPI.get_model(self, model_id)\nGet model by model_id.\nProtembedModel allows all the usual job manipulation: e.g. making POST and GET requests for this model specifically.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmodel_id\nstr\nthe model identifier\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nProtembedModel\nThe model\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nHTTPError\nIf the GET request does not succeed.\n\n\n\n\n\n\n\napi.embedding.EmbeddingAPI.get_results(self, job)\nRetrieves the results of an embedding job.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\njob\nJob\nThe embedding job whose results are to be retrieved.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nEmbeddingResultFuture\nAn instance of EmbeddingResultFuture\n\n\n\n\n\n\n\napi.embedding.EmbeddingAPI.get_svd(self, svd_id)\nGet SVD job results. Including SVD dimension and sequence lengths.\nRequires a successful SVD job from fit_svd\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsvd_id\nstr\nThe ID of the SVD job.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nSVDModel\nThe model with the SVD fit.\n\n\n\n\n\n\n\napi.embedding.EmbeddingAPI.get_svd_results(self, job)\nGet SVD job results. Including SVD dimension and sequence lengths.\nRequires a successful SVD job from fit_svd\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\njob\nJob\nSVD JobFuture\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nSVDModel\nThe model with the SVD fit.\n\n\n\n\n\n\n\napi.embedding.EmbeddingAPI.list_models(self)\nlist models available for creating embeddings of your sequences\n\n\n\napi.embedding.EmbeddingAPI.list_svd(self)\nList SVD models made by user.\nTakes no args.\n\n\n\n\n\nType\nDescription\n\n\n\n\nlist[openprotein.api.embedding.SVDModel]\nSVDModels\n\n\n\n\n\n\n\napi.embedding.EmbeddingAPI.load_job(self, job_id)\nReload a Submitted job to resume from where you left off!\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\njob_id\nstr\nThe identifier of the job whose details are to be loaded.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nJob\nJob\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nHTTPError\nIf the request to the server fails.\n\n\nInvalidJob\nIf the Job is of the wrong type"
  },
  {
    "objectID": "reference/api.embedding.EmbeddingAPI.html#methods",
    "href": "reference/api.embedding.EmbeddingAPI.html#methods",
    "title": "api.embedding.EmbeddingAPI",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ndelete_svd\nDelete SVD model.\n\n\nembed\nEmbed sequences using the specified model.\n\n\nfit_svd\nFit an SVD on the sequences with the specified model_id and hyperparameters (n_components).\n\n\nget_model\nGet model by model_id.\n\n\nget_results\nRetrieves the results of an embedding job.\n\n\nget_svd\nGet SVD job results. Including SVD dimension and sequence lengths.\n\n\nget_svd_results\nGet SVD job results. Including SVD dimension and sequence lengths.\n\n\nlist_models\nlist models available for creating embeddings of your sequences\n\n\nlist_svd\nList SVD models made by user.\n\n\nload_job\nReload a Submitted job to resume from where you left off!\n\n\n\n\n\napi.embedding.EmbeddingAPI.delete_svd(self, svd_id)\nDelete SVD model.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsvd_id\nstr\nThe ID of the SVD job.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nbool\nTrue: successful deletion\n\n\n\n\n\n\n\napi.embedding.EmbeddingAPI.embed(self, model, sequences, reduction='MEAN')\nEmbed sequences using the specified model.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmodel\ntyping.Union[openprotein.api.embedding.ProtembedModel, openprotein.api.embedding.SVDModel, str]\nThe model to use for embedding. This can be an instance of ProtembedModel, SVDModel, or a string representing the model_id.\nrequired\n\n\nsequences\ntyping.List[bytes]\nList of byte sequences to be embedded.\nrequired\n\n\nreduction\nstr\nThe reduction operation to be applied on the embeddings. Options are None, “MEAN”, or “SUM”. Default is None.\n'MEAN'\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nEmbeddingResultFuture\nAn instance of EmbeddingResultFuture\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nTypeError\nIf the input model is neither ProtembedModel, SVDModel, nor str.\n\n\n\n\n\n\n\napi.embedding.EmbeddingAPI.fit_svd(self, model_id, sequences, n_components=1024, reduction=None)\nFit an SVD on the sequences with the specified model_id and hyperparameters (n_components).\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmodel_id\nstr\nThe ID of the model to fit the SVD on.\nrequired\n\n\nsequences\ntyping.List[bytes]\nThe list of sequences to use for the SVD fitting.\nrequired\n\n\nn_components\nint\nThe number of components for the SVD, by default 1024.\n1024\n\n\nreduction\ntyping.Optional[str]\nThe reduction method to apply to the embeddings, by default None.\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nSVDModel\nThe model with the SVD fit.\n\n\n\n\n\n\n\napi.embedding.EmbeddingAPI.get_model(self, model_id)\nGet model by model_id.\nProtembedModel allows all the usual job manipulation: e.g. making POST and GET requests for this model specifically.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmodel_id\nstr\nthe model identifier\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nProtembedModel\nThe model\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nHTTPError\nIf the GET request does not succeed.\n\n\n\n\n\n\n\napi.embedding.EmbeddingAPI.get_results(self, job)\nRetrieves the results of an embedding job.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\njob\nJob\nThe embedding job whose results are to be retrieved.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nEmbeddingResultFuture\nAn instance of EmbeddingResultFuture\n\n\n\n\n\n\n\napi.embedding.EmbeddingAPI.get_svd(self, svd_id)\nGet SVD job results. Including SVD dimension and sequence lengths.\nRequires a successful SVD job from fit_svd\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsvd_id\nstr\nThe ID of the SVD job.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nSVDModel\nThe model with the SVD fit.\n\n\n\n\n\n\n\napi.embedding.EmbeddingAPI.get_svd_results(self, job)\nGet SVD job results. Including SVD dimension and sequence lengths.\nRequires a successful SVD job from fit_svd\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\njob\nJob\nSVD JobFuture\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nSVDModel\nThe model with the SVD fit.\n\n\n\n\n\n\n\napi.embedding.EmbeddingAPI.list_models(self)\nlist models available for creating embeddings of your sequences\n\n\n\napi.embedding.EmbeddingAPI.list_svd(self)\nList SVD models made by user.\nTakes no args.\n\n\n\n\n\nType\nDescription\n\n\n\n\nlist[openprotein.api.embedding.SVDModel]\nSVDModels\n\n\n\n\n\n\n\napi.embedding.EmbeddingAPI.load_job(self, job_id)\nReload a Submitted job to resume from where you left off!\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\njob_id\nstr\nThe identifier of the job whose details are to be loaded.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nJob\nJob\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nHTTPError\nIf the request to the server fails.\n\n\nInvalidJob\nIf the Job is of the wrong type"
  },
  {
    "objectID": "reference/api.design.DesignFuture.html",
    "href": "reference/api.design.DesignFuture.html",
    "title": "api.design.DesignFuture",
    "section": "",
    "text": "api.design.DesignFuture(self, session, job, page_size=1000)\nFuture Job for manipulating results\n\n\n\n\n\nName\nDescription\n\n\n\n\nget\nGet all the results of the design job.\n\n\n\n\n\napi.design.DesignFuture.get(self, verbose=False)\nGet all the results of the design job.\nArgs: verbose (bool, optional): If True, print verbose output. Defaults False.\nRaises: APIError: If there is an issue with the API request.\nReturns: DesignJob: A list of predict objects representing the results."
  },
  {
    "objectID": "reference/api.design.DesignFuture.html#methods",
    "href": "reference/api.design.DesignFuture.html#methods",
    "title": "api.design.DesignFuture",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nget\nGet all the results of the design job.\n\n\n\n\n\napi.design.DesignFuture.get(self, verbose=False)\nGet all the results of the design job.\nArgs: verbose (bool, optional): If True, print verbose output. Defaults False.\nRaises: APIError: If there is an issue with the API request.\nReturns: DesignJob: A list of predict objects representing the results."
  },
  {
    "objectID": "reference/api.embedding.EmbeddingResultFuture.html",
    "href": "reference/api.embedding.EmbeddingResultFuture.html",
    "title": "api.embedding.EmbeddingResultFuture",
    "section": "",
    "text": "api.embedding.EmbeddingResultFuture(self, session, job, sequences=None, max_workers=config.MAX_CONCURRENT_WORKERS)\nFuture Job for manipulating results\n\n\n\n\n\nName\nDescription\n\n\n\n\nget_item\nGet embedding results for specified sequence.\n\n\n\n\n\napi.embedding.EmbeddingResultFuture.get_item(self, sequence)\nGet embedding results for specified sequence.\nArgs: sequence (bytes): sequence to fetch results for\nReturns: np.ndarray: embeddings"
  },
  {
    "objectID": "reference/api.embedding.EmbeddingResultFuture.html#methods",
    "href": "reference/api.embedding.EmbeddingResultFuture.html#methods",
    "title": "api.embedding.EmbeddingResultFuture",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nget_item\nGet embedding results for specified sequence.\n\n\n\n\n\napi.embedding.EmbeddingResultFuture.get_item(self, sequence)\nGet embedding results for specified sequence.\nArgs: sequence (bytes): sequence to fetch results for\nReturns: np.ndarray: embeddings"
  },
  {
    "objectID": "reference/api.embedding.SVDModel.html",
    "href": "reference/api.embedding.SVDModel.html",
    "title": "api.embedding.SVDModel",
    "section": "",
    "text": "api.embedding.SVDModel(self, session, metadata)\nClass providing embedding endpoint for SVD models. Also allows retrieving embeddings of sequences used to fit the SVD with get.\n\n\n\n\n\nName\nDescription\n\n\n\n\ndelete\nDelete this SVD model.\n\n\nembed\nUse this SVD model to reduce embeddings results.\n\n\nget_embeddings\nGet SVD embedding results for this model.\n\n\nget_inputs\nGet sequences used for embeddings job.\n\n\nget_job\nGet job associated with this SVD model\n\n\nget_model\nFetch embeddings model\n\n\n\n\n\napi.embedding.SVDModel.delete(self)\nDelete this SVD model.\n\n\n\napi.embedding.SVDModel.embed(self, sequences)\nUse this SVD model to reduce embeddings results.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsequences\ntyping.List[bytes]\nList of protein sequences.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nEmbeddingResultFuture\nClass for further job manipulation.\n\n\n\n\n\n\n\napi.embedding.SVDModel.get_embeddings(self)\nGet SVD embedding results for this model.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nEmbeddingResultFuture: class for futher job manipulation\n\n\n\n\n\n\n\n\napi.embedding.SVDModel.get_inputs(self)\nGet sequences used for embeddings job.\n\n\n\n\n\nType\nDescription\n\n\n\n\nList[bytes]: list of sequences\n\n\n\n\n\n\n\n\napi.embedding.SVDModel.get_job(self)\nGet job associated with this SVD model\n\n\n\napi.embedding.SVDModel.get_model(self)\nFetch embeddings model"
  },
  {
    "objectID": "reference/api.embedding.SVDModel.html#methods",
    "href": "reference/api.embedding.SVDModel.html#methods",
    "title": "api.embedding.SVDModel",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ndelete\nDelete this SVD model.\n\n\nembed\nUse this SVD model to reduce embeddings results.\n\n\nget_embeddings\nGet SVD embedding results for this model.\n\n\nget_inputs\nGet sequences used for embeddings job.\n\n\nget_job\nGet job associated with this SVD model\n\n\nget_model\nFetch embeddings model\n\n\n\n\n\napi.embedding.SVDModel.delete(self)\nDelete this SVD model.\n\n\n\napi.embedding.SVDModel.embed(self, sequences)\nUse this SVD model to reduce embeddings results.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsequences\ntyping.List[bytes]\nList of protein sequences.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nEmbeddingResultFuture\nClass for further job manipulation.\n\n\n\n\n\n\n\napi.embedding.SVDModel.get_embeddings(self)\nGet SVD embedding results for this model.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nEmbeddingResultFuture: class for futher job manipulation\n\n\n\n\n\n\n\n\napi.embedding.SVDModel.get_inputs(self)\nGet sequences used for embeddings job.\n\n\n\n\n\nType\nDescription\n\n\n\n\nList[bytes]: list of sequences\n\n\n\n\n\n\n\n\napi.embedding.SVDModel.get_job(self)\nGet job associated with this SVD model\n\n\n\napi.embedding.SVDModel.get_model(self)\nFetch embeddings model"
  },
  {
    "objectID": "reference/index.html#overview",
    "href": "reference/index.html#overview",
    "title": "Function reference",
    "section": "",
    "text": "Welcome to the OpenProtein python client documentation!  Our workflows follow an asynchronous POST and GET framework. Once you initiate a task the system will schedule the job for retrieval later, once the work is complete. This means that even for tasks that may take a while to complete, your request will return immediately.  The job objects contain a job ID (job_id) which can be used to resume a workflow from where you left off! See the notebooks for demonstrations.\n\n\n\nbase.APISession\nConnection session."
  },
  {
    "objectID": "reference/base.APISession.html",
    "href": "reference/base.APISession.html",
    "title": "base.APISession",
    "section": "",
    "text": "base.APISession(self, username, password, backend='https://dev.api.openprotein.ai/api/')\nConnection session.\n\n\n\n\n\nName\nDescription\n\n\n\n\nlogin\nAuthenticate connection to OpenProtein with your credentials.\n\n\n\n\n\nbase.APISession.login(self, username, password)\nAuthenticate connection to OpenProtein with your credentials.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nusername\nstr\nusername\nrequired\n\n\npassword\nstr\npassword\nrequired"
  },
  {
    "objectID": "reference/index.html#assay-data",
    "href": "reference/index.html#assay-data",
    "title": "Function reference",
    "section": "",
    "text": "Upload your dataset to OpenProtein’s engineering platform for train, predict and design tasks.\n\n\n\napi.data.DataAPI\nAPI interface for calling AssayData endpoints\n\n\napi.data.AssayDataset\nFuture Job for manipulating results"
  },
  {
    "objectID": "reference/index.html#train-ml-models",
    "href": "reference/index.html#train-ml-models",
    "title": "Function reference",
    "section": "",
    "text": "Train model(s) on your measured properties to enable predictions for new sequences! These workflows can additionally perform cross-validation on your models to estimate uncertainty. /n A trained model is required before you can utilize predict or design endpoints.\n\n\n\napi.train.TrainingAPI\nAPI interface for calling Train endpoints\n\n\napi.train.TrainFuture\nFuture Job for manipulating results"
  },
  {
    "objectID": "reference/index.html#design-new-sequences",
    "href": "reference/index.html#design-new-sequences",
    "title": "Function reference",
    "section": "",
    "text": "Design new sequences based on your stated objectives and our genetic algorithm!\n\n\n\napi.design.DesignAPI\nAPI interface for calling Design endpoints\n\n\napi.design.DesignFuture\nFuture Job for manipulating results"
  },
  {
    "objectID": "reference/index.html#predict-protein-attributes",
    "href": "reference/index.html#predict-protein-attributes",
    "title": "Function reference",
    "section": "",
    "text": "Predict properties on arbitary sequences with your OpenProtein trained models! You can make predictions for single sequences as well as single mutant variants of the sequence. Note, that you must first train a model with the train endpoints (see above).\n\n\n\napi.predict.PredictAPI\nAPI interface for calling Predict endpoints\n\n\napi.predict.PredictFuture\nFuture Job for manipulating results"
  },
  {
    "objectID": "reference/index.html#protein-evolutionary-transformer-poet",
    "href": "reference/index.html#protein-evolutionary-transformer-poet",
    "title": "Function reference",
    "section": "",
    "text": "Use our generative Protein Evolutionary Transformer (PoET) model for de novo generation of proteins, evaluation of protein fitness, and single site mutant analysis of proteins. These workflows are all possible without prior wetlab data, and therefore do not require assaydata to be pre-loaded!\n\n\n\napi.poet.PoetAPI\nAPI interface for calling Poet and Align endpoints\n\n\napi.poet.PoetScoreFuture\nRepresents a result of a PoET scoring job.\n\n\napi.poet.PoetSingleSiteFuture\nRepresents a result of a PoET single-site analysis job.\n\n\napi.poet.PoetGenerateFuture\nRepresents a result of a PoET generation job.\n\n\napi.poet.PromptFuture\nRepresents a result of a prompt job.\n\n\napi.poet.MSAFuture\nRepresents a result of a MSA job."
  },
  {
    "objectID": "reference/index.html#protein-embeddings",
    "href": "reference/index.html#protein-embeddings",
    "title": "Function reference",
    "section": "",
    "text": "Create embeddings for your protein sequences using open-source and proprietary models!\n\n\n\napi.embedding.EmbeddingAPI\nThis class defines a high level interface for accessing the embeddings API.\n\n\napi.embedding.EmbeddingResultFuture\nFuture Job for manipulating results\n\n\napi.embedding.ProtembedModel\nClass providing inference endpoints for protein embedding models served by OpenProtein.\n\n\napi.embedding.SVDModel\nClass providing embedding endpoint for SVD models. Also allows retrieving embeddings of sequences used to fit the SVD with get."
  },
  {
    "objectID": "reference/base.APISession.html#methods",
    "href": "reference/base.APISession.html#methods",
    "title": "base.APISession",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nlogin\nAuthenticate connection to OpenProtein with your credentials.\n\n\n\n\n\nbase.APISession.login(self, username, password)\nAuthenticate connection to OpenProtein with your credentials.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nusername\nstr\nusername\nrequired\n\n\npassword\nstr\npassword\nrequired"
  },
  {
    "objectID": "reference/index.html#design",
    "href": "reference/index.html#design",
    "title": "Function reference",
    "section": "",
    "text": "Design new sequences based on your stated objectives and our genetic algorithm!\n\n\n\napi.design.DesignAPI\nAPI interface for calling Design endpoints\n\n\napi.design.DesignFuture\nFuture Job for manipulating results"
  },
  {
    "objectID": "reference/index.html#predict",
    "href": "reference/index.html#predict",
    "title": "Function reference",
    "section": "",
    "text": "Predict properties on arbitary sequences with your OpenProtein trained models! You can make predictions for single sequences as well as single mutant variants of the sequence. Note, that you must first train a model with the train endpoints (see above).\n\n\n\napi.predict.PredictAPI\nAPI interface for calling Predict endpoints\n\n\napi.predict.PredictFuture\nFuture Job for manipulating results"
  },
  {
    "objectID": "reference/index.html#embeddings",
    "href": "reference/index.html#embeddings",
    "title": "Function reference",
    "section": "",
    "text": "Create embeddings for your protein sequences using open-source and proprietary models!\n\n\n\napi.embedding.EmbeddingAPI\nThis class defines a high level interface for accessing the embeddings API.\n\n\napi.embedding.EmbeddingResultFuture\nFuture Job for manipulating results\n\n\napi.embedding.ProtembedModel\nClass providing inference endpoints for protein embedding models served by OpenProtein.\n\n\napi.embedding.SVDModel\nClass providing embedding endpoint for SVD models. Also allows retrieving embeddings of sequences used to fit the SVD with get."
  },
  {
    "objectID": "reference/index.html#train",
    "href": "reference/index.html#train",
    "title": "Function reference",
    "section": "",
    "text": "Train model(s) on your measured properties to enable predictions for new sequences! These workflows can additionally perform cross-validation on your models to estimate uncertainty. /n A trained model is required before you can utilize predict or design endpoints.\n\n\n\napi.train.TrainingAPI\nAPI interface for calling Train endpoints\n\n\napi.train.TrainFuture\nFuture Job for manipulating results"
  }
]